import { createRequire } from 'module';const require = createRequire(import.meta.url);
import {
  notionMCPFetch,
  notionMCPGetSelf,
  notionMCPSearch
} from "./chunk-36RZ7HXC.js";
import {
  executeShipperCloudDeploymentWithFiles,
  injectDeployKeyIntoSandbox
} from "./chunk-KVFOHPGT.js";
import {
  createFilesystemSnapshot,
  createSandbox,
  deleteSandbox,
  executeCommand,
  getSandbox,
  hasSnapshot,
  listFiles,
  readFile,
  startDevServer,
  writeFile
} from "./chunk-IDZAZ4YU.js";
import {
  createProjectLogger,
  logger
} from "./chunk-TIBZDRCE.js";
import {
  import_prisma,
  prisma
} from "./chunk-YMWDDMLV.js";
import {
  __require,
  init_esm_shims
} from "./chunk-IXOW5DJO.js";

// src/services/ai-tools.ts
init_esm_shims();
import { Buffer as Buffer2 } from "buffer";
import { transformModalUrlForDisplay } from "@shipper/shared";

// src/services/sandbox-health.ts
init_esm_shims();
var CORE_FILE_PATTERNS = [
  { label: "package.json", regex: /^package\.json$/i },
  {
    label: "vite.config",
    regex: /^vite\.config\.(js|ts|mjs|cjs)$/i
  },
  {
    label: "app entry",
    // Support various entry point patterns:
    // - src/main.jsx, src/app.jsx, src/index.jsx (standard Vite)
    // - main.jsx (root level, some platforms)
    // - src/App.jsx (capital A, common pattern)
    regex: /^(src\/)?(main|app|index|App)\.(t|j)sx?$/i
  }
];
var CONFIG_PATTERN = {
  label: "tsconfig/jsconfig",
  regex: /^(tsconfig|jsconfig)(\.[^.]+)?\.json$/i
};
var TYPESCRIPT_SOURCE_FILE_PATTERN = /^src\/.*\.(ts|tsx)$/i;
var FALLBACK_MODAL_TEMPLATE = "database-vite-template";
var TEMPLATE_KEYWORD_MAP = [
  {
    template: "database-vite-todo-template",
    keywords: ["todo", "task", "tasks"]
  },
  {
    template: "database-vite-calculator-template",
    keywords: ["calculator"]
  },
  {
    template: "database-vite-content-sharing-template",
    keywords: ["content", "share", "sharing"]
  },
  {
    template: "database-vite-landing-page-template",
    keywords: ["landing", "marketing", "hero"]
  },
  {
    template: "database-vite-tracker-template",
    keywords: ["tracker", "tracking", "habit", "budget"]
  }
];
var enableRecoveryDebug = process.env.RECOVERY_DEBUG === "true" || (process.env.DEBUG || "").includes("sandbox-recovery");
function logRecoveryEvent(logger2, payload) {
  if (!enableRecoveryDebug) return;
  (logger2 ?? logger).info({
    msg: "sandbox.recovery",
    ...payload
  });
}
function getModalEnvironment() {
  return process.env.NODE_ENV === "development" ? "dev" : "main";
}
function ensureRecord(value) {
  if (typeof value === "string") {
    try {
      return JSON.parse(value);
    } catch {
      return null;
    }
  }
  if (value && typeof value === "object" && !Array.isArray(value)) {
    return value;
  }
  return null;
}
function inferTemplateFromFiles(files) {
  const fileNamesText = Object.keys(files).join(" ").toLowerCase();
  const packageJsonRaw = files["package.json"];
  let packageText = "";
  if (packageJsonRaw) {
    try {
      const pkg = JSON.parse(packageJsonRaw);
      const dependencyNames = Object.keys({
        ...pkg.dependencies || {},
        ...pkg.devDependencies || {}
      }).join(" ");
      packageText = `${pkg.name || ""} ${pkg.description || ""} ${dependencyNames}`.toLowerCase();
    } catch {
      packageText = packageJsonRaw.toLowerCase();
    }
  }
  const readmeText = (files["README.md"] || "").toLowerCase();
  const combinedText = `${fileNamesText} ${packageText} ${readmeText}`;
  for (const mapping of TEMPLATE_KEYWORD_MAP) {
    if (mapping.keywords.some((keyword) => combinedText.includes(keyword))) {
      return mapping.template;
    }
  }
  return null;
}
function logTemplateResolution(logger2, projectId, resolution) {
  logger2.info({
    msg: "ai.sandbox.templateResolved",
    projectId,
    templateName: resolution.templateName,
    templateSource: resolution.source,
    hasSnapshot: resolution.hasSnapshot
  });
}
async function resolveProjectTemplate(projectId, logger2) {
  const env = getModalEnvironment();
  const project = await prisma.project.findUnique({
    where: { id: projectId },
    select: {
      activeFragmentId: true
    }
  });
  const fragmentCandidates = [];
  if (project?.activeFragmentId) {
    const activeFragment = await prisma.v2Fragment.findUnique({
      where: { id: project.activeFragmentId },
      select: { id: true, files: true, createdAt: true }
    });
    if (activeFragment) {
      fragmentCandidates.push(activeFragment);
    }
  }
  const fallbackFragment = await prisma.v2Fragment.findFirst({
    where: { projectId },
    orderBy: { createdAt: "desc" },
    select: { id: true, files: true, createdAt: true }
  });
  if (fallbackFragment && !fragmentCandidates.some((fragment) => fragment.id === fallbackFragment.id)) {
    fragmentCandidates.push(fallbackFragment);
  }
  for (const fragment of fragmentCandidates) {
    const files = ensureRecord(fragment.files);
    if (!files) continue;
    const inferredTemplate = inferTemplateFromFiles(files);
    if (inferredTemplate) {
      const hasKnownSnapshot = hasSnapshot(inferredTemplate, env);
      const source = project?.activeFragmentId === fragment.id ? "fragment" : "heuristic";
      const resolution = {
        templateName: inferredTemplate,
        source,
        hasSnapshot: hasKnownSnapshot
      };
      logTemplateResolution(logger2, projectId, resolution);
      return resolution;
    }
  }
  const fallbackResolution = {
    templateName: FALLBACK_MODAL_TEMPLATE,
    source: "fallback",
    hasSnapshot: hasSnapshot(FALLBACK_MODAL_TEMPLATE, env)
  };
  logTemplateResolution(logger2, projectId, fallbackResolution);
  return fallbackResolution;
}
async function ensureFragmentForRecovery(projectId, preferredFragmentId, logger2) {
  if (preferredFragmentId) {
    const exists = await prisma.v2Fragment.findUnique({
      where: { id: preferredFragmentId },
      select: { id: true }
    });
    if (exists) {
      return preferredFragmentId;
    }
    logger2.warn({
      msg: "ai.sandbox.fragmentMissingForRecovery",
      projectId,
      fragmentId: preferredFragmentId
    });
  }
  const fallback = await prisma.v2Fragment.findFirst({
    where: { projectId },
    orderBy: { updatedAt: "desc" },
    select: { id: true }
  });
  if (!fallback) {
    logger2.error({
      msg: "ai.sandbox.noFragmentsAvailable",
      projectId
    });
    return null;
  }
  logger2.info({
    msg: "ai.sandbox.fragmentSelectedForRecovery",
    projectId,
    fragmentId: fallback.id
  });
  return fallback.id;
}
async function findRecoverySnapshot(projectId, startingFragmentId, logger2, templateNameOverride) {
  if (startingFragmentId) {
    const activeFragment = await prisma.v2Fragment.findUnique({
      where: { id: startingFragmentId },
      select: {
        id: true,
        snapshotImageId: true,
        createdAt: true
      }
    });
    if (activeFragment?.snapshotImageId) {
      logger2.info({
        msg: "ai.sandbox.recoverySnapshotSelected",
        projectId,
        fragmentId: activeFragment.id,
        snapshotImageId: activeFragment.snapshotImageId,
        source: "active-fragment"
      });
      return {
        fragmentId: activeFragment.id,
        snapshotImageId: activeFragment.snapshotImageId
      };
    }
    logger2.info({
      msg: "ai.sandbox.recoverySnapshotSearch",
      projectId,
      fragmentId: startingFragmentId,
      reason: "active-fragment-missing-snapshot"
    });
    const fallbackFragment = await prisma.v2Fragment.findFirst({
      where: {
        projectId,
        snapshotImageId: { not: null },
        createdAt: activeFragment?.createdAt ? { lte: activeFragment.createdAt } : void 0
      },
      orderBy: { createdAt: "desc" },
      select: { id: true, snapshotImageId: true }
    });
    if (fallbackFragment?.snapshotImageId) {
      logger2.info({
        msg: "ai.sandbox.recoverySnapshotSelected",
        projectId,
        fragmentId: fallbackFragment.id,
        snapshotImageId: fallbackFragment.snapshotImageId,
        source: "fallback-fragment"
      });
      return {
        fragmentId: fallbackFragment.id,
        snapshotImageId: fallbackFragment.snapshotImageId
      };
    }
  }
  const latestSnapshot = await prisma.v2Fragment.findFirst({
    where: {
      projectId,
      snapshotImageId: { not: null }
    },
    orderBy: { createdAt: "desc" },
    select: { id: true, snapshotImageId: true }
  });
  if (latestSnapshot?.snapshotImageId) {
    logger2.info({
      msg: "ai.sandbox.recoverySnapshotSelected",
      projectId,
      fragmentId: latestSnapshot.id,
      snapshotImageId: latestSnapshot.snapshotImageId,
      source: "latest-snapshot"
    });
    return {
      fragmentId: latestSnapshot.id,
      snapshotImageId: latestSnapshot.snapshotImageId
    };
  }
  logger2.warn({
    msg: "ai.sandbox.noSnapshotsFound",
    projectId
  });
  const fragmentForRecovery = await ensureFragmentForRecovery(
    projectId,
    startingFragmentId,
    logger2
  );
  const templateName = templateNameOverride ?? FALLBACK_MODAL_TEMPLATE;
  if (!fragmentForRecovery) {
    return {
      fragmentId: null,
      snapshotImageId: null,
      templateName
    };
  }
  try {
    logger2.info({
      msg: "ai.sandbox.bootstrapFromTemplate",
      projectId,
      fragmentId: fragmentForRecovery,
      templateName
    });
    const sandboxInfo = await createSandbox(
      projectId,
      fragmentForRecovery,
      templateName,
      logger2
    );
    const snapshotImageId = await createFilesystemSnapshot(
      sandboxInfo.sandbox,
      fragmentForRecovery,
      projectId,
      logger2
    );
    logger2.info({
      msg: "ai.sandbox.templateSnapshotCreated",
      projectId,
      fragmentId: fragmentForRecovery,
      snapshotImageId,
      templateName,
      sandboxId: sandboxInfo.sandboxId
    });
    return {
      fragmentId: fragmentForRecovery,
      snapshotImageId,
      templateName,
      sandboxId: sandboxInfo.sandboxId,
      sandboxUrl: sandboxInfo.sandboxUrl
    };
  } catch (error) {
    logger2.error({
      msg: "ai.sandbox.templateBootstrapFailed",
      projectId,
      fragmentId: fragmentForRecovery,
      templateName,
      error: error instanceof Error ? error.message : String(error)
    });
    return {
      fragmentId: fragmentForRecovery,
      snapshotImageId: null,
      templateName
    };
  }
}
async function getSandboxHealth(projectId, logger2 = logger) {
  const project = await prisma.project.findUnique({
    where: { id: projectId },
    select: {
      sandboxId: true,
      sandboxProvider: true,
      buildStatus: true,
      importedFrom: true,
      codeImport: { select: { importedFrom: true } }
    }
  });
  if (!project?.sandboxId) {
    const fragmentCount = await prisma.v2Fragment.count({
      where: { projectId }
    });
    if (fragmentCount === 0) {
      logger2.info({
        msg: "ai.sandbox.newProjectNoSandbox",
        projectId,
        reason: "brand-new-project-no-fragments"
      });
      return {
        broken: false,
        // Changed from true - brand new projects aren't "broken"
        sandboxId: null,
        reason: "new-project-no-generation-yet"
      };
    }
    return {
      broken: true,
      sandboxId: null,
      reason: "missing-sandbox"
    };
  }
  if (project.sandboxProvider && project.sandboxProvider !== "modal") {
    return {
      broken: false,
      sandboxId: project.sandboxId,
      reason: "non-modal-provider"
    };
  }
  try {
    const files = await listFiles(project.sandboxId, logger2);
    const paths = Array.from(files.keys());
    const importedFrom = project.importedFrom ?? project.codeImport?.importedFrom ?? null;
    const hasTypeScriptSourceFiles = paths.some(
      (path) => TYPESCRIPT_SOURCE_FILE_PATTERN.test(path)
    );
    const requiredPatterns = [...CORE_FILE_PATTERNS];
    if (hasTypeScriptSourceFiles) {
      requiredPatterns.push(CONFIG_PATTERN);
    }
    if (enableRecoveryDebug) {
      logger2.info({
        msg: "sandbox.recovery",
        step: "list-files",
        projectId,
        sandboxId: project.sandboxId,
        workingDir: "/workspace",
        fileSample: paths.slice(0, 50),
        criticalPatterns: requiredPatterns.map((pattern) => pattern.label),
        hasTypeScriptSourceFiles,
        importedFrom
      });
    }
    const missing = requiredPatterns.filter(({ regex }) => !paths.some((path) => regex.test(path))).map(({ label }) => label);
    if (missing.length > 0) {
      logger2.warn({
        msg: "ai.sandbox.detectedBroken",
        projectId,
        sandboxId: project.sandboxId,
        missing,
        hasTypeScriptSourceFiles,
        importedFrom
      });
      return {
        broken: true,
        sandboxId: project.sandboxId,
        reason: "missing-critical-files",
        missingFiles: missing
      };
    }
    return {
      broken: false,
      sandboxId: project.sandboxId
    };
  } catch (error) {
    logger2.error({
      msg: "ai.sandbox.detectedBroken",
      projectId,
      sandboxId: project.sandboxId,
      reason: "list-files-failed",
      error: error instanceof Error ? error.message : String(error)
    });
    return {
      broken: true,
      sandboxId: project.sandboxId,
      reason: "list-files-failed"
    };
  }
}
async function ensureSandboxRecovered(projectId, options = {}) {
  const logger2 = options.logger ?? logger;
  const project = await prisma.project.findUnique({
    where: { id: projectId },
    select: {
      sandboxId: true,
      sandboxProvider: true,
      activeFragmentId: true,
      importedFrom: true,
      codeImport: { select: { id: true, importedFrom: true } }
      // Check if this is an imported project
    }
  });
  const isImportedProject = !!project?.codeImport;
  const importedFrom = project?.importedFrom ?? project?.codeImport?.importedFrom ?? null;
  if (!project) {
    throw new Error(`Project not found: ${projectId}`);
  }
  const templateResolution = await resolveProjectTemplate(projectId, logger2);
  const previousSandboxId = project.sandboxId ?? null;
  logRecoveryEvent(logger2, {
    step: "recovery-start",
    projectId,
    previousSandboxId,
    templateName: templateResolution.templateName,
    templateSource: templateResolution.source,
    templateHasSnapshot: templateResolution.hasSnapshot
  });
  if (project.sandboxProvider && project.sandboxProvider !== "modal") {
    return {
      recovered: false,
      sandboxId: project.sandboxId
    };
  }
  const health = await getSandboxHealth(projectId, logger2);
  if (!health.broken) {
    if (health.reason === "new-project-no-generation-yet") {
      logger2.info({
        msg: "ai.sandbox.skippingRecoveryForNewProject",
        projectId,
        reason: "brand-new-project-awaiting-first-generation"
      });
    }
    return {
      recovered: false,
      sandboxId: health.sandboxId
    };
  }
  const fragmentId = options.fragmentId ?? project.activeFragmentId ?? null;
  const recoverySnapshot = await findRecoverySnapshot(
    projectId,
    fragmentId,
    logger2,
    options.templateName ?? templateResolution.templateName
  );
  const fragmentForRecovery = recoverySnapshot.fragmentId ?? fragmentId ?? project.activeFragmentId ?? null;
  let templateForRecovery = options.templateName ?? recoverySnapshot.templateName ?? templateResolution.templateName;
  let templateSource = options.templateName ? "override" : templateResolution.source;
  const templateHasSnapshot = hasSnapshot(
    templateForRecovery,
    getModalEnvironment()
  );
  logger2.info({
    msg: "ai.sandbox.recoveryStarted",
    projectId,
    sandboxId: project.sandboxId,
    fragmentId: fragmentForRecovery,
    templateName: templateForRecovery,
    templateSource,
    templateHasSnapshot,
    reason: health.reason,
    missingFiles: health.missingFiles,
    recoverySnapshotImageId: recoverySnapshot.snapshotImageId ?? void 0
  });
  let sandboxId = recoverySnapshot.sandboxId ?? null;
  if (!sandboxId) {
    const createdSandbox = await createSandbox(
      projectId,
      fragmentForRecovery,
      templateForRecovery,
      logger2,
      {
        recoverySnapshotImageId: recoverySnapshot.snapshotImageId ?? void 0,
        isImportedProject,
        importedFrom
      }
    );
    sandboxId = createdSandbox.sandboxId;
  } else {
    logger2.info({
      msg: "ai.sandbox.reusingTemplateBootstrap",
      projectId,
      sandboxId,
      fragmentId: fragmentForRecovery
    });
  }
  await prisma.project.update({
    where: { id: projectId },
    data: {
      activeFragmentId: fragmentForRecovery ?? project.activeFragmentId,
      buildStatus: "READY",
      buildStatusUpdatedAt: /* @__PURE__ */ new Date(),
      buildError: null
    }
  });
  logRecoveryEvent(logger2, {
    step: "before-verify",
    projectId,
    sandboxId,
    templateName: templateForRecovery,
    templateSource,
    templateHasSnapshot
  });
  const verification = await getSandboxHealth(projectId, logger2);
  if (verification.broken) {
    logger2.error({
      msg: "ai.sandbox.recoveryVerificationFailed",
      projectId,
      sandboxId,
      reason: verification.reason,
      missingFiles: verification.missingFiles
    });
    logRecoveryEvent(logger2, {
      step: "verify-failed",
      projectId,
      sandboxId,
      missingFiles: verification.missingFiles || []
    });
    throw new Error(
      "Sandbox recovery failed verification. Critical files still missing."
    );
  } else {
    logger2.info({
      msg: "ai.sandbox.recoveryFinished",
      projectId,
      sandboxId,
      fragmentId: fragmentForRecovery,
      templateName: templateForRecovery
    });
    logRecoveryEvent(logger2, {
      step: "verify-success",
      projectId,
      sandboxId
    });
  }
  if (previousSandboxId && sandboxId && previousSandboxId !== sandboxId) {
    const stillReferenced = await prisma.project.findFirst({
      where: { sandboxId: previousSandboxId },
      select: { id: true }
    });
    if (!stillReferenced) {
      try {
        await deleteSandbox(previousSandboxId, projectId);
        logger2.info({
          msg: "ai.sandbox.cleanedUpOldSandbox",
          projectId,
          sandboxId: previousSandboxId
        });
      } catch (cleanupError) {
        logger2.warn({
          msg: "ai.sandbox.cleanupFailed",
          projectId,
          sandboxId: previousSandboxId,
          error: cleanupError instanceof Error ? cleanupError.message : String(cleanupError)
        });
      }
    } else {
      logger2.info({
        msg: "ai.sandbox.cleanupSkippedActiveReference",
        projectId,
        sandboxId: previousSandboxId,
        referencedByProjectId: stillReferenced.id
      });
    }
  }
  return {
    recovered: true,
    sandboxId
  };
}
async function assertSandboxHealthyOrThrow(projectId, logger2 = logger) {
  const health = await getSandboxHealth(projectId, logger2);
  if (health.broken) {
    throw new Error(
      "Sandbox is currently unavailable. Recovery is in progress. Please retry in a few seconds."
    );
  }
}

// src/services/ai-tools.ts
import { tool } from "ai";
import { z } from "zod";

// src/services/posthog-capture.ts
init_esm_shims();
function getEnvironmentProperties() {
  const nodeEnv = process.env.NODE_ENV || "development";
  const vercelEnv = process.env.VERCEL_ENV;
  return {
    environment: nodeEnv,
    vercel_env: vercelEnv
  };
}
var PostHogManualCapture = class {
  constructor() {
    this.apiKey = process.env.POSTHOG_PROJECT_API_KEY || process.env.NEXT_PUBLIC_POSTHOG_KEY || "";
    this.host = process.env.POSTHOG_HOST || process.env.NEXT_PUBLIC_POSTHOG_HOST || "https://eu.i.posthog.com";
  }
  async sendEvent(event) {
    if (!this.apiKey) {
      console.warn("[PostHog] API key not configured, skipping event capture");
      return;
    }
    try {
      const response = await fetch(`${this.host}/i/v0/e/`, {
        method: "POST",
        headers: {
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          ...event,
          api_key: this.apiKey,
          timestamp: event.timestamp || (/* @__PURE__ */ new Date()).toISOString()
        })
      });
      if (!response.ok) {
        console.error(
          `[PostHog] Failed to send event: ${response.status} ${response.statusText}`
        );
      }
    } catch (error) {
      console.error("[PostHog] Error sending event:", error);
    }
  }
  /**
   * Capture an AI generation event
   * @param properties - The properties for the AI generation event
   */
  async captureAIGeneration(properties) {
    await this.sendEvent({
      api_key: this.apiKey,
      event: "$ai_generation",
      properties
    });
  }
  /**
   * Capture an AI trace event
   * @param properties - The properties for the AI trace event
   */
  async captureAITrace(properties) {
    await this.sendEvent({
      api_key: this.apiKey,
      event: "$ai_trace",
      properties
    });
  }
  /**
   * Capture an AI span event
   * @param properties - The properties for the AI span event
   */
  async captureAISpan(properties) {
    await this.sendEvent({
      api_key: this.apiKey,
      event: "$ai_span",
      properties
    });
  }
  /**
   * Capture a custom event
   * @param event - The event name
   * @param properties - The event properties
   */
  async capture(event, properties) {
    await this.sendEvent({
      api_key: this.apiKey,
      event,
      properties
    });
  }
  /**
   * Check if PostHog is configured
   */
  isConfigured() {
    return !!this.apiKey;
  }
};
var postHogCapture = null;
function getPostHogCapture() {
  if (!postHogCapture) {
    postHogCapture = new PostHogManualCapture();
  }
  return postHogCapture;
}
function generateSpanId() {
  return `span_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
}

// src/prompts/v2-full-stack-prompt.ts
init_esm_shims();

// src/prompts/utils.ts
init_esm_shims();
function stripIndents(strings, ...values) {
  let text;
  if (typeof strings === "string") {
    text = strings;
  } else {
    text = strings.reduce((acc, str, i) => acc + str + (values[i] ?? ""), "");
  }
  const lines = text.split("\n");
  while (lines.length > 0 && lines[0].trim() === "") {
    lines.shift();
  }
  while (lines.length > 0 && lines[lines.length - 1].trim() === "") {
    lines.pop();
  }
  const minIndent = lines.reduce((min, line) => {
    if (line.trim() === "") return min;
    const indent = line.match(/^[ \t]*/)?.[0].length ?? 0;
    return Math.min(min, indent);
  }, Infinity);
  const dedented = lines.map((line) => {
    if (line.trim() === "") return "";
    return line.slice(minIndent);
  });
  return dedented.join("\n");
}

// src/prompts/v2-full-stack-prompt.ts
function getFullStackPrompt() {
  return stripIndents`
üé® === FIRST GENERATION EXCELLENCE - THIS IS THE USER'S FIRST IMPRESSION === üé®

You are a world-class full-stack developer for Shipper that creates complete, beautiful, functional applications in Vite + React + TypeScript + TanStack Router + Tailwind v4 sandboxes.

**IF THIS IS THE INITIAL BUILD:**
This is the user's FIRST EXPERIENCE with their app. Make it exceptional:
1. **VISUALLY IMPRESSIVE** - Professional design that looks production-ready
2. **ZERO PLACEHOLDERS** - Real content, never "Lorem ipsum", "TODO", or "Hello /route!" stub routes
3. **FULLY FUNCTIONAL** - All features work perfectly on first load
4. **VISUAL POLISH** - Smooth transitions, hover states, shadows, responsive design
5. **TAILWIND V4 CLASSES** - Use standard Tailwind classes OR Tailwind v4 theme variables
6. **THEME SUPPORT** - Use \`dark:\` variant for all colors, include theme switcher, set \`defaultTheme="system"\`

Remember: First impressions define the product. Build something that wows immediately!

üéØ === THINK LIKE A SURGEON, NOT AN ARTIST === üéØ

**IF THIS IS AN EDIT (modifying existing user code):**
You are a SURGEON making a precise incision, not a construction worker demolishing a wall.
- Preserve 99% of original code
- Change ONLY what's explicitly requested
- Think: minimal viable change, not complete reimagination

---

## ‚ö° CRITICAL RULES - TOP 13 COMMANDMENTS

<critical_rules>
1. **Always call \`getFiles\` first** - See existing structure before any operation (MANDATORY FIRST STEP)
2. **NEVER call deployToShipperCloud on first message** - Build UI with mock data first, database only when explicitly requested
3. **Always finalize fragments** - Every task ends with \`finalizeWorkingFragment\` (even 1-char edits)
4. **Zero errors on first finalization** - Write code that passes TypeScript validation immediately
5. **Queries return null when unauthenticated** - NEVER throw errors in queries (crashes the app)
6. **userId is v.string()** - Better Auth user.id is a string (NOT v.id("users"))
7. **Never question user requests** - If user asks for it, implement immediately without discussion
8. **No excuses or explanations** - Never explain why something is missing, just fix it
9. **Silent error fixing** - When finalization fails, fix errors without explaining to user
10. **Complete implementations** - Build fully-featured applications, no placeholders or TODOs
11. **NEVER pass context prop to TanStack Router** - Use search params, useState, or Zustand for shared state (context prop causes TS2322 error)
12. **ALWAYS use skip pattern for ALL Convex queries** - \`useQuery(api.x.y, isAuthenticated ? {} : "skip")\` prevents Server Error crashes
13. **NEVER create placeholder auth routes** - signin/signup routes MUST have real forms, not \`Hello "/signin"!\` stubs
14. **PRESERVE ROUTING LIBRARY FOR IMPORTED PROJECTS** - NEVER change router imports! If project uses react-router-dom, keep using it. TanStack Router is ONLY for new Shipper template projects.
</critical_rules>

---

## üìù MANDATORY THOUGHT PROCESS (Execute Before Writing Code)

<thought_process>
Before you write ANY code, you MUST mentally execute these steps:

**1. Understand Intent**
- What is the user's core goal?
- Is this initial build or surgical edit?

**2. Locate Code**
- Use getFiles to see what exists
- Find EXACT file names - check the file list!
- DO NOT create new files if similar ones exist

**3. Plan Minimal Changes**
- What's the smallest change that achieves the goal?
- Which exact lines need modification?
- Count: How many files will I touch? (Keep it minimal!)

**4. Verify Preservation**
- What existing code must NOT be touched?
- How can I avoid disrupting surrounding code?

**5. Generate Code**
- Only after completing steps 1-4, generate final code

**ACCURACY & ROBUSTNESS GUIDELINES:**
- Verify before you write: Ensure you understand existing file structure and dependencies
- No broken builds: Your code must compile and run without errors
- Respect existing code: Do not overwrite or delete code unless necessary
- Follow instructions literally: If user provides specific text or data, use it exactly
</thought_process>

---

## üö® CRITICAL RESPONSE GUIDELINES

<communication_rules>
**1. BE CONCISE** - Keep text responses brief and focused
- When presenting your plan: "Let's build your {description of app here}"
- Short and sweet, not lengthy explanations

**2. NEVER OUTPUT CODE INLINE** - Use tools to create files, don't include code in your responses

**3. NO CODE BLOCKS** - Don't wrap code in backticks or show code content in messages

**4. TOOL-FIRST APPROACH** - Let the tools handle all code/file operations

**5. SUMMARY ONLY** - Only describe what you're doing, not how the code looks

**6. NO EXCUSES OR EXPLANATIONS** - Never explain why something is missing, broken, or was removed
- ‚ùå WRONG: "I see the issue - the previous update removed the button. Let me add it back"
- ‚úÖ CORRECT: "Adding the random color button now"
- Users want action, not diagnosis

**7. üö´üö´üö´ ABSOLUTE SILENCE BETWEEN TOOL CALLS** - CRITICAL for UI grouping
- ‚ùå NEVER say: "Let me...", "Now I'll...", "Perfect!", "Done!", "Created!", "Let me fix..."
- ‚ùå NEVER narrate your actions: "I'll help you build...", "Let me start by checking...", "Now let me create..."
- ‚ùå NEVER give status updates between steps
- ‚úÖ CORRECT: Call tool ‚Üí Call tool ‚Üí Call tool ‚Üí ONE brief summary at the very end
- ‚úÖ Execute tools in COMPLETE SILENCE until all work is done
- Tool results speak for themselves - the UI shows tool progress automatically
- Text messages between tools break the UI's tool grouping and create a poor experience
- **ONLY SPEAK WHEN:** (a) All work is finalized, OR (b) User asks a question
- Wait until ALL tools are complete, then give ONE concise summary

**8. NEVER QUESTION USER REQUESTS**
- If a user asks you to add/change something, DO IT IMMEDIATELY without discussion
- NEVER say "I already added this" or "This feature exists" - just implement what's asked
- When users restore a previous fragment and ask to re-add features, they KNOW those features aren't in the current version
- The current fragment state is the ONLY truth - ignore conversation history about what was "already done"
- If the user asks for it, they need it - no questions, no explanations, just action

**9. SILENT ERROR FIXING**
- When finalizeWorkingFragment fails with errors, DON'T explain the errors to the user
- DON'T say "I see there are 3 build errors, let me fix them"
- DON'T list out the errors or explain what's wrong
- JUST FIX THEM SILENTLY and try finalizing again
- Keep fixing and finalizing until it succeeds - no commentary needed
- Users see the progress through tool calls, not through your explanations
- **If errors are confusing or tool behaves unexpectedly**: Use debugInfo field in finalizeWorkingFragment tool call (3-4 sentences max, never mention to user)
</communication_rules>

---

## ‚ö†Ô∏è ERROR PREVENTION - WRITE IT RIGHT THE FIRST TIME

<error_prevention>
Most errors are preventable if you follow TypeScript rules strictly:

**Common error categories and how to prevent them:**
1. **Type errors (TS2322, TS2345)** - Always verify types match before assigning
2. **Unused variable errors (TS6133)** - Only declare what you actually use
3. **Property errors (TS2339)** - Verify object/array structure before accessing properties
4. **Import errors** - Only import what exists and what you'll use

**Target: ZERO errors on first finalization attempt**

Think of errors as failures - the goal is to write code so clean it passes validation immediately.
</error_prevention>

---

## ‚ú® VISUAL POLISH REQUIREMENTS (FIRST GENERATION)

<visual_polish>
Every component you create MUST include:

1. **Smooth Transitions** - \`transition-all duration-300\` on interactive elements
2. **Hover States** - \`hover:scale-105\`, \`hover:shadow-lg\`, \`hover:bg-blue-700\`
3. **Depth & Shadows** - \`shadow-md\`, \`shadow-lg\` for cards and elevated elements
4. **Responsive Design** - \`sm:\`, \`md:\`, \`lg:\`, \`xl:\` breakpoints for mobile-first design
5. **Color Contrast** - Ensure text is readable on all backgrounds
6. **Proper Spacing** - Consistent padding/margins using Tailwind's spacing scale

**Example of a polished button:**
\`\`\`
className="px-6 py-3 bg-blue-600 text-white rounded-lg shadow-md
           hover:bg-blue-700 hover:shadow-xl transform hover:scale-105
           transition-all duration-200 font-semibold"
\`\`\`

**Example of a polished card:**
\`\`\`
className="bg-white dark:bg-slate-800 rounded-xl shadow-lg p-8 border border-gray-100 dark:border-slate-700
           hover:shadow-2xl transition-shadow duration-300"
\`\`\`

**Example of a polished hero section:**
\`\`\`
className="min-h-screen bg-gradient-to-br from-blue-50 to-indigo-100 dark:from-slate-900 dark:to-slate-800
           flex items-center justify-center px-4 sm:px-6 lg:px-8"
\`\`\`
</visual_polish>

---

## üîß TOOL DEBUGGING - HELP US IMPROVE

<tool_debugging>
- **finalizeWorkingFragment has optional debugInfo field** - Silent feedback to developers about tools/workflow
- **Be concise (3-4 sentences max)** - Don't waste tokens on verbose feedback
- **Don't be afraid to share your thoughts** - Your feedback helps us improve the platform
- Use when: tools behaved unexpectedly, features missing, descriptions unclear, errors encountered, or suggestions
- **NEVER mention to user** - Silent feedback only
- Examples:
  * "quickEdit pattern matching too strict - fuzzy matching would help"
  * "batch file update feature would reduce multiple createOrEditFiles calls"
  * "validation error messages were very clear and helpful"
  * "Got error about ease-in-out class not existing - Tailwind v4 doesn't support it"
</tool_debugging>

---

## üöÄ SHIPPER CLOUD - CRITICAL DEPLOYMENT RULES

<shipper_cloud_critical>

**Shipper Cloud provides a production-ready backend. It includes:**
- Real-time database with automatic sync (changes reflect instantly in UI)
- Type-safe queries and mutations (full TypeScript support)
- Native Convex Auth integration (email/password authentication)
- File storage for images and documents
- Scheduled functions (cron jobs)

### üö´üö´üö´ RULE #1: NEVER CALL deployToShipperCloud ON FIRST MESSAGE üö´üö´üö´

**This is the #1 rule for Shipper Cloud and prevents the most common production issue.**

Even if the user describes an app that obviously needs a database (chat app, todo app, e-commerce, notes app, shopping cart), you MUST build the frontend UI first with mock data.

**THE CORRECT FLOW:**
\`\`\`
1. First message ‚Üí Build frontend UI with useState and mock/placeholder data
2. User sees working preview
3. User explicitly requests persistence ‚Üí THEN call deployToShipperCloud
\`\`\`

**‚úÖ ENABLE Shipper Cloud when user EXPLICITLY says:**
- "connect a database", "save to database", "persist this data"
- "add user accounts", "add authentication", "add login"
- "make it real", "save my data permanently"
- "how do I save this?", "I need a backend"

**‚ùå NEVER call deployToShipperCloud on first message, even if the concept involves data:**
- "build me a Slack clone" ‚Üí Build chat UI first with mock messages, wait for database request
- "build me a todo app" ‚Üí Build UI first with local state, wait for them to ask about saving
- "create a notes app" ‚Üí Build UI first, let them ask about persistence
- "make a shopping cart" ‚Üí Build UI first with useState, wait for database request
- "build a chat app" ‚Üí Build chat UI with mock data, wait for user to ask about real persistence

**Why this matters:** Users need to see their app working FIRST. They interact with it, get excited, THEN ask "how do I save this?" Show the WOW first, add database complexity second.

### ‚ö†Ô∏è BRANDING RULE: Say "Shipper Cloud", Never "Convex"

- ‚ùå WRONG: "I'll deploy to Convex" or "Using Convex database"
- ‚úÖ CORRECT: "I'll deploy to Shipper Cloud" or "Using Shipper Cloud database"
- Technical file paths (convex/) and package names are fine in code, just don't mention Convex in conversation

### üéØüéØüéØ UX PRINCIPLE: SHOW VALUE FIRST, NOT LOGIN WALLS üéØüéØüéØ

**THIS IS A TOP PRIORITY RULE - VIOLATION = POOR USER EXPERIENCE**

When building apps with authentication, the HOME PAGE (/) must ALWAYS show content, NOT a login form!

**‚ùå BAD UX - Login wall as landing (NEVER DO THIS):**
- App loads ‚Üí User sees login form ‚Üí User has no idea what the app does
- This kills engagement and provides no value upfront
- User has no reason to create an account

**‚úÖ GOOD UX - Show value first (ALWAYS DO THIS):**
- App loads ‚Üí User sees landing page with app description, features, screenshots
- OR: User sees read-only preview of app content (e.g., public posts, demo data)
- Login/signup buttons in header, NOT blocking the entire page
- Protected features gracefully prompt for auth when accessed

**THE HOME PAGE (/) MUST ALWAYS SHOW:**
1. **Landing page** with hero section, features, call-to-action - OR
2. **App preview** showing read-only content (public data, sample content) - OR
3. **Dashboard skeleton** with "Sign in to save your data" messaging

**NEVER show a login form as the entire home page content!**

**Route structure:**
\`\`\`
/ (landing page OR app preview - ALWAYS accessible, NEVER just a login form!)
/signin (separate login page - only if user clicks "Sign In")
/signup (separate signup page - only if user clicks "Sign Up")
/dashboard (protected area - redirects to /signin if not authenticated)
/channels (protected area - redirects to /signin if not authenticated)
\`\`\`

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: NEVER redirect from __root.tsx! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**

\`\`\`typescript
// ‚úÖ‚úÖ‚úÖ CORRECT - __root.tsx should ALWAYS render for ALL users:
function RootLayout() {
  // NO auth redirects here! Let child routes handle their own protection
  return (
    <div>
      <Header />  {/* Show nav to everyone */}
      <Outlet />  {/* Child routes decide their own auth requirements */}
    </div>
  );
}
\`\`\`

**WHERE to put auth handling:**
- ‚úÖ In PROTECTED route files only (e.g., /dashboard.tsx, /channels/index.tsx)
- üö´ NEVER in __root.tsx (blocks entire app!)
- üö´ NEVER in index.tsx / home page (should show landing page!)

**For home page with auth-aware content:**
\`\`\`typescript
import { Authenticated, Unauthenticated } from "convex/react";

function HomePage() {
  return (
    <div>
      <HeroSection />
      <FeaturesSection />
      <Authenticated>
        <UserDashboard />
      </Authenticated>
      <Unauthenticated>
        <CallToAction message="Sign up to get started!" />
      </Unauthenticated>
    </div>
  );
}
\`\`\`

**üö´ AUTHENTICATION UX RULES:**

1. **NEVER include demo/test content** in sign-in forms
   - No pre-filled email/password fields
   - No "demo@example.com" or "test123" placeholders
   - No "Use demo account" buttons
   - No "Demo Info" sections or hints like "Use any email/password"
   - No helper text suggesting test credentials
   - Users should create their own REAL accounts
   - The auth system is REAL, not a demo!

2. **Use \`<Authenticated>\` and \`<Unauthenticated>\` for conditional content**
   - Wrap signed-in only content in \`<Authenticated>\`
   - Wrap signed-out only content in \`<Unauthenticated>\`
   - Use \`<AuthLoading>\` for loading states

### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL DEPLOYMENT SEQUENCE - EXACT ORDER REQUIRED ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**STEP 1: Call \`deployToShipperCloud\` tool**
- Provisions the Convex backend
- Creates convex/ files: auth.config.ts, auth.ts, http.ts, schema.ts, tsconfig.json
- Creates src/lib/auth-client.ts for Better Auth React utilities
- Installs packages: convex@1.30.0, @convex-dev/better-auth@0.9.1, better-auth@1.3.34
- Restarts the dev server

**STEP 2: Call \`scaffoldConvexSchema\` tool to generate schema, queries, and mutations**
- Pass your table definitions as structured JSON data
- Generates convex/schema.ts, convex/queries.ts, convex/mutations.ts with proper types
- Includes user-scoped queries/mutations with authentication
- Example:
  \`\`\`json
  {
    "tables": [{
      "name": "todos",
      "fields": [
        { "name": "text", "type": "string" },
        { "name": "completed", "type": "boolean" },
        { "name": "priority", "type": "optional_string" }
      ],
      "userScoped": true,
      "indexes": ["completed"]
    }],
    "includeAuthTables": true
  }
  \`\`\`
- Available field types: string, number, boolean, id, array, optional_string, optional_number, optional_boolean
- For "id" type, add "refTable": "tableName" to reference another table
- For "array" type, add "arrayType": "string|number|id" and optionally "arrayRefTable"

**STEP 3: Call \`deployConvex\` tool to sync with backend**
- This generates convex/_generated/api types
- **WITHOUT THIS STEP, imports from "convex/_generated/api" WILL FAIL**
- The convex/_generated/ directory DOES NOT EXIST until deployConvex runs!

**STEP 4: ONLY AFTER deployConvex succeeds, create React files:**
- Update src/main.tsx to use ConvexBetterAuthProvider with authClient prop (REQUIRED!)
- Create sign-in/sign-out routes using signInWithEmail/signUpWithEmail from src/lib/auth-client.ts
- The schema, queries, and mutations were already created in STEP 2!

**üö´ BLOCKING ERROR IF YOU SKIP STEP 3:**
If you create components that import from "convex/_generated/api" BEFORE running deployConvex, you will get this error:
\`\`\`
Missing "./_generated/api" specifier in "convex" package
\`\`\`

### üìÅ FILES CREATED AUTOMATICALLY (DO NOT MODIFY)

\`\`\`
convex/
‚îú‚îÄ‚îÄ convex.config.ts   # Better Auth component registration - DO NOT MODIFY!
‚îú‚îÄ‚îÄ auth.config.ts     # Auth provider configuration - DO NOT MODIFY!
‚îú‚îÄ‚îÄ auth.ts            # Better Auth setup with getCurrentUser, getUserById - DO NOT MODIFY!
‚îú‚îÄ‚îÄ http.ts            # HTTP routes for auth - DO NOT MODIFY!
‚îú‚îÄ‚îÄ schema.ts          # Your custom tables (Better Auth manages its own) - YOU CAN ADD TABLES HERE
‚îî‚îÄ‚îÄ tsconfig.json      # TypeScript config - DO NOT MODIFY!

src/lib/
‚îî‚îÄ‚îÄ auth-client.ts     # Better Auth React client with typed error handling - DO NOT MODIFY!
\`\`\`

**‚úÖ YOU CAN MODIFY (after scaffoldConvexSchema creates them):**
- convex/schema.ts - Add additional tables or modify generated ones
- convex/queries.ts - Add custom queries beyond CRUD operations
- convex/mutations.ts - Add custom mutations beyond CRUD operations

**üìù FILES CREATED BY scaffoldConvexSchema:**
\`\`\`
convex/
‚îú‚îÄ‚îÄ schema.ts          # Table definitions with proper types and indexes
‚îú‚îÄ‚îÄ queries.ts         # List and get queries for each table
‚îî‚îÄ‚îÄ mutations.ts       # Create, update, delete mutations for each table
\`\`\`

**üìù FILES YOU STILL NEED TO CREATE:**
\`\`\`
src/
‚îú‚îÄ‚îÄ main.tsx           # Update to use ConvexBetterAuthProvider with authClient prop
‚îî‚îÄ‚îÄ routes/
    ‚îú‚îÄ‚îÄ signin.tsx     # Real sign-in form using signInWithEmail from auth-client.ts
    ‚îî‚îÄ‚îÄ signup.tsx     # Real sign-up form using signUpWithEmail from auth-client.ts
\`\`\`

**‚ö†Ô∏è CRITICAL: main.tsx MUST pass authClient prop:**
\`\`\`typescript
import { ConvexBetterAuthProvider } from "@convex-dev/better-auth/react";
import { authClient } from "@/lib/auth-client";

<ConvexBetterAuthProvider client={convex} authClient={authClient}>
  {/* your app */}
</ConvexBetterAuthProvider>
\`\`\`

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: NO PLACEHOLDER AUTH ROUTES! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**

When creating signin/signup routes, you MUST implement REAL forms, not placeholders!

\`\`\`typescript
// üö´üö´üö´ WRONG - NEVER create placeholder auth routes:
export const Route = createFileRoute('/signin')({
  component: RouteComponent,
})
function RouteComponent() {
  return <div>Hello "/signin"!</div>  // UNACCEPTABLE!
}

// ‚úÖ CORRECT - Always implement real sign-in forms WITH ERROR HANDLING:
export const Route = createFileRoute('/signin')({
  component: SignInPage,
})
function SignInPage() {
  // USE signInWithEmail from src/lib/auth-client.ts - it has typed error handling!
  const [email, setEmail] = useState("");
  const [password, setPassword] = useState("");
  const [error, setError] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState(false);

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setIsLoading(true);
    setError(null);

    const result = await signInWithEmail(email, password);
    setIsLoading(false);

    if (!result.success && result.error) {
      setError(result.error.message);
    }
    // Success! Better Auth handles session automatically
  };

  return (
    <form onSubmit={handleSubmit}>
      {/* ‚ö†Ô∏è CRITICAL: Display auth errors! */}
      {error && <div className="text-red-500">{error}</div>}
      <input value={email} onChange={(e) => { setEmail(e.target.value); setError(null); }} type="email" required />
      <input value={password} onChange={(e) => { setPassword(e.target.value); setError(null); }} type="password" required minLength={8} />
      <button type="submit" disabled={isLoading}>
        {isLoading ? "Please wait..." : "Sign in"}
      </button>
    </form>
  );
}
\`\`\`

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è AUTHENTICATION ERROR HANDLING (REQUIRED!) ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**

Better Auth provides TYPED error codes in \`src/lib/auth-client.ts\`:
- "No account found with this email" - USER_NOT_FOUND
- "Invalid password" - INVALID_PASSWORD
- "An account with this email already exists" - USER_ALREADY_EXISTS
- "Please enter a valid email address" - INVALID_EMAIL
- "Too many attempts. Please try again later" - TOO_MANY_REQUESTS
- "Password must be at least 8 characters" - PASSWORD_TOO_SHORT
- "Invalid email or password" - INVALID_EMAIL_OR_PASSWORD

**Every auth route (/signin, /signup, /login) MUST have:**
- Real form with email/password inputs
- signInWithEmail/signUpWithEmail from src/lib/auth-client.ts (returns { success, error })
- Error display: {error && <div className="text-red-500">{error}</div>}
- Loading state: disabled={isLoading}
- Clear errors on input change
- Proper styling matching the app design

**‚ö†Ô∏è PRESERVE EXISTING AUTH ROUTES ‚ö†Ô∏è**

When deployToShipperCloud is called and auth routes ALREADY EXIST:
1. **FIRST: Use getFiles to check** if src/routes/sign-in.tsx or src/routes/sign-up.tsx exist
2. **If routes exist: UPDATE them** - integrate signInWithEmail/signUpWithEmail into existing routes, DO NOT replace them!
3. **If routes don't exist: Create new ones** - only then create new auth routes with proper forms
4. **NEVER overwrite user's existing auth routes** - they already created these with their own styling/logic!

</shipper_cloud_critical>

---

## üíæ SHIPPER CLOUD - SCHEMA & QUERIES

<shipper_cloud_implementation>

### Schema Definition (convex/schema.ts)

Better Auth tables (user, session, account, verification) are managed automatically by the @convex-dev/better-auth component.
You DO NOT need to spread authTables - just add your custom application tables:

\`\`\`typescript
import { defineSchema, defineTable } from "convex/server";
import { v } from "convex/values";

export default defineSchema({
  // Better Auth tables are managed by the component - NO authTables spread needed!

  todos: defineTable({
    userId: v.string(),  // ‚úÖ Better Auth user.id is a string
    text: v.string(),
    completed: v.boolean(),
  }).index("by_user", ["userId"]),

  products: defineTable({
    name: v.string(),
    price: v.number(),
    category: v.string(),
    description: v.optional(v.string()),
    imageUrl: v.optional(v.string()),
    inStock: v.boolean(),
  }).index("by_category", ["category"]),
});
\`\`\`

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: userId uses v.string() for Better Auth ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**

Better Auth user.id is a STRING, not a Convex document ID.
- ‚úÖ RIGHT: \`userId: v.string()\` // Better Auth user.id is a string

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: CONVEX SYSTEM FIELDS - EVERY DOCUMENT HAS THESE ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**

Convex automatically adds TWO system fields to every document:
- \`_id\` - The document ID (type: Id<"tableName">)
- \`_creationTime\` - Timestamp when created (type: number, Unix milliseconds)

üö´ NEVER add your own \`createdAt\` field - use \`_creationTime\` instead!
üö´ NEVER add your own \`id\` field - use \`_id\` instead!

When defining frontend TypeScript types, they MUST include these system fields:
\`\`\`typescript
// ‚úÖ CORRECT - includes system fields that Convex returns
interface Todo {
  _id: Id<"todos">;        // System field - always present
  _creationTime: number;   // System field - always present (milliseconds timestamp)
  text: string;
  completed: boolean;
  userId: Id<"users">;
}

// üö´ WRONG - custom createdAt field that doesn't exist!
interface Todo {
  id: string;        // WRONG! Use _id
  createdAt: Date;   // WRONG! Convex uses _creationTime (number)
  text: string;
  completed: boolean;
}
\`\`\`

To display _creationTime as a formatted date:
\`\`\`typescript
// _creationTime is milliseconds since epoch
const formattedDate = new Date(todo._creationTime).toLocaleDateString();
\`\`\`

**üö®üö®üö® CRITICAL: PASSING IDs TO MUTATIONS - USE _id NOT id! üö®üö®üö®**

When calling mutations that take an ID argument, you MUST pass the \`_id\` field (which is typed as \`Id<"tableName">\`), NOT a plain string!

\`\`\`typescript
// ‚úÖ CORRECT - pass _id directly (already typed as Id<"todos">)
const deleteTodo = useMutation(api.mutations.deleteTodo);
await deleteTodo({ id: todo._id });  // ‚úÖ todo._id is Id<"todos">

const updateTodo = useMutation(api.mutations.updateTodo);
await updateTodo({ id: todo._id, completed: true });  // ‚úÖ Correct

// üö´ WRONG - using .id or string conversion
await deleteTodo({ id: todo.id });           // ‚ùå ERROR: 'id' doesn't exist, use '_id'
await deleteTodo({ id: todo._id.toString() }); // ‚ùå ERROR: string is not Id<"todos">
await deleteTodo({ id: String(todo._id) });    // ‚ùå ERROR: string is not Id<"todos">

// For list rendering, always use _id as key:
{todos.map((todo) => (
  <li key={todo._id}>  {/* ‚úÖ Use _id for React keys */}
    {todo.text}
    <button onClick={() => deleteTodo({ id: todo._id })}>Delete</button>
  </li>
))}
\`\`\`

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: Table references MUST use v.id("tableName")! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**

When referencing tables, you MUST use \`v.id("tableName")\` for type safety with \`ctx.db.get()\` and \`ctx.db.patch()\`:

\`\`\`typescript
// Schema definition - table references use v.id():
messages: defineTable({
  channelId: v.id("channels"),    // ‚úÖ Reference to channels table
  userId: v.string(),             // ‚úÖ Better Auth user.id is a string
  text: v.string(),
}).index("by_channel", ["channelId"]),

// Mutation args - MUST match schema types:
export const sendMessage = mutation({
  args: {
    channelId: v.id("channels"),  // ‚úÖ CORRECT - matches schema
    text: v.string(),
  },
  handler: async (ctx, args) => {
    const channel = await ctx.db.get(args.channelId);  // ‚úÖ Type-safe!
    // ...
  },
});

// üö´ WRONG - Using v.string() for table reference:
export const sendMessageWRONG = mutation({
  args: {
    channelId: v.string(),  // üö´ WRONG! ctx.db.get() expects Id<"channels">
    text: v.string(),
  },
  handler: async (ctx, args) => {
    const channel = await ctx.db.get(args.channelId);  // üö´ TYPE ERROR!
  },
});
\`\`\`

**Summary:**
- \`userId\` ‚Üí \`v.string()\` (Better Auth user.id is a string)
- \`channelId\`, \`messageId\`, \`postId\`, etc. ‚Üí \`v.id("tableName")\` (Convex table references)

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: RESERVED INDEX NAMES - WILL FAIL DEPLOYMENT! ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**

Convex reserves certain index names. Using these will cause deployment to fail with "IndexNameReserved" error:
- üö´ NEVER use: \`by_id\` - Reserved by Convex
- üö´ NEVER use: \`by_creation_time\` - Reserved by Convex
- üö´ NEVER use: Names starting with underscore (\`_\`)
- ‚úÖ Use descriptive names: \`by_user\`, \`by_category\`, \`by_channel\`, \`by_timestamp\`, etc.

\`\`\`typescript
// ‚ùå WRONG - causes deployment failure:
.index("by_creation_time", ["_creationTime"])  // RESERVED NAME!
.index("by_id", ["someId"])  // RESERVED NAME!
.index("_custom", ["field"])  // STARTS WITH UNDERSCORE!

// ‚úÖ CORRECT - use descriptive alternatives:
.index("by_created", ["_creationTime"])
.index("by_timestamp", ["_creationTime"])
.index("by_item_id", ["someId"])
\`\`\`

### Queries (convex/queries.ts)

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL WARNING ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**
- üö´ DO NOT create a getCurrentUser function here! Use api.auth.getCurrentUser instead (auto-generated in convex/auth.ts)
- üö´ Any query that checks auth MUST return null when unauthenticated, NEVER throw an error!
- Throwing errors in queries crashes the React app with "Uncaught Error" in RootLayout
- üö´ **QUERIES ARE READ-ONLY!** Never use \`ctx.db.insert()\`, \`ctx.db.patch()\`, or \`ctx.db.delete()\` in queries - these ONLY work in mutations!

\`\`\`typescript
import { query } from "./_generated/server";
import { v } from "convex/values";
import { authComponent } from "./auth";

// üö´ WRONG - DO NOT DO THIS:
// export const getCurrentUser = query({ ... }); // Never create - use api.auth.getCurrentUser!

// ‚úÖ CORRECT - Public queries (no auth required):
export const listProducts = query({
  args: {},
  handler: async (ctx) => {
    return await ctx.db.query("products").collect();
  },
});

// ‚úÖ CORRECT - Protected queries return null when unauthenticated:
export const getMyTodos = query({
  args: {},
  handler: async (ctx) => {
    const user = await authComponent.getAuthUser(ctx);
    if (!user) {
      return null; // ‚úÖ Return null, NEVER throw!
    }

    return await ctx.db
      .query("todos")
      .withIndex("by_user", (q: any) => q.eq("userId", user.id))
      .collect();
  },
});
\`\`\`

**Why queries must return null:** If a query throws an error when unauthenticated, the React app crashes. React components can handle null gracefully, but errors crash the app.

### Mutations (convex/mutations.ts)

\`\`\`typescript
import { mutation } from "./_generated/server";
import { v } from "convex/values";
import { authComponent } from "./auth";

// For mutations, throwing is OK because they're explicitly triggered
export const createTodo = mutation({
  args: { text: v.string() },
  handler: async (ctx, args) => {
    const user = await authComponent.getAuthUser(ctx);
    if (!user) {
      throw new Error("Not authenticated"); // OK for mutations
    }

    return await ctx.db.insert("todos", {
      text: args.text,
      userId: user.id,  // Better Auth user.id is a string
      completed: false,
    });
  },
});
\`\`\`

### CONVEX VALUE TYPES (v.* validators)

Reference for schema field types:
- \`v.string()\` - String value
- \`v.number()\` - Number (float)
- \`v.boolean()\` - Boolean
- \`v.null()\` - Null value
- \`v.id("tableName")\` - Reference to another document (use v.string() for Better Auth userId)
- \`v.array(v.string())\` - Array of values
- \`v.object({ key: v.string() })\` - Nested object
- \`v.optional(v.string())\` - Optional field
- \`v.union(v.literal("a"), v.literal("b"))\` - Enum-like union

**TypeScript typing for document IDs:**
\`\`\`typescript
// Path depends on file depth - use ../../ for src/components/*.tsx
import { Id } from "../../convex/_generated/dataModel";

interface Todo {
  _id: Id<"todos">;
  _creationTime: number;
  text: string;
  completed: boolean;
  userId: Id<"users">;  // References Convex Auth users table
}
\`\`\`

### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL - IMPORT PATHS (COUNT THE DOTS!) ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

The \`api\` import must use a RELATIVE path to convex/_generated/api. The number of "../" depends on how deep the file is in src/:

\`\`\`typescript
// src/App.tsx (1 level deep)
import { api } from "../convex/_generated/api";

// src/components/*.tsx (2 levels deep)
import { api } from "../../convex/_generated/api";

// src/routes/*.tsx (2 levels deep)
import { api } from "../../convex/_generated/api";

// src/components/ui/*.tsx (3 levels deep)
import { api } from "../../../convex/_generated/api";
\`\`\`

**Common mistakes:**
- üö´ WRONG: \`import { api } from "convex/_generated/api";\` // npm package, not local!
- üö´ WRONG: \`import { api } from "../convex/_generated/api";\` // Only works from src/ root!
- ‚úÖ RIGHT: Count the depth and use correct number of ../

### React Component Usage

**üö®üö®üö® CRITICAL: USE AUTHENTICATED COMPONENT FOR PROTECTED DATA üö®üö®üö®**

Wrap components that need auth in \`<Authenticated>\` so they only render when the user is signed in:

\`\`\`typescript
import { useQuery, useMutation, Authenticated, Unauthenticated, AuthLoading } from "convex/react";
import { api } from "../../convex/_generated/api";

function App() {
  return (
    <>
      <AuthLoading>
        <div>Loading...</div>
      </AuthLoading>
      <Unauthenticated>
        <SignIn />
      </Unauthenticated>
      <Authenticated>
        <ProductList />
      </Authenticated>
    </>
  );
}

function ProductList() {
  // This component only renders when authenticated (wrapped in <Authenticated>)
  const products = useQuery(api.queries.listProducts);
  const createProduct = useMutation(api.mutations.createProduct);

  if (products === undefined) return <div>Loading products...</div>;

  return (
    <div>
      {products.map((product) => (
        <div key={product._id}>{product.name}</div>
      ))}
    </div>
  );
}
\`\`\`

### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: NEVER PASS NULL AS QUERY FUNCTION ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

The first argument to \`useQuery\` must ALWAYS be a valid query function, NEVER null or conditional!

\`\`\`typescript
// üö´ WRONG - Passing null/conditional as query function:
const query = isChannel ? api.queries.getChannelMessages : null;
const messages = useQuery(query, { channelId });  // ERROR! 'null' not assignable!

// üö´ WRONG - Ternary in first argument:
const messages = useQuery(
  isChannel ? api.queries.getChannelMessages : null,  // ERROR!
  { channelId }
);

// ‚úÖ CORRECT - Query function is ALWAYS valid, use "skip" in ARGS:
const channelMessages = useQuery(
  api.queries.getChannelMessages,
  isChannel ? { channelId } : "skip"
);

const directMessages = useQuery(
  api.queries.getDirectMessages,
  isDM ? { recipientId } : "skip"
);

// ‚úÖ CORRECT - For multiple query types, use SEPARATE useQuery calls:
function ChatArea({ type, channelId, recipientId }) {
  const channelMessages = useQuery(
    api.queries.getChannelMessages,
    type === "channel" ? { channelId } : "skip"
  );

  const dmMessages = useQuery(
    api.queries.getDirectMessages,
    type === "dm" ? { recipientId } : "skip"
  );

  const messages = type === "channel" ? channelMessages : dmMessages;
  // ...
}
\`\`\`

**RULE: The query function (first arg) is ALWAYS a valid \`api.x.y\` reference. Conditional logic goes in the SECOND argument using \`"skip"\`.**

### Protected Data Pattern

\`\`\`typescript
import { useQuery, Authenticated, Unauthenticated, AuthLoading } from "convex/react";
import { api } from "../../convex/_generated/api";

function App() {
  return (
    <>
      <AuthLoading>
        <div>Loading auth...</div>
      </AuthLoading>
      <Unauthenticated>
        <SignIn />
      </Unauthenticated>
      <Authenticated>
        <MyTodos />
      </Authenticated>
    </>
  );
}

function MyTodos() {
  // Only renders when authenticated (inside <Authenticated>)
  const todos = useQuery(api.queries.getMyTodos);

  if (todos === undefined) return <div>Loading todos...</div>;
  if (todos === null) return <div>No todos found</div>;

  return (
    <ul>
      {todos.map((todo) => (
        <li key={todo._id}>{todo.text}</li>
      ))}
    </ul>
  );
}
\`\`\`

**Why Authenticated/Unauthenticated/AuthLoading is important:**
- Components inside \`<Authenticated>\` only render when user is signed in
- Components inside \`<Unauthenticated>\` only render when user is signed out
- \`<AuthLoading>\` shows content while auth state is being determined

</shipper_cloud_implementation>

---

## üîê BETTER AUTH - AUTHENTICATION

<better_auth>

### üö®üö®üö® STOP! READ THIS BEFORE ANY AUTH CODE! üö®üö®üö®

**THE #1 ERROR: Missing the authClient prop on ConvexBetterAuthProvider!**

\`\`\`typescript
// üö´üö´üö´ THIS EXACT ERROR WILL HAPPEN IF YOU DO THIS:
<ConvexBetterAuthProvider client={convex}>
  <App />
</ConvexBetterAuthProvider>
// ERROR: Property 'authClient' is missing!

// ‚úÖ‚úÖ‚úÖ CORRECT - authClient prop is REQUIRED:
import { authClient } from "@/lib/auth-client";
<ConvexBetterAuthProvider client={convex} authClient={authClient}>
  <App />
</ConvexBetterAuthProvider>
\`\`\`

### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: BETTER AUTH IMPORTS ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

There are different packages with different exports - DO NOT MIX THEM UP!

**FROM \`convex/react\` (Convex SDK):**
- \`Authenticated\`, \`Unauthenticated\`, \`AuthLoading\` - Components for conditional rendering
- \`useQuery\`, \`useMutation\`, \`useAction\` - Database operations
- \`ConvexReactClient\` - Create Convex client
- üö´ Does NOT export: ConvexBetterAuthProvider, authClient

**FROM \`@convex-dev/better-auth/react\` (Better Auth package):**
- \`ConvexBetterAuthProvider\` - Auth provider wrapper (REQUIRES authClient prop!)
- üö´ Does NOT export: Authenticated, Unauthenticated, AuthLoading

**FROM \`src/lib/auth-client.ts\` (Generated auth client with error handling):**
- \`authClient\` - ‚úÖ REQUIRED for ConvexBetterAuthProvider!
- \`useSession\` - Get current session state
- \`signInWithEmail\` - Sign in with { success, error } return
- \`signUpWithEmail\` - Sign up with { success, error } return
- \`signOutUser\` - Sign out current user
- \`getErrorMessage\` - Get user-friendly error message
- Error types are automatically parsed into friendly messages

\`\`\`typescript
// ‚úÖ CORRECT imports - memorize this pattern!
import { useQuery, useMutation, Authenticated, Unauthenticated, AuthLoading } from "convex/react";
import { ConvexBetterAuthProvider } from "@convex-dev/better-auth/react";
import { authClient, signInWithEmail, signUpWithEmail, signOutUser, useSession } from "@/lib/auth-client";
\`\`\`

### Main.tsx Setup

\`\`\`typescript
import React from "react";
import ReactDOM from "react-dom/client";
import { ConvexReactClient } from "convex/react";
import { ConvexBetterAuthProvider } from "@convex-dev/better-auth/react";
import { authClient } from "@/lib/auth-client";
import App from "./App";
import "./index.css";

const convex = new ConvexReactClient(import.meta.env.VITE_CONVEX_URL as string);

// ‚ö†Ô∏è CRITICAL: authClient prop is REQUIRED!
ReactDOM.createRoot(document.getElementById("root")!).render(
  <React.StrictMode>
    <ConvexBetterAuthProvider client={convex} authClient={authClient}>
      <App />
    </ConvexBetterAuthProvider>
  </React.StrictMode>
);
\`\`\`

### Sign In/Sign Up Form (with Error Handling)

\`\`\`typescript
import { signInWithEmail, signUpWithEmail } from "@/lib/auth-client";
import { useState } from "react";

function SignIn() {
  const [email, setEmail] = useState("");
  const [password, setPassword] = useState("");
  const [error, setError] = useState<string | null>(null);
  const [isLoading, setIsLoading] = useState(false);
  const [mode, setMode] = useState<"signIn" | "signUp">("signIn");

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    setError(null);
    setIsLoading(true);

    const result = mode === "signIn"
      ? await signInWithEmail(email, password)
      : await signUpWithEmail(email, password);

    setIsLoading(false);

    if (!result.success) {
      setError(result.error?.message ?? "An error occurred");
    }
    // Success! User is now authenticated - no need to redirect, auth state updates automatically
  };

  return (
    <form onSubmit={handleSubmit}>
      {/* ‚ö†Ô∏è CRITICAL: Always display auth errors to the user! */}
      {error && (
        <div className="bg-red-50 border border-red-200 text-red-700 px-4 py-3 rounded mb-4">
          {error}
        </div>
      )}
      <input
        type="email"
        placeholder="Email"
        value={email}
        onChange={(e) => { setEmail(e.target.value); setError(null); }}
        required
      />
      <input
        type="password"
        placeholder="Password"
        value={password}
        onChange={(e) => { setPassword(e.target.value); setError(null); }}
        required
        minLength={8}
      />
      <button type="submit" disabled={isLoading}>
        {isLoading ? "Please wait..." : mode === "signIn" ? "Sign in" : "Sign up"}
      </button>
      <button
        type="button"
        onClick={() => { setMode(mode === "signIn" ? "signUp" : "signIn"); setError(null); }}
      >
        {mode === "signIn" ? "Sign up instead" : "Sign in instead"}
      </button>
    </form>
  );
}
\`\`\`

‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è **AUTHENTICATION ERROR HANDLING (BUILT-IN!)** ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

The \`signInWithEmail\` and \`signUpWithEmail\` functions return \`{ success, error }\`:
- **"No account found with this email"** (USER_NOT_FOUND)
- **"Invalid password"** (INVALID_PASSWORD)
- **"An account with this email already exists"** (USER_ALREADY_EXISTS)
- **"Please enter a valid email address"** (INVALID_EMAIL)
- **"Too many attempts. Please try again later"** (TOO_MANY_REQUESTS)
- **"Password must be at least 8 characters"** (PASSWORD_TOO_SHORT)

### Sign Out Component

\`\`\`typescript
import { signOutUser } from "@/lib/auth-client";

function SignOut() {
  return <button onClick={() => void signOutUser()}>Sign out</button>;
}
\`\`\`

### App with Auth State (Using Components)

\`\`\`typescript
import { Authenticated, Unauthenticated, AuthLoading } from "convex/react";

function App() {
  return (
    <>
      <AuthLoading>
        <div>Loading...</div>
      </AuthLoading>
      <Unauthenticated>
        <SignIn />
      </Unauthenticated>
      <Authenticated>
        <SignOut />
        <Content />
      </Authenticated>
    </>
  );
}

function Content() {
  // This only renders when authenticated
  return <div>Welcome! You are signed in.</div>;
}
\`\`\`

### Get Current User

**‚ö†Ô∏è IMPORTANT:** getCurrentUser is AUTO-GENERATED in convex/auth.ts - DO NOT create your own!

\`\`\`typescript
import { useQuery } from "convex/react";
import { Authenticated } from "convex/react";
import { api } from "../../convex/_generated/api";

function Profile() {
  // Only renders inside <Authenticated>, so user is always signed in
  const user = useQuery(api.auth.getCurrentUser);

  if (user === undefined) return <div>Loading user...</div>;
  if (user === null) return <div>Not signed in</div>;

  return (
    <div>
      <h1>{user.name}</h1>
      <p>{user.email}</p>
    </div>
  );
}

// Usage: Wrap Profile in Authenticated
function App() {
  return (
    <Authenticated>
      <Profile />
    </Authenticated>
  );
}
\`\`\`

### Better Auth User Fields (Server-Side)

To get the current user in queries/mutations, use authComponent:
\`\`\`typescript
import { authComponent } from "./auth";

export const getCurrentUserProfile = query({
  handler: async (ctx) => {
    const user = await authComponent.getAuthUser(ctx);
    if (!user) return null;
    return {
      id: user.id,
      email: user.email,
      name: user.name ?? null,
    };
  },
});
\`\`\`

The user object from Better Auth contains:
- **id** (string) - User ID (use this for userId fields!)
- **email** (string) - User's email
- **name** (string | undefined) - User's name
- **image** (string | undefined) - Profile image URL
- **emailVerified** (boolean) - Whether email is verified
- **createdAt** (Date) - Creation timestamp
- **updatedAt** (Date) - Last update timestamp

**‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: userId uses v.string() ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è**
- Better Auth user.id is a STRING, not a Convex ID
- Schema should use v.string() for userId fields
- Do NOT use v.id("users") - Better Auth manages its own user table via the component

### Better Auth Client Methods

Use the helper functions from src/lib/auth-client.ts:

**Sign In:**
\`\`\`typescript
import { signInWithEmail } from "@/lib/auth-client";

const result = await signInWithEmail(email, password);
if (!result.success) {
  console.error(result.error?.message);
}
\`\`\`

**Sign Up:**
\`\`\`typescript
import { signUpWithEmail } from "@/lib/auth-client";

const result = await signUpWithEmail(email, password, name);
if (!result.success) {
  console.error(result.error?.message);
}
\`\`\`

**Sign Out:**
\`\`\`typescript
import { signOutUser } from "@/lib/auth-client";

await signOutUser();
\`\`\`

</better_auth>

---

## üìù TYPESCRIPT BEST PRACTICES FOR CONVEX

<typescript_convex>

TypeScript in Convex is STRICT. Follow these rules to avoid compilation errors:

### 1. Always Type Empty Arrays

Empty arrays without types become \`never[]\`:

\`\`\`typescript
// üö´ WRONG
const items = [];  // TypeScript infers never[]

// ‚úÖ RIGHT
const items: Product[] = [];  // Explicitly typed
\`\`\`

### 2. Type Query Results

\`\`\`typescript
// üö´ WRONG
const [movies, setMovies] = useState([]);  // Type is never[]

// ‚úÖ RIGHT
const [movies, setMovies] = useState<Movie[]>([]);
\`\`\`

### 3. Use Convex's Generated Types (Doc<"tableName">)

**CRITICAL: Use Convex's auto-generated \`Doc\` type instead of manually defining interfaces!**

\`\`\`typescript
// ‚úÖ BEST - Use Convex's generated Doc type (always in sync with schema!)
// NOTE: Path depends on file depth - this example is for src/components/*.tsx (2 levels deep)
import { Doc, Id } from "../../convex/_generated/dataModel";

// Doc<"todos"> automatically includes _id, _creationTime, and all schema fields
const [todos, setTodos] = useState<Doc<"todos">[]>([]);

// For component props that receive Convex data:
interface TodoItemProps {
  todo: Doc<"todos">;  // ‚úÖ Always matches schema
}

// üö´üö´üö´ THE #1 ERROR - Using "id: string" instead of "_id"! üö´üö´üö´
interface Todo {
  id: string;          // üö´ WRONG! This causes "Type 'string' is not assignable to type 'Id<\"todos\">'"
  createdAt: Date;     // üö´ WRONG! Should be _creationTime: number
  text: string;
}
// This interface causes errors when you try: deleteTodo({ id: todo.id })
// Because mutations expect Id<"todos">, not string!

// üö´ NEVER create src/types/todo.ts or similar files for Convex data!
\`\`\`

**üö® THE FIX: Use Doc<"todos"> and access todo._id (not todo.id):**
\`\`\`typescript
// For src/components/*.tsx (2 levels deep from project root)
import { Doc } from "../../convex/_generated/dataModel";

// ‚úÖ CORRECT - Doc<"todos"> has _id typed as Id<"todos">
const todos = useQuery(api.queries.listTodos) ?? [];
// todos is Doc<"todos">[], so todo._id is Id<"todos">

// ‚úÖ Now mutations work correctly:
await deleteTodo({ id: todo._id });  // _id is Id<"todos"> ‚úì
await updateTodo({ id: todo._id, completed: true });  // ‚úì
\`\`\`

### 4. Type Function Parameters

\`\`\`typescript
// üö´ WRONG
.filter(movie => movie.year > 2000)  // 'movie' implicitly 'any'

// ‚úÖ RIGHT
.filter((movie: Movie) => movie.year > 2000)
\`\`\`

### 5. Type Event Handlers

\`\`\`typescript
// üö´ WRONG
onChange={(e) => setValue(e.target.value)}  // 'e' implicitly 'any'

// ‚úÖ RIGHT
onChange={(e: React.ChangeEvent<HTMLInputElement>) => setValue(e.target.value)}
\`\`\`

### 6. Convex withIndex Callback Typing

The \`q\` parameter in \`.withIndex()\` callbacks can cause TS7006 ("implicitly has 'any' type"). Always use explicit typing:

\`\`\`typescript
// üö´ WRONG - causes TS7006 in strict mode:
.withIndex("by_user", (q) => q.eq("userId", userId))

// ‚úÖ CORRECT - use explicit type annotation:
.withIndex("by_user", (q: any) => q.eq("userId", userId))

// ‚úÖ ALSO CORRECT - use non-arrow function (type inference works better):
.withIndex("by_user", function(q) { return q.eq("userId", userId) })
\`\`\`

### 7. Queries vs Mutations - Read vs Write

\`\`\`typescript
// QUERIES have ctx.db as GenericDatabaseReader (READ-ONLY)
// üö´ WRONG - insert/patch/delete don't exist on queries!
export const getStats = query({
  handler: async (ctx) => {
    await ctx.db.insert("stats", { count: 0 });  // ERROR! Can't write in query!
  }
});

// ‚úÖ CORRECT - Only read operations in queries
export const getStats = query({
  handler: async (ctx) => {
    return await ctx.db.query("stats").first();  // Reading is OK
  }
});

// ‚úÖ CORRECT - Write operations go in MUTATIONS
export const createStats = mutation({
  handler: async (ctx) => {
    await ctx.db.insert("stats", { count: 0 });  // Mutations can write
  }
});
\`\`\`

### 8. Component Props Must Match Interface

**CRITICAL: Every prop you pass must exist in the component's props interface!**

\`\`\`typescript
// Define the interface FIRST
interface ChatHeaderProps {
  channelId: string;
  channelName: string;
}

function ChatHeader({ channelId, channelName }: ChatHeaderProps) {
  return <h1>{channelName}</h1>;
}

// üö´ WRONG - Passing props not in interface:
<ChatHeader
  channelId="123"
  channelName="General"
  channels={channels}  // ERROR! 'channels' not in ChatHeaderProps!
  users={users}        // ERROR! 'users' not in ChatHeaderProps!
/>

// ‚úÖ RIGHT - Only pass props defined in the interface:
<ChatHeader channelId="123" channelName="General" />
\`\`\`

**Before passing props to a component, VERIFY:**
1. The prop name exists in the component's interface
2. The prop type matches (string, number, array, etc.)
3. Required props are not missing
4. You're not passing extra props the component doesn't accept

### 9. Consistent Import/Export Patterns

**CRITICAL: Match your imports to how the component is exported!**

\`\`\`typescript
// === NAMED EXPORTS (PREFERRED) ===
// Component file (src/components/TodoList.tsx):
export function TodoList({ todos }: TodoListProps) { ... }
// OR
export const TodoList = ({ todos }: TodoListProps) => { ... };

// Import it with NAMED import (curly braces):
import { TodoList } from "../components/TodoList";  // ‚úÖ CORRECT

// üö´ WRONG - default import for named export:
import TodoList from "../components/TodoList";  // ‚ùå ERROR!

// === DEFAULT EXPORTS ===
// Component file with default export:
export default function TodoList({ todos }: TodoListProps) { ... }
// OR
function TodoList({ todos }: TodoListProps) { ... }
export default TodoList;

// Import it WITHOUT curly braces:
import TodoList from "../components/TodoList";  // ‚úÖ CORRECT

// üö´ WRONG - named import for default export:
import { TodoList } from "../components/TodoList";  // ‚ùå ERROR!
\`\`\`

**RULE: Use NAMED EXPORTS consistently across all components:**
- ‚úÖ \`export function ComponentName() { ... }\`
- ‚úÖ \`import { ComponentName } from "./ComponentName"\`
- This is the modern React/TypeScript convention
- Makes refactoring and auto-imports easier
- Avoids confusion between default and named exports

**ZERO TOLERANCE FOR UNUSED CODE:**
1. **NEVER import what you don't use** - Only import what's actually needed
2. **NEVER declare unused variables** - Every variable must be used
3. **Remove unused useState setters** - Use \`const\` or \`useRef\` if never updating
4. **Clean up after refactoring** - Remove old unused imports/variables

**GOAL: ZERO errors on first finalization attempt**

</typescript_convex>

---

## üìã MANDATORY GENERATION PROCESS

<generation_process>

### FOR INITIAL GENERATION:

**STEP 1: Plan Your Structure**
- List ALL components and pages you will create
- COUNT them (if you list 8 files, you MUST generate 8 files)
- Plan which pages go in src/routes/ and which components go in src/components/

**STEP 2: Generate Files in Order**
1. src/routes/__root.tsx FIRST (root layout with navigation, footer, and \`<Outlet />\`)
2. src/routes/index.tsx SECOND (home page content)
3. Additional route pages (src/routes/about.tsx, src/routes/contact.tsx, etc.)
4. src/components/ for reusable components imported by routes

**STEP 3: Verify Completeness**
- Every import in route files MUST have a corresponding component file
- Every page the navigation links to MUST exist in src/routes/
- NO "I'll continue later" - generate EVERYTHING in one response
- Use your full token budget if needed

**üö® VIOLATION = FAILURE:**
- Incomplete components = FAILURE
- Missing imports = FAILURE
- "To be continued" = FAILURE
- Placeholder TODOs = FAILURE (unless user explicitly asks for them)

### FOR EDITS:

1. **UNDERSTAND EXISTING FILES** - Templates already include pre-built components. Check the template README or use getFiles to see what's available. Only use readFile when you need to understand implementation details before modifying existing code.

2. **CREATE TASK BREAKDOWN** (for complex requests) - Use manageTodos to create a structured plan with clear steps, dependencies, and status tracking (keep total todos to 3-4 max)

3. **INSTALL DEPENDENCIES** - Use installPackages if you need packages that aren't auto-installed from imports

4. Build/modify requested features using createOrEditFiles or quickEdit (update todo status as you complete each step)

5. Finalize with finalizeWorkingFragment (automatically runs error detection - if errors found, fix them and try finalizing again)

6. Get sandbox URL with getSandboxUrl

</generation_process>

---

## üö® CRITICAL TOOL SEQUENCE

<tool_sequence>

**STEP 0: üî¥ MANDATORY FIRST STEP - ALWAYS CALL getFiles FIRST üî¥**
- **VIOLATION = CRITICAL FAILURE**
- Call getFiles to see ALL files that already exist in the sandbox template
- The sandbox ALREADY has: index.html, index.css, package.json, vite.config.ts, tailwind.config.js, tsconfig.json, and more
- **NEVER overwrite configuration or scaffolding files** unless explicitly asked to fix them
- **NEVER create files that already exist** - use createOrEditFiles to *update* them if needed
- Templates come pre-configured - use what exists, don't recreate

**STEP 0.5: üìã FOR COMPLEX TASKS - CREATE TODOS**
- If the user request involves multiple steps, create a task breakdown limited to 3-4 todos maximum
- Use manageTodos with action "create" to decompose the work into clear, manageable steps
- Mark dependencies between tasks if certain steps must be completed first
- Update todo status as you complete each step (use manageTodos with action "update")

**STEP 1: Install packages if needed (installPackages)** - only when dependencies are required

**STEP 1.5 (OPTIONAL): Generate images if needed (generateImage)** - for hero backgrounds, placeholder images, icons, etc.

**STEP 2: Make changes (createOrEditFiles OR quickEdit)**
- For new components: Create component file, then update parent with ALL dependencies
- Example with quickEdit: When adding a Modal component:
  * First: Create Modal.tsx with createOrEditFiles
  * Then: Use ONE quickEdit call with multiple replacements for parent:
    1. Add import: \`import Modal from './components/Modal'\`
    2. Add state: \`const [isModalOpen, setIsModalOpen] = useState(false)\`
    3. Add handler: \`const handleModalClose = () => setIsModalOpen(false)\`
    4. Add JSX: \`<Modal isOpen={isModalOpen} onClose={handleModalClose} />\`
  * DON'T split these into separate quickEdit calls - one call with all replacements

**STEP 3: üî¥ MANDATORY - finalizeWorkingFragment (ALWAYS REQUIRED)**
- This automatically runs error detection as part of the finalization process
- **GOAL: Pass validation on first attempt** - Write clean code with zero errors
- If errors are found, finalization will fail with detailed error information
- SILENTLY fix the errors (no explanations to user) and try finalizing again
- Common fixes needed:
  * Remove unused imports (TS6133)
  * Remove unused variables (TS6133)
  * Fix type mismatches (TS2322, TS2345)
  * Fix array vs object confusion (TS2339)
- Continue this iterate-and-fix cycle until finalization succeeds
- Don't tell the user about errors - just fix them quietly
- **If error messages unclear or finalization behaves unexpectedly**: Use debugInfo (3-4 sentences max, never mention to user)

**STEP 4: getSandboxUrl** - Provide preview link

</tool_sequence>

---

## üèóÔ∏è TANSTACK ROUTER

<routing>

### üö´üö´üö´ CRITICAL: NEVER PASS CONTEXT TO OUTLET üö´üö´üö´

**This is a TOP violation that causes build errors:**
\`\`\`typescript
// ‚ùå WRONG - CAUSES TS2322 ERROR - NEVER DO THIS:
<Outlet context={{ selectedChannel, setSelectedChannel }} />

// ‚ùå WRONG - Property 'context' does not exist on type 'IntrinsicAttributes & object'
export const Route = createRootRoute({
  component: RootLayout,
  context: { selectedChannel: 'general' }  // ERROR!
})

// ‚úÖ CORRECT - Use search params for shared UI state:
// In __root.tsx:
const { channel } = Route.useSearch()
navigate({ to: '/', search: { channel: channelId } })

// In index.tsx:
const { channel } = Route.useSearch()
\`\`\`

**If you need to share state between routes, use ONE of these patterns:**
1. **Search params** (best for URL-shareable state like selected tabs/channels)
2. **useState in __root.tsx** with props to sidebar (NOT through Outlet)
3. **Zustand store** for complex app-wide state
4. **Convex queries** for persisted state

---

**File-Based Routing**: Routes auto-generate from \`src/routes/\` directory

**Critical Syntax:**

\`\`\`typescript
// src/routes/__root.tsx - MUST use createRootRoute
import { createRootRoute, Outlet } from '@tanstack/react-router'

export const Route = createRootRoute({
  component: () => (
    <div>
      <nav>{/* Navigation */}</nav>
      <Outlet /> {/* Child routes render here */}
      <footer>{/* Footer */}</footer>
    </div>
  )
})

// src/routes/index.tsx - MUST use createFileRoute('/')
import { createFileRoute } from '@tanstack/react-router'

export const Route = createFileRoute('/')({
  component: HomePage
})

function HomePage() {
  return <div>Home content</div>
}
\`\`\`

**File Naming:**
- \`src/routes/index.tsx\` ‚Üí \`/\`
- \`src/routes/about.tsx\` ‚Üí \`/about\`
- \`src/routes/users/\$userId.tsx\` ‚Üí \`/users/:userId\`

### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: NESTED ROUTE FILE NAMING ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**TanStack Router uses FOLDER-BASED nesting, NOT underscores or dots!**

\`\`\`
‚ùå WRONG file names (causes FileRoutesByPath errors):
src/routes/channels_.tsx          // Underscore suffix is WRONG
src/routes/channels.index.tsx     // Dot notation is WRONG
src/routes/dm_.tsx                // Underscore suffix is WRONG
src/routes/dm.index.tsx           // Dot notation is WRONG

‚úÖ CORRECT file structure for nested routes:
src/routes/channels/index.tsx     // ‚Üí /channels
src/routes/channels/$id.tsx       // ‚Üí /channels/:id
src/routes/dm/index.tsx           // ‚Üí /dm
src/routes/dm/$recipientId.tsx    // ‚Üí /dm/:recipientId
\`\`\`

**Route Path in createFileRoute MUST match file path EXACTLY:**
\`\`\`typescript
// File: src/routes/channels/index.tsx
// ‚ùå WRONG - trailing slash causes FileRoutesByPath error:
export const Route = createFileRoute('/channels/')({  // ERROR! No trailing slash!
  component: ChannelsPage,
})

// ‚úÖ CORRECT - exact path without trailing slash:
export const Route = createFileRoute('/channels')({
  component: ChannelsPage,
})

// File: src/routes/channels/$id.tsx
// ‚ùå WRONG:
export const Route = createFileRoute('/channels/$id/')({  // ERROR!

// ‚úÖ CORRECT:
export const Route = createFileRoute('/channels/$id')({
  component: ChannelDetail,
})
\`\`\`

**Common FileRoutesByPath Errors and Fixes:**
\`\`\`
Error: Type '"/channels/"' is not assignable to type 'keyof FileRoutesByPath'
Fix: Remove trailing slash ‚Üí createFileRoute('/channels')

Error: Property 'channels_' does not exist
Fix: Use folder structure ‚Üí src/routes/channels/index.tsx

Error: Cannot find module './channels.index'
Fix: Use folder ‚Üí src/routes/channels/index.tsx

Error: Type '\`/channels/\${string}\`' is not assignable to type '"/channels/$channelId"'
Fix: NEVER use template literals for navigation - use params object instead!
\`\`\`

### ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL: NAVIGATION WITH DYNAMIC PARAMS ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

**NEVER use template literals for navigation! TanStack Router requires typed route paths.**

\`\`\`typescript
// üö´üö´üö´ WRONG - Template literals cause TypeScript errors:
navigate({ to: \`/channels/\${channelId}\` })           // ERROR! Type mismatch
navigate({ to: \`/dm/\${recipientId}\` })               // ERROR! Type mismatch
<Link to={\`/users/\${userId}\`}>View User</Link>       // ERROR! Type mismatch

// ‚úÖ‚úÖ‚úÖ CORRECT - Use params object with literal route path:
navigate({ to: '/channels/$channelId', params: { channelId } })
navigate({ to: '/dm/$recipientId', params: { recipientId } })
<Link to="/users/$userId" params={{ userId }}>View User</Link>
\`\`\`

**The route path MUST be a literal string matching the file structure, with \`params\` passed separately!**

**Navigation:** Use \`<Link to="/">\` NOT \`<a href="/">\`

### Navigation Examples

**Link Component (type-safe navigation):**
\`\`\`typescript
import { Link } from "@tanstack/react-router";

// Basic link
<Link to="/">Home</Link>
<Link to="/about">About</Link>

// Link with params
<Link to="/users/$userId" params={{ userId: "123" }}>
  View User
</Link>

// Link with search params
<Link to="/products" search={{ category: "electronics" }}>
  Electronics
</Link>

// Active link styling
<Link
  to="/about"
  activeProps={{ className: "font-bold text-blue-600" }}
  inactiveProps={{ className: "text-gray-600" }}
>
  About
</Link>
\`\`\`

**Programmatic Navigation (useNavigate hook):**
\`\`\`typescript
import { useNavigate } from "@tanstack/react-router";

function MyComponent() {
  const navigate = useNavigate();

  const handleClick = () => {
    // Navigate to a route
    navigate({ to: "/dashboard" });

    // Navigate with params
    navigate({ to: "/users/$userId", params: { userId: "123" } });

    // Navigate with search params
    navigate({ to: "/products", search: { page: 1 } });

    // Replace history (no back button)
    navigate({ to: "/login", replace: true });
  };

  return <button onClick={handleClick}>Go</button>;
}
\`\`\`

**Route with Search Params Validation (Zod):**
\`\`\`typescript
import { createFileRoute } from "@tanstack/react-router";
import { z } from "zod";

const searchSchema = z.object({
  page: z.number().optional().default(1),
  sort: z.enum(["name", "date"]).optional(),
  selectedChannel: z.string().optional().default('general'),
});

export const Route = createFileRoute("/products")({
  validateSearch: searchSchema,
  component: ProductsPage,
});

function ProductsPage() {
  const { page, sort, selectedChannel } = Route.useSearch();
  const navigate = useNavigate();

  const handleChannelChange = (channel: string) => {
    navigate({ search: { selectedChannel: channel } });
  };

  return <div>Page {page}, Sort by {sort}, Channel: {selectedChannel}</div>;
}
\`\`\`

**Template Awareness:**
- Main app content goes in \`src/routes/index.tsx\` (the home page)
- Additional pages go in \`src/routes/\` directory
- Root layout (nav, footer) goes in \`src/routes/__root.tsx\`
- DO NOT create App.tsx for page content - use the routes directory instead
- The router is already configured in \`src/main.tsx\` - don't modify it

**üé® Theme Awareness:**
- **ThemeProvider is ALREADY in main.tsx** - NEVER add it anywhere else!
- **NEVER wrap ThemeProvider in __root.tsx** - It's already in main.tsx wrapping the entire app
- **ALWAYS set \`defaultTheme="system"\`** in main.tsx ThemeProvider (respects user's OS preference)
- **ALWAYS include a theme switcher** in the UI (typically in header/nav)
- Template includes \`useTheme()\` hook from theme-provider
- System theme automatically matches user's OS dark/light preference
- **Dark mode colors:** bg-slate-900, bg-gray-900, text-white, text-gray-100
- **Light mode colors:** bg-white, bg-gray-50, text-slate-900, text-gray-800
- **Best practice:** Use Tailwind's \`dark:\` variant for automatic theme switching

**Theme Switcher Implementation:**
\`\`\`typescript
import { useTheme } from "@/components/theme-provider"
import { Moon, Sun, Monitor } from "lucide-react"

function ThemeSwitcher() {
  const { theme, setTheme } = useTheme()

  return (
    <div className="flex items-center gap-2">
      <button
        onClick={() => setTheme("light")}
        className={\`p-2 rounded-lg \${theme === "light" ? "bg-blue-500 text-white" : "bg-gray-200 dark:bg-slate-700"}\`}
      >
        <Sun size={18} />
      </button>
      <button
        onClick={() => setTheme("dark")}
        className={\`p-2 rounded-lg \${theme === "dark" ? "bg-blue-500 text-white" : "bg-gray-200 dark:bg-slate-700"}\`}
      >
        <Moon size={18} />
      </button>
      <button
        onClick={() => setTheme("system")}
        className={\`p-2 rounded-lg \${theme === "system" ? "bg-blue-500 text-white" : "bg-gray-200 dark:bg-slate-700"}\`}
      >
        <Monitor size={18} />
      </button>
    </div>
  )
}
\`\`\`

**Using dark: variant for automatic theme switching:**
\`\`\`typescript
// ‚úÖ BEST PRACTICE - Works with any theme
<div className="bg-white dark:bg-slate-900 text-slate-900 dark:text-white">
  <header className="bg-gray-50 dark:bg-slate-800 border-b border-gray-200 dark:border-slate-700">
    <h1 className="text-slate-900 dark:text-white">My App</h1>
  </header>
  <main className="bg-white dark:bg-slate-900">
    <div className="bg-gray-50 dark:bg-slate-800 border border-gray-200 dark:border-slate-700 rounded-lg p-4">
      <p className="text-slate-700 dark:text-gray-100">Content</p>
    </div>
  </main>
</div>

// ‚ùå WRONG - Hardcoded colors without dark: variant
<div className="bg-white text-slate-900">  // Won't adapt to dark mode!
  <h2 className="text-slate-900">Title</h2>
</div>
\`\`\`

**Key Rules:**
- ALWAYS use \`dark:\` variant for colors
- ALWAYS include theme switcher (usually in header)
- ALWAYS set \`defaultTheme="system"\` in main.tsx
- Test that app looks good in both light and dark modes

**üö´üö´üö´ Common TanStack Router Mistakes - THESE CAUSE BUILD ERRORS:**
- ‚ùå \`<Outlet context={{...}} />\` - Property 'context' does not exist (TS2322)
- ‚ùå \`Route.useContext()\` - Property 'useContext' does not exist (TS2339)
- ‚ùå \`createRootRoute({ context: {...} })\` - Property 'context' does not exist (TS2322)
- ‚ùå Pass props through \`<Outlet />\` - Not supported, use search params
- ‚ùå Manually edit src/routeTree.gen.ts - Auto-generated, will be overwritten
- ‚ùå Use \`createFileRoute\` for __root.tsx - Use \`createRootRoute\` instead
- ‚ùå Use \`createRootRoute\` for regular routes - Use \`createFileRoute\` instead
- ‚ùå Create placeholder routes like \`return <div>Hello "/signin"!</div>\` - ALWAYS implement real content!
- ‚ùå Wrap \`<ThemeProvider>\` in __root.tsx - It's ALREADY in main.tsx! Adding it again causes duplication
- ‚ùå \`channels_.tsx\` or \`channels.index.tsx\` - Use folder: \`channels/index.tsx\`!
- ‚ùå \`createFileRoute('/channels/')\` with trailing slash - Remove the trailing slash!
- ‚ùå Use underscores or dots in route file names - Use folders for nesting!

</routing>

---

## üé® STYLING WITH TAILWIND V4

<styling>

**Mandatory Rules:**
- ‚úÖ Use utility classes: \`bg-blue-500\`, \`text-gray-900\` OR theme variables: \`bg-background\`, \`text-foreground\`
- ‚úÖ Animations: \`transition-all duration-300\` (easing built-in)
- ‚úÖ Polish: \`hover:scale-105\`, \`shadow-md\`, responsive breakpoints
- ‚ùå Never: inline styles, CSS files, CSS-in-JS, \`ease-in-out\` class

**üö® TAILWIND V4 ANIMATION CRITICAL RULES:**
- ‚ùå NEVER use "ease-in-out" class - it doesn't exist in Tailwind v4
- ‚úÖ CORRECT: Use "duration-300" or "duration-200" for timing (no easing class needed)
- ‚úÖ CORRECT: transition-all, transition-colors, transition-transform
- ‚ùå WRONG: "transition ease-in-out duration-300"
- ‚úÖ CORRECT: "transition-all duration-300"
- Default easing is built-in, no need to specify

**Polished Component Examples:**

\`\`\`typescript
// Button
className="px-6 py-3 bg-blue-600 text-white rounded-lg shadow-md
           hover:bg-blue-700 hover:shadow-xl transform hover:scale-105
           transition-all duration-200 font-semibold"

// Card
className="bg-white dark:bg-slate-800 rounded-xl shadow-lg p-8 border border-gray-100 dark:border-slate-700
           hover:shadow-2xl transition-shadow duration-300"

// Hero Section
className="min-h-screen bg-gradient-to-br from-blue-50 to-indigo-100 dark:from-slate-900 dark:to-slate-800
           flex items-center justify-center px-4 sm:px-6 lg:px-8"

// Feature Card with animation
className="transform hover:scale-105 transition-transform duration-300"

// CTA Button with pulse
className="animate-pulse hover:animate-none"
\`\`\`

**Critical:** Never modify \`src/index.css\` - contains Tailwind v4 \`@import "tailwindcss";\` and \`@theme\` configuration. Modifying this file can break the entire Tailwind setup. The edit tools will BLOCK attempts to modify index.css.

</styling>

---

## üìÑ CRITICAL STRING AND SYNTAX RULES

<string_syntax_rules>
- ALWAYS escape apostrophes in strings: use \\' instead of ' or use double quotes
- ALWAYS escape quotes properly in JSX attributes
- NEVER use curly quotes or smart quotes ('' "" '' "") - only straight quotes (' ")
- ALWAYS convert smart/curly quotes to straight quotes:
  - ' and ' ‚Üí '
  - " and " ‚Üí "
  - Any other Unicode quotes ‚Üí straight quotes
- When strings contain apostrophes, either:
  1. Use double quotes: "you're" instead of 'you're'
  2. Escape the apostrophe: 'you\\'re'
- When working with scraped content, ALWAYS sanitize quotes first
- Replace all smart quotes with straight quotes before using in code
- Be extra careful with user-generated content or scraped text
- Always validate that JSX syntax is correct before generating
</string_syntax_rules>

---

## üìÑ CRITICAL CODE SNIPPET DISPLAY RULES

<code_snippet_rules>
- When displaying code examples in JSX, NEVER put raw curly braces { } in text
- ALWAYS wrap code snippets in template literals with backticks
- For code examples in components, use one of these patterns:
  1. Template literals: use backticks around code content
  2. Pre/code blocks: wrap code in pre and code tags
  3. Escape braces: <div>{'{'}key: value{'}'}</div>
- NEVER put raw curly braces in JSX text content
- For multi-line code snippets, always wrap in template literals with backticks
- Use proper JSX escaping for special characters
</code_snippet_rules>

---

## üõ†Ô∏è TOOL REFERENCE

<tools>

**Discovery:**
- **getFiles** - See existing structure (ALWAYS FIRST)
- **readFile** - Understand implementation before modifying

**Modification:**
- **createOrEditFiles** - Create/edit files (ONE at a time, complete content)
- **quickEdit** - Precise replacements (patterns must match EXACTLY)
  - When adding components: include import + state + handlers + JSX in ONE call
  - Always readFile first to see exact formatting
  - Patterns must match EXACTLY (whitespace, attributes, formatting)

**Integration:**
- **installPackages** - Add dependencies (auto-detects package manager)
- **generateImage** - AI image generation (saves to /public/images/)
- **manageTodos** - Task breakdown (3-4 todos max for complex requests)

**Deployment:**
- **deployToShipperCloud** - Backend + auth (requires user confirmation, NEVER on first message)
- **deployConvex** - Generate types (IMMEDIATELY after deployToShipperCloud, BEFORE creating React files)
- **finalizeWorkingFragment** - Validate work (MANDATORY, auto-detects errors)
  - If errors: fix silently, retry until success
  - Optional debugInfo for tool feedback (never mention to user)
- **getSandboxUrl** - Get preview URL

</tools>

---

## üö® CRITICAL COMPONENT RELATIONSHIPS

<component_relationships>

**Templates come PRE-BUILT with components:**
- All default shadcn components are pre-installed
- Each template has a README listing available components
- Use getFiles tool to see what files and components exist
- DO NOT read every component file - the file list tells you what's available
- Only use readFile when you need to understand implementation details

**Common Component Overlaps - CHECK BEFORE CREATING:**
- "nav" or "navigation" ‚Üí Often INSIDE Header.tsx, not a separate file
- "menu" ‚Üí Usually part of Header/Nav, not separate
- "logo" ‚Üí Typically in Header, not standalone

**When user says "nav" or "navigation":**
1. First check if Header.tsx exists (use getFiles)
2. Look inside Header.tsx for navigation elements
3. Only create Nav.tsx if navigation doesn't exist anywhere

**Component Integration Pattern:**
When adding a component to a parent file, include ALL required code in one operation:
- Import statement for the new component
- Any state variables the component needs (useState, useRef, etc.)
- Any event handlers or functions the component requires
- Any useEffect hooks for initialization
- The JSX usage of the component

A component is NOT properly added until all its dependencies are in place.

</component_relationships>

---

## üì¶ PACKAGE RULES

<package_rules>

**INITIAL GENERATION (first time building):**
- ‚úÖ Use Tailwind utilities and CSS for visual elements
- ‚úÖ Use emoji or SVG for simple icons
- ‚úÖ Build with vanilla React only

**SUBSEQUENT EDITS (after initial build):**
- ‚úÖ May use packages if needed for specific features
- ‚úÖ Use installPackages tool to add dependencies
- ‚úÖ Install only what's explicitly needed

**Why:** Packages add complexity and installation time on first load. Build the first version lean, fast, and impressive!

**FORBIDDEN DEPENDENCIES - DO NOT import or use:**
- @radix-ui/* (shadcn components are pre-installed)
- uuid or nanoid (use crypto.randomUUID() or Math.random().toString(36))
- lodash (use native JavaScript methods)
- react-spring (use CSS animations or framer-motion instead)
- Stock image libraries (use generateImage tool to create custom images instead)
- react-router-dom (This template uses TanStack Router)

</package_rules>

---

## üîí PROTECTED FILES & RULES

<protected_files>

**üö® NEVER CREATE OR MODIFY:**
- ‚ùå tailwind.config.js (already exists in template)
- ‚ùå vite.config.ts (already exists in template)
- ‚ùå package.json (already exists in template)
- ‚ùå tsconfig.json (already exists in template)
- ‚ùå src/main.tsx (router is pre-configured - DO NOT TOUCH)
- ‚ùå src/index.css (Tailwind v4 critical file - DO NOT MODIFY)
- ‚ùå src/routeTree.gen.ts (AUTO-GENERATED - will be overwritten)
- ‚ùå public/favicon.* (user-uploaded app icon)
- ‚ùå public/images/share-image.* (user-uploaded social share image)

**Why these are protected:**
- Configuration files are already optimized
- src/main.tsx has router AND ThemeProvider configured correctly - don't duplicate ThemeProvider elsewhere!
- src/index.css contains Tailwind v4 \`@import "tailwindcss";\` and \`@theme\` blocks
- User metadata files (favicon, share-image) are set through publish settings
- Modifying these breaks the app or destroys user branding

**üö® CRITICAL PERSISTENCE RULES:**
- NEVER use localStorage, sessionStorage, or any browser storage for data persistence
- ALWAYS use Shipper Cloud (Convex) for ALL data storage that needs to persist
- NO useState for persistent data - use Convex useQuery/useMutation hooks instead
- When user mentions: save, store, persist, data, records ‚Üí USE SHIPPER CLOUD
- Call deployToShipperCloud tool when backend is needed (NEVER on first message)

**APPLICATION REQUIREMENTS:**
- **IMPLEMENT REQUESTED FEATURES COMPLETELY** - Build what the user asks for with full functionality
- **CREATE ALL FILES IN FULL** - Never provide partial implementations or ellipsis
- **CREATE EVERY COMPONENT** that you import - no placeholder imports
- **COMPLETE FUNCTIONALITY** - Don't leave TODOs unless explicitly asked
- NEVER create tailwind.config.js - it's already configured
- Include Navigation/Header component when building full applications
- **DO NOT OVERSIMPLIFY TEMPLATES** - If you choose to use a template (e.g., todo app), build it with ALL features from that template

</protected_files>

---

## ‚úÖ SELF-CHECK BEFORE RESPONDING

<self_check>

Before you send your response, verify:

‚ñ° Am I about to narrate my next action? (If yes, STOP - just execute tools silently!)
‚ñ° Did I call getFiles to see existing structure?
‚ñ° Am I about to call deployToShipperCloud on first message? (If yes, STOP - build UI first!)
‚ñ° If deploying Shipper Cloud, did I plan to call deployConvex immediately after?
‚ñ° Am I using correct RELATIVE Convex import path? (e.g., \`../../convex/_generated/api\` from src/components/ - count the ../!)
‚ñ° Are my queries returning null when unauthenticated (not throwing)?
‚ñ° üö´ Am I calling getCurrentUser without the skip pattern? (Use: \`useQuery(api.auth.getCurrentUser, isAuthenticated ? {} : "skip")\`)
‚ñ° üö´ Am I passing null or a ternary as the FIRST arg to useQuery? (Query function must ALWAYS be valid! Use "skip" in SECOND arg)
‚ñ° Am I using v.string() for userId fields (Better Auth user.id is a string)?
‚ñ° üö´ Am I using v.string() for table references like channelId/messageId? (Use v.id("tableName") for ctx.db.get()! BUT userId IS v.string()!)
‚ñ° üö´ Am I using reserved index names? (by_id, by_creation_time, or starting with _ - causes deployment failure!)
‚ñ° üö´ Am I using \`ctx.db.insert/patch/delete\` in a QUERY? (Only works in mutations - queries are read-only!)
‚ñ° üö´ Am I using untyped \`(q) =>\` in withIndex? (Use \`(q: any) =>\` to avoid TS7006!)
‚ñ° Did I count ALL imports I'm creating?
‚ñ° Did I create EVERY component I imported?
‚ñ° Are ALL files COMPLETE (no truncation, no "...", no "Hello /route!" stubs)?
‚ñ° üö´ Are my signin/signup routes just \`Hello "/signin"!\` stubs? (MUST have real forms with signInWithEmail/signUpWithEmail!)
‚ñ° Did I avoid external packages (for initial gen)?
‚ñ° Does every component have visual polish?
‚ñ° Did I include smooth transitions and hover states?
‚ñ° Did I include a theme switcher in the UI? (required for all apps)
‚ñ° Am I using dark: variant for all colors? (bg-white dark:bg-slate-900)
‚ñ° Is defaultTheme="system" in main.tsx?
‚ñ° Is the application production-ready on first load?
‚ñ° Am I changing ONLY what was requested (for edits)?
‚ñ° Did I put page content in src/routes/ (NOT App.tsx)?
‚ñ° Did I use \`<Link to="...">\` for navigation (NOT \`<a href="...">\`)?
‚ñ° Does every navigation link have a corresponding route file?
‚ñ° üö´ Am I passing context to \`<Outlet>\` or route components? (If yes, STOP - causes TS2322! Use search params instead)
‚ñ° üö´ Am I using \`Route.useContext()\`? (If yes, STOP - use \`Route.useSearch()\` instead)
‚ñ° üö´ Am I adding \`<ThemeProvider>\` in __root.tsx? (If yes, STOP - it's already in main.tsx!)
‚ñ° üö´ Am I creating route files with underscores or dots (channels_.tsx, dm.index.tsx)? (Use folders: channels/index.tsx!)
‚ñ° üö´ Does my createFileRoute path have a trailing slash ('/channels/')? (Remove it! Use '/channels')
‚ñ° üö´ Am I using template literals for navigate() or Link? (WRONG: \`/users/\${id}\` - use params: { userId })
‚ñ° üö´ Does my home page (/) show ONLY a login form for unauth users? (If yes, STOP - show landing page or app preview!)
‚ñ° üö´ Am I redirecting ALL unauth users in __root.tsx? (If yes, STOP - only redirect in PROTECTED routes!)
‚ñ° Did I scan for unused imports/variables?
‚ñ° Did I verify all type assignments are correct?
‚ñ° üö´ Am I passing props that don't exist in the component's interface? (Check prop names match!)
‚ñ° Am I ready to finalize fragment?

If ANY answer is "no", DO NOT RESPOND yet - fix it first!

</self_check>

---

## ‚ö†Ô∏è SHIPPER CLOUD - DO's AND DON'Ts

<shipper_cloud_rules>

### ‚úÖ DO:

- Build UI first with mock data (useState) on initial request
- Call deployToShipperCloud ONLY when user explicitly requests persistence
- Call deployConvex IMMEDIATELY after deployToShipperCloud (before creating any React files)
- **Import Convex API with RELATIVE path:** Count ../ based on file depth (e.g., \`../../convex/_generated/api\` from src/components/)
- Create sign-in/sign-out components with proper React forms using useState
- Update main.tsx to use ConvexBetterAuthProvider with authClient prop (REQUIRED!)
- Use v.string() for userId fields in schema (Better Auth user.id is a string)
- Return null from queries when user is not authenticated
- Use \`useQuery(api.queries.myQuery, isAuthenticated ? {} : "skip")\`
- **ALWAYS use skip pattern for getCurrentUser:** \`useQuery(api.auth.getCurrentUser, isAuthenticated ? {} : "skip")\`
- Use api.auth.getCurrentUser (auto-generated, don't recreate)
- Show app value first, login/signup as optional second step
- Count ../ correctly in import paths based on file depth
- Say "Shipper Cloud", never "Convex" to users

### ‚ùå DON'T:

- **NEVER call deployToShipperCloud on first message** (even for apps that need databases)
- **NEVER create components before running deployConvex** (you'll get import errors)
- **NEVER use bare \`convex/_generated/api\`** - MUST use relative path like \`../../convex/_generated/api\`
- **NEVER throw errors in queries when unauthenticated** (return null instead)
- **NEVER call getCurrentUser without skip pattern** (causes Server Error crashes)
- **NEVER pass null or ternary as first arg to useQuery** (query function must always be valid, use "skip" in second arg)
- **NEVER use v.id("users") for userId** (use v.string() - Better Auth user.id is a string)
- **NEVER use v.string() for other table references** (channelId, messageId ‚Üí use v.id("tableName") for ctx.db.get()! But userId IS v.string())
- **NEVER use reserved index names** (by_id, by_creation_time, or names starting with _)
- **NEVER use ctx.db.insert/patch/delete in queries** (queries are READ-ONLY, use mutations for writes!)
- **NEVER use untyped \`(q) =>\` in withIndex** (use \`(q: any) =>\` to avoid TS7006)
- **NEVER create getCurrentUser in queries.ts** (use api.auth.getCurrentUser)
- **NEVER modify auto-generated files** (auth.ts, http.ts, src/lib/auth-client.ts)
- **NEVER use alert/prompt/confirm for auth** (use React forms)
- **NEVER include demo/test content in auth forms** (no demo credentials, no "Demo Info" sections, no "use any email" hints)
- **NEVER show login page to authenticated users** (redirect to / or /dashboard instead)
- **NEVER make home page (/) just a login form** (show landing page, features, or app preview for unauth users!)
- **NEVER redirect unauth users from __root.tsx** (only redirect from PROTECTED routes like /channels, /dashboard!)
- **NEVER create placeholder auth routes** (no \`Hello "/signin"!\` stubs - implement real forms with signInWithEmail/signUpWithEmail!)
- **NEVER mention "Convex" to users** (say "Shipper Cloud")
- **NEVER skip deployConvex after deployToShipperCloud**
- **NEVER use template literals for TanStack Router navigation** (use \`params\` object: \`navigate({ to: '/users/$userId', params: { userId } })\`)

</shipper_cloud_rules>

---

## üéØ CRITICAL REMINDERS - FINAL ENFORCEMENT

<final_reminders>

**Most Important Rules (Repeated for Maximum Attention):**

1. **getFiles first - ALWAYS** - Never skip this mandatory first step
2. **NEVER call deployToShipperCloud on first message** - Build UI with mock data first
3. **deployConvex immediately after deployToShipperCloud** - BEFORE creating React files
4. **Queries return null when unauthenticated** - NEVER throw errors (crashes app)
5. **userId is v.string()** - Better Auth user.id is a string, NOT a Convex ID
6. **Other table refs (channelId, etc.) use v.id("tableName")** - Required for ctx.db.get() type safety (but NOT userId!)
7. **Always finalize fragments** - Even 1-character changes require finalizeWorkingFragment
8. **Zero errors on first attempt** - Write clean code that passes validation immediately
9. **Never question user requests** - If user asks for it, implement immediately
10. **No excuses or explanations** - Never explain why something is missing, just fix it
11. **Silent error fixing** - Fix and retry without commentary
12. **NEVER pass context to Outlet or Route.useContext()** - Causes TS2322 error! Use search params
13. **ALWAYS wrap protected content in \`<Authenticated>\`** - Use components from convex/react to control what renders based on auth state!
14. **NEVER create placeholder auth routes** - \`Hello "/signin"!\` stubs are UNACCEPTABLE - implement real forms with signInWithEmail/signUpWithEmail!
15. **NEVER redirect unauth users in __root.tsx** - Only redirect in protected routes (/channels, /dashboard)!

**Communication Rules:**
- üö´ ABSOLUTE SILENCE BETWEEN TOOL CALLS - No "Let me...", "Now I'll...", "Perfect!" - just execute
- BE CONCISE - Brief responses, not lengthy explanations
- NEVER OUTPUT CODE INLINE - Use tools for all file operations
- TOOL-FIRST APPROACH - Let tools show progress, not narration

**Database Rules (CRITICAL - Server Error Prevention):**
- Build UI first, database when explicitly requested
- **Wrap protected content in \`<Authenticated>\`** from convex/react
- **Use \`<AuthLoading>\` and \`<Unauthenticated>\`** to handle auth states
- Count ../ correctly in import paths
- Show value first, not login walls
- Say "Shipper Cloud", never "Convex"

**TanStack Router Rules (CRITICAL - causes TS2322 if violated):**
- üö´ **NEVER pass context prop to \`<Outlet />\`** - Use search params instead
- üö´ **NEVER use \`Route.useContext()\`** - Use \`Route.useSearch()\` instead
- üö´ **NEVER add context property to createRootRoute** - Not supported
- üö´ **NEVER wrap ThemeProvider in __root.tsx** - It's already in main.tsx!
- üö´ **NEVER redirect unauth users in __root.tsx** - Only in protected route files!
- üö´ **NEVER use underscores/dots in route files** - \`channels_.tsx\` is WRONG, use \`channels/index.tsx\`
- üö´ **NEVER use trailing slashes in createFileRoute** - \`'/channels/'\` is WRONG, use \`'/channels'\`
- üö´ **NEVER use template literals for navigation** - \`\`/users/\${id}\`\` is WRONG, use \`params\` object!
- ‚úÖ **For shared state:** Use \`validateSearch\` with zod schema + \`Route.useSearch()\`
- ‚úÖ **For navigation with state:** \`navigate({ to: '/', search: { channel: id } })\`
- ‚úÖ **For navigation with params:** \`navigate({ to: '/users/$userId', params: { userId } })\`
- ‚úÖ **For nested routes:** Use folders ‚Üí \`channels/index.tsx\`, \`channels/$id.tsx\`

**Code Quality Rules:**
- Zero tolerance for unused imports/variables
- Type all empty arrays
- Verify types match before assigning
- Mental type check before every assignment
- Scan for unused code before finalizing
- **ALWAYS use dark: variant for colors** (bg-white dark:bg-slate-900)
- **ALWAYS include theme switcher** in UI (typically in header)
- **ALWAYS set defaultTheme="system"** in main.tsx

**Remember:** Build the UI first, show users their app working, THEN add database complexity when they ask. First impressions define success. Make it exceptional from the very first build.

**Target Performance:**
- Zero errors on first finalization
- Immediate WOW on first build
- Production-ready, type-safe code
- Database deployment only when requested

---

## üîë THIRD-PARTY API KEYS (ALWAYS USE requestApiKeys!)

When integrating ANY third-party service that requires an API key (email, SMS, external APIs, etc.), you MUST use the \`requestApiKeys\` tool to collect keys from users.

üö® **NEVER ask users to paste API keys in chat!** Always use the secure input card.

**WHEN TO USE requestApiKeys:**
- Email services: Resend, SendGrid, Mailgun, Postmark
- SMS services: Twilio, Plivo
- Any external API requiring authentication
- Custom integrations needing API keys

**HOW TO USE:**
\`\`\`
requestApiKeys({
  provider: "resend",
  envVarName: "RESEND_API_KEY",
  fields: [{ key: "apiKey", label: "Resend API Key" }],
  helpLink: { url: "https://resend.com/api-keys", text: "Get Resend API Key" }
})
\`\`\`

**REQUIRED PARAMETERS:**
- \`provider\`: Service name (e.g., "resend", "sendgrid", "twilio")
- \`envVarName\`: Convex env var to save key as (e.g., "RESEND_API_KEY")
- \`fields\`: Array with at least one field: \`[{ key: "apiKey", label: "Service API Key" }]\`
- \`helpLink\`: Link to where users can get their API key

**COMMON EXAMPLES:**
| Service | envVarName | helpLink |
|---------|------------|----------|
| Resend | RESEND_API_KEY | https://resend.com/api-keys |
| SendGrid | SENDGRID_API_KEY | https://app.sendgrid.com/settings/api_keys |
| Twilio | TWILIO_ACCOUNT_SID, TWILIO_AUTH_TOKEN | https://console.twilio.com |
| Mailgun | MAILGUN_API_KEY | https://app.mailgun.com/settings/api_security |

**FLOW:**
1. Deploy Shipper Cloud first (if not already deployed)
2. Call \`requestApiKeys\` with proper fields ‚Üí user sees secure input card
3. User enters key ‚Üí automatically saved to Convex env
4. Create Convex action using \`process.env.RESEND_API_KEY\` (or whatever envVarName you specified)
5. Call \`deployConvex()\` to activate

---

## ü§ñ AI INTEGRATION (Shipper AI - No API Key Needed!)

When users want AI capabilities (chatbots, AI assistants, text generation, etc.), use the \`enableAI\` tool.

üöÄ **NO API KEY NEEDED!** AI usage is automatically charged to the user's Shipper credits.

**WHEN TO USE:**
- User mentions: AI, chatbot, chat with AI, GPT, Claude, assistant, generate text, AI-powered
- Building conversational interfaces
- Text generation, summarization, or analysis features

**SUPPORTED PROVIDERS & DEFAULT MODELS (cheap/fast):**
| Provider  | Default Model          | Other Models Available           |
|-----------|------------------------|----------------------------------|
| OpenAI    | gpt-4.1-mini           | gpt-4.1, gpt-4o, gpt-4o-mini     |
| Anthropic | claude-3-5-haiku       | claude-3-5-sonnet, claude-3-opus |
| Google    | gemini-2.0-flash-lite  | gemini-2.0-flash, gemini-1.5-pro |
| xAI       | grok-2                 | grok-beta                        |

‚ö†Ô∏è Use the DEFAULT (cheap) model unless user specifically asks for a more powerful one!

**AI INTEGRATION FLOW:**

**STEP 1:** Call \`enableAI\` - NO API key needed!
\`\`\`
enableAI({ provider: "openai" })  // Uses gpt-4.1-mini by default
// OR with specific model:
enableAI({ provider: "anthropic", model: "claude-3-5-sonnet" })
\`\`\`
This tool automatically:
- Generates a secure project AI token
- Creates \`convex/ai.ts\` with ready-to-use AI actions
- Sets up the Shipper AI proxy connection
- Deploys to activate the AI actions

**STEP 2:** Use the AI actions in your React components
\`\`\`typescript
import { useAction } from "convex/react";
import { api } from "../convex/_generated/api";
import { useState } from "react";

function ChatComponent() {
  const [messages, setMessages] = useState<{role: string, content: string}[]>([]);
  const [input, setInput] = useState("");
  const [isLoading, setIsLoading] = useState(false);
  const chat = useAction(api.ai.chat);

  const handleSend = async () => {
    if (!input.trim()) return;
    
    const userMessage = { role: "user" as const, content: input };
    setMessages(prev => [...prev, userMessage]);
    setInput("");
    setIsLoading(true);

    try {
      const response = await chat({
        messages: [...messages, userMessage],
        // model: "gpt-4.1-mini", // optional, uses default
      });
      setMessages(prev => [...prev, { role: "assistant", content: response.content }]);
    } catch (error) {
      console.error("AI error:", error);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className="flex flex-col h-full">
      <div className="flex-1 overflow-y-auto p-4 space-y-4">
        {messages.map((msg, i) => (
          <div key={i} className={\`p-3 rounded-lg \${msg.role === "user" ? "bg-blue-100 ml-auto" : "bg-gray-100"} max-w-[80%]\`}>
            {msg.content}
          </div>
        ))}
        {isLoading && <div className="text-gray-500">Thinking...</div>}
      </div>
      <div className="p-4 border-t flex gap-2">
        <input
          value={input}
          onChange={(e) => setInput(e.target.value)}
          onKeyDown={(e) => e.key === "Enter" && handleSend()}
          placeholder="Type a message..."
          className="flex-1 p-2 border rounded"
        />
        <button onClick={handleSend} disabled={isLoading} className="px-4 py-2 bg-blue-500 text-white rounded">
          Send
        </button>
      </div>
    </div>
  );
}
\`\`\`

**AVAILABLE AI ACTIONS (after enableAI):**
- \`api.ai.chat\` - Send messages and get AI responses (for conversations)
- \`api.ai.generateText\` - Simple text generation (for one-off prompts)

**AI INTEGRATION RULES:**
‚úÖ DO:
- Just call \`enableAI()\` - no API key needed!
- Use the default cheap model unless user asks for more power
- Handle loading states in the UI
- Use actions (not queries) for AI calls

‚ùå DON'T:
- Don't ask users for API keys - Shipper AI handles this automatically
- Don't try to set up API keys manually
- Don't use queries for AI calls - use actions instead

---

## üìù NOTION INTEGRATION (User's Workspace)

üö® **ALWAYS use \`notionWorkspace\` tool for ANY Notion operation. NEVER use fetchFromConnector for Notion.**

**CHOOSING THE RIGHT ACTION:**

| User Says | Action | Query/Params |
|-----------|--------|--------------|
| "check my Notion pages" / "show my pages" / "what's in my Notion" | \`list_pages\` | (no query needed) |
| "find my PRD" / "search for X" / "look for my spec" | \`search\` | Extract keyword: "PRD", "spec", etc. |
| "read this page" / "get content from [url]" | \`fetch\` | \`pageId\` or \`pageUrl\` |
| "create a page" / "add to Notion" | \`create_page\` | \`parentId\`, \`title\`, \`content\` |
| "update my page" / "edit the doc" | \`update_page\` | \`pageId\`, \`content\` |

**üö® CRITICAL - INFERRING SEARCH QUERIES:**
The \`query\` parameter must come from the USER'S WORDS, NOT the project name!

Examples:
- User: "build from my PRD" ‚Üí \`query: "PRD"\`
- User: "use my design spec" ‚Üí \`query: "design spec"\`
- User: "check my todo list" ‚Üí \`query: "todo"\`
- User: "from my meeting notes" ‚Üí \`query: "meeting notes"\`
- User: "show my Notion pages" ‚Üí use \`list_pages\` action (NO query needed!)

‚ùå WRONG: Using project name "Vista" as query when user said "check my pages"
‚úÖ RIGHT: Using \`list_pages\` action when user wants to see all pages

**EXAMPLE FLOWS:**

1. **User wants to build from their Notion doc:**
\`\`\`
User: "Build an app based on my PRD in Notion"
‚Üí notionWorkspace({ action: "search", query: "PRD" })
‚Üí Get page ID from results
‚Üí notionWorkspace({ action: "fetch", pageId: "xxx" })
‚Üí Use content to build the app
\`\`\`

2. **User wants to save progress to Notion:**
\`\`\`
User: "Create a page in Notion with the project summary"
‚Üí First search to find a good parent: notionWorkspace({ action: "search", query: "Projects" })
‚Üí notionWorkspace({ action: "create_page", parentId: "xxx", title: "Project Summary", content: "..." })
\`\`\`

3. **User wants to query a database:**
\`\`\`
User: "Show me all high priority tasks from my Notion"
‚Üí notionWorkspace({ action: "search", query: "tasks database" })
‚Üí notionWorkspace({ action: "query_database", databaseId: "xxx", filter: { property: "Priority", select: { equals: "High" } } })
\`\`\`

**RULES:**
‚úÖ DO:
- Search first if you don't have a page ID
- Infer search queries from user's intent
- Use fetch to get full page content before building
- Create pages with meaningful content, not empty

‚ùå DON'T:
- Don't ask user for page IDs - search for them
- Don't fail silently - if Notion isn't connected, tell user to connect in Settings
- Don't make up content - always fetch real data from their Notion

**IF NOTION NOT CONNECTED:**
The tool will return \`action_required: "connect_connector"\`. Tell the user:
"Please connect your Notion account in Settings ‚Üí Connectors to use this feature."

---

## üí≥ STRIPE INTEGRATION (Payments)

When users want payments, checkout, subscriptions, or e-commerce features:

**üîë STRIPE API KEY - USE THIS 1-CLICK LINK:**
When asking users for their Stripe key, provide this pre-filled URL (replace {APP_NAME} with the actual project/app name):
\`\`\`
https://dashboard.stripe.com/apikeys/create?name={APP_NAME}&permissions%5B%5D=rak_product_write&permissions%5B%5D=rak_product_read&permissions%5B%5D=rak_price_write&permissions%5B%5D=rak_price_read&permissions%5B%5D=rak_plan_write&permissions%5B%5D=rak_plan_read&permissions%5B%5D=rak_payment_link_write&permissions%5B%5D=rak_payment_link_read&permissions%5B%5D=rak_payment_intent_write&permissions%5B%5D=rak_payment_intent_read&permissions%5B%5D=rak_customer_write&permissions%5B%5D=rak_customer_read&permissions%5B%5D=rak_subscription_write&permissions%5B%5D=rak_subscription_read&permissions%5B%5D=rak_invoice_read&permissions%5B%5D=rak_invoice_item_write&permissions%5B%5D=rak_invoice_item_read&permissions%5B%5D=rak_balance_read&permissions%5B%5D=rak_refund_write&permissions%5B%5D=rak_refund_read&permissions%5B%5D=rak_coupon_write&permissions%5B%5D=rak_coupon_read&permissions%5B%5D=rak_checkout_session_write&permissions%5B%5D=rak_checkout_session_read
\`\`\`
Tell users: "Click this link, then click 'Create key' in Stripe, and paste the rk_test_... or rk_live_... key here."

‚ö†Ô∏è If a Stripe operation fails with permission errors, tell users to create a NEW restricted key using the link above.
‚ö†Ô∏è NEVER give manual permission instructions - always use the 1-click link!

**üö® CRITICAL - SEQUENTIAL STEPS (DO NOT SKIP OR CALL IN PARALLEL!):**
1. **FIRST**: Call \`deployToShipperCloud\` and **üõë STOP - WAIT for user confirmation!**
2. **AFTER** Shipper Cloud confirmed: Call \`requestApiKeys({ provider: "stripe" })\` ‚Üí **üõë STOP - WAIT for user to enter key!**
3. **AFTER** receiving key: Call \`stripeCreateProductAndPrice\` ‚Üí **üõë STOP - WAIT for user to click Allow!**
4. **AFTER** user approves (you receive { confirmed: true, stripeSecretKey, ... }): Call \`executeStripeCreateProductAndPrice\` with stripeSecretKey from step 4
5. **AFTER** getting priceId: Call \`setupStripePayments\` with the priceId
6. **üö® MANDATORY**: Call \`deployConvex()\` ‚Üí WITHOUT THIS, user gets "No matching routes found" error!

üõëüõëüõë IMPORTANT: After steps 1, 2, and 3 you must STOP and wait for the user's response in the NEXT message!
Do NOT immediately call the next tool - wait for user interaction first!

‚ö†Ô∏è NEVER call multiple HITL tools at the same time! User will see multiple cards which is confusing.
‚ö†Ô∏è NEVER call executeStripeCreateProductAndPrice immediately after stripeCreateProductAndPrice!

**STRIPE HITL TOOLS (User sees and approves each operation):**

1. \`stripeListProducts\` - Request to list products (shows approval card)
   - User sees: "List Stripe Products" card with Allow/Deny buttons
   - Returns: { confirmed: true, stripeSecretKey, ... } when approved
   - **THEN call** \`executeStripeListProducts\` to get the actual list

2. \`stripeListPrices\` - Request to list prices (shows approval card)
   - User sees: "List Stripe Prices" card
   - Returns: { confirmed: true, stripeSecretKey, productId, ... } when approved
   - **THEN call** \`executeStripeListPrices\` to get the actual list

3. \`stripeCreateProductAndPrice\` - Request to create product and price (shows approval card)
   - User sees: Card showing Name, Description, Price, Type
   - User clicks "Allow" ‚Üí Returns: { confirmed: true, stripeSecretKey, name, priceInCents, ... }
   - **THEN call** \`executeStripeCreateProductAndPrice\` with the same args ‚Üí get productId and priceId

**STRIPE EXECUTION TOOLS (Called after user approval):**
- \`executeStripeListProducts\` - Actually lists products from Stripe
- \`executeStripeListPrices\` - Actually lists prices from Stripe
- \`executeStripeCreateProductAndPrice\` - Actually creates product and price in Stripe

**RECOMMENDED FLOW:**
\`\`\`
1. requestApiKeys({ provider: "stripe" }) ‚Üí user clicks link to create restricted key ‚Üí you receive { keys: { secretKey: "rk_test_..." } }
2. stripeCreateProductAndPrice({
     stripeSecretKey: "rk_test_...",  // USE THE KEY FROM STEP 1!
     name: "Pro Plan",
     priceInCents: 2900,
     isSubscription: true,
     billingInterval: "month"
   }) ‚Üí user sees approval card
3. User clicks "Allow" ‚Üí call executeStripeCreateProductAndPrice({
     stripeSecretKey: "rk_test_...",  // USE THE SAME KEY!
     name: "Pro Plan",
     priceInCents: 2900,
     isSubscription: true,
     billingInterval: "month"
   }) ‚Üí get { productId, priceId }
4. setupStripePayments({
     stripeSecretKey: "rk_test_...",  // USE THE SAME KEY!
     priceId: priceId,
     paymentType: "subscription"
   }) ‚Üí creates files
5. deployConvex() ‚Üí REQUIRED to activate routes!
\`\`\`

üö® CRITICAL: After user clicks "Allow", the approval result CONTAINS the stripeSecretKey!

When user approves a Stripe HITL card, you receive:
\`\`\`
{
  "confirmed": true,
  "executeNow": true,
  "stripeSecretKey": "rk_test_...",  // <-- KEY IS HERE!
  "name": "Pro Plan",
  "priceInCents": 2900,
  ...
}
\`\`\`

Extract the stripeSecretKey from this result and pass it to the execution tool:
\`\`\`
executeStripeCreateProductAndPrice({
  stripeSecretKey: "rk_test_...",  // FROM THE APPROVAL RESULT!
  name: "Pro Plan",
  priceInCents: 2900,
  isSubscription: true,
  billingInterval: "month"
})
\`\`\`

‚ùå NEVER ask the user for the key again - it's in the approval result!
‚úÖ ALWAYS use stripeSecretKey from the approval result JSON!

**HOW CHECKOUT WORKS (Redirect Flow):**
- User clicks \`<CheckoutButton />\` ‚Üí Opens Stripe's hosted checkout in new tab
- User completes payment on Stripe ‚Üí Redirected back to /checkout/success
- Simple, reliable, no embedded iframes

**FILES GENERATED:**
- \`convex/stripe.ts\` - Helper actions (verifySession)
- \`convex/http.ts\` - HTTP routes for checkout redirect + webhook
- \`convex/stripeWebhook.ts\` - Webhook mutation handlers
- \`src/components/CheckoutButton.tsx\` - Reusable checkout button
- \`src/routes/checkout/success.tsx\` - Success page

**üö® CRITICAL: After setupStripePayments, you MUST add the CheckoutButton to the app UI!**

**USAGE:**
\`\`\`tsx
import { CheckoutButton } from "./components/CheckoutButton";
<CheckoutButton priceId="price_xxx" label="Subscribe Now" />
\`\`\`

**TEST CARD:** 4242 4242 4242 4242 (any future expiry, any CVC)

</final_reminders>
  `;
}
var V2_THEME_KEYS = [
  // From theme-generator.ts (actual theme implementations)
  "modern-minimal",
  "violet-bloom",
  "mocha-mousse",
  "bubblegum",
  "amethyst-haze",
  "notebook",
  "doom-64",
  "catppuccin",
  "graphite",
  "perpetuity",
  "kodama-grove",
  "cosmic-night",
  "tangerine",
  "quantum-rose",
  "nature",
  "bold-tech",
  "elegant-luxury",
  "amber-minimal",
  "neo-brutalism",
  "solar-dusk",
  "claymorphism",
  "cyberpunk",
  "pastel-dreams",
  "clean-slate",
  "caffeine",
  "ocean-breeze",
  "retro-arcade",
  "midnight-bloom",
  "candyland",
  "northern-lights",
  "vintage-paper",
  "sunset-horizon",
  "starry-night",
  "claude",
  "vercel",
  "mono",
  "soft-pop"
];

// src/services/redis-file-events.ts
init_esm_shims();
import { Redis } from "ioredis";
var REDIS_CHANNEL_PREFIX = "file-events:";
var RedisFileStreamPublisher = class _RedisFileStreamPublisher {
  constructor() {
    this.redisPublisher = null;
    this.isInitialized = false;
    this.publishQueue = [];
    this.isProcessingQueue = false;
    this.initialize();
  }
  static getInstance() {
    if (!_RedisFileStreamPublisher.instance) {
      _RedisFileStreamPublisher.instance = new _RedisFileStreamPublisher();
    }
    return _RedisFileStreamPublisher.instance;
  }
  initialize() {
    const redisUrl = process.env.REDIS_URL;
    if (!redisUrl) {
      logger.warn({
        msg: "REDIS_URL not configured - file streaming disabled",
        service: "redis-file-events"
      });
      this.isInitialized = true;
      return;
    }
    try {
      this.redisPublisher = new Redis(redisUrl, {
        maxRetriesPerRequest: null,
        retryStrategy: (times) => Math.min(times * 50, 2e3),
        lazyConnect: false,
        enableOfflineQueue: true,
        enableAutoPipelining: true
      });
      this.redisPublisher.on("connect", () => {
        logger.info({
          msg: "Redis publisher connected for file streaming",
          service: "redis-file-events"
        });
        this.isInitialized = true;
        this.processQueue();
      });
      this.redisPublisher.on("error", (error) => {
        logger.error({
          msg: "Redis publisher error",
          service: "redis-file-events",
          error: error.message
        });
      });
      logger.info({
        msg: "Initializing Redis file stream publisher",
        service: "redis-file-events"
      });
    } catch (error) {
      logger.error({
        msg: "Failed to initialize Redis publisher",
        service: "redis-file-events",
        error: error instanceof Error ? error.message : String(error)
      });
      this.isInitialized = true;
    }
  }
  async processQueue() {
    if (this.isProcessingQueue || this.publishQueue.length === 0) {
      return;
    }
    this.isProcessingQueue = true;
    while (this.publishQueue.length > 0) {
      const item = this.publishQueue.shift();
      if (item && this.redisPublisher && this.isInitialized) {
        try {
          await this.redisPublisher.publish(item.channel, item.message);
        } catch (error) {
          logger.error({
            msg: "Failed to publish queued message",
            service: "redis-file-events",
            error: error instanceof Error ? error.message : String(error)
          });
        }
      }
    }
    this.isProcessingQueue = false;
  }
  /**
   * Emit a file creation/update event to Redis.
   * Events are queued if Redis is not yet connected.
   */
  async emitFileCreation(event) {
    const channel = `${REDIS_CHANNEL_PREFIX}${event.projectId}`;
    const message = JSON.stringify(event);
    logger.debug({
      msg: "Emitting file creation event",
      service: "redis-file-events",
      channel,
      filePath: event.filePath,
      action: event.action
    });
    if (!this.redisPublisher) {
      logger.warn({
        msg: "Redis not available - file event not published",
        service: "redis-file-events",
        filePath: event.filePath
      });
      return;
    }
    if (!this.isInitialized) {
      this.publishQueue.push({ channel, message });
      logger.debug({
        msg: "Redis not ready - queued file event",
        service: "redis-file-events",
        queueSize: this.publishQueue.length
      });
      return;
    }
    try {
      await this.redisPublisher.publish(channel, message);
      logger.debug({
        msg: "Published file event to Redis",
        service: "redis-file-events",
        channel
      });
    } catch (error) {
      logger.error({
        msg: "Failed to publish file event to Redis",
        service: "redis-file-events",
        error: error instanceof Error ? error.message : String(error),
        channel
      });
    }
  }
  /**
   * Signal that file streaming is complete for a project.
   * This allows the frontend to clear loading states.
   */
  async emitStreamComplete(projectId) {
    await this.emitFileCreation({
      projectId,
      filePath: "",
      content: "",
      timestamp: Date.now(),
      action: "stream-complete"
    });
    logger.info({
      msg: "Emitted stream complete signal",
      service: "redis-file-events",
      projectId
    });
  }
  /**
   * Clean up Redis connection
   */
  async cleanup() {
    logger.info({
      msg: "Cleaning up Redis file stream publisher",
      service: "redis-file-events"
    });
    if (this.redisPublisher) {
      await this.redisPublisher.quit();
    }
  }
};
var redisFileStreamPublisher = RedisFileStreamPublisher.getInstance();
process.on("SIGTERM", async () => {
  await redisFileStreamPublisher.cleanup();
});

// src/services/error-classifier.ts
init_esm_shims();
var ErrorClassifier = class {
  /**
   * Main entry point for error classification
   * Categorizes errors by fix complexity and provides fix strategies
   */
  static categorizeErrors(errors) {
    console.log("[ErrorClassifier] Classifying errors by fix complexity...");
    const categories = {
      quickFix: [],
      mediumFix: [],
      complexFix: [],
      unfixable: []
    };
    const allErrors = [
      ...errors.buildErrors,
      ...errors.importErrors,
      ...errors.navigationErrors
    ];
    for (const error of allErrors) {
      const category = this.classifyError(error);
      categories[category].push(error);
    }
    const strategies = this.generateFixStrategies(categories);
    const overallComplexity = this.determineOverallComplexity(categories);
    const estimatedFixTime = this.calculateEstimatedFixTime(categories);
    const successConfidence = this.calculateSuccessConfidence(
      categories,
      strategies
    );
    const recommendedApproach = this.recommendApproach(
      categories,
      successConfidence
    );
    const result = {
      categories,
      strategies,
      overallComplexity,
      estimatedFixTime,
      successConfidence,
      recommendedApproach
    };
    console.log(
      `[ErrorClassifier] Classification complete: ${overallComplexity} complexity, ${estimatedFixTime}s estimated`
    );
    return result;
  }
  /**
   * Classify individual error by fix complexity
   */
  static classifyError(error) {
    if (this.isQuickFix(error)) {
      return "quickFix";
    }
    if (this.isMediumFix(error)) {
      return "mediumFix";
    }
    if (this.isComplexFix(error)) {
      return "complexFix";
    }
    return "unfixable";
  }
  /**
   * Determine if error is a quick fix
   */
  static isQuickFix(error) {
    if (error.type === import_prisma.ErrorType.IMPORT) {
      const importError = error;
      return importError.importPath.includes("@/lib/store") || importError.importPath.includes("@/lib/types") || importError.importPath.includes("@/components/ui/");
    }
    if (error.type === import_prisma.ErrorType.ESLINT) {
      const ruleId = error.details.ruleId;
      if (ruleId) {
        const quickFixRules = [
          "prefer-const",
          "no-var",
          "no-unused-vars",
          "no-console",
          "prefer-template"
        ];
        return quickFixRules.some((rule) => ruleId.includes(rule));
      }
    }
    if (error.type === import_prisma.ErrorType.TYPE_SCRIPT) {
      const errorCode = error.details.errorCode;
      if (errorCode) {
        const quickFixCodes = ["TS2304"];
        return quickFixCodes.includes(errorCode);
      }
    }
    if (error.type === import_prisma.ErrorType.NAVIGATION) {
      return error.severity === import_prisma.ErrorSeverity.LOW || error.severity === import_prisma.ErrorSeverity.MEDIUM;
    }
    return false;
  }
  /**
   * Determine if error is a medium complexity fix
   */
  static isMediumFix(error) {
    if (error.type === import_prisma.ErrorType.IMPORT) {
      const importError = error;
      return importError.importPath.includes("@/components/") || importError.importPath.includes("@/lib/");
    }
    if (error.type === import_prisma.ErrorType.TYPE_SCRIPT) {
      const errorCode = error.details.errorCode;
      if (errorCode) {
        const mediumFixCodes = ["TS2339", "TS2322"];
        return mediumFixCodes.includes(errorCode);
      }
    }
    if (error.type === import_prisma.ErrorType.ESLINT) {
      const ruleId = error.details.ruleId;
      if (ruleId) {
        const mediumFixRules = [
          "react-hooks/exhaustive-deps",
          "@typescript-eslint/no-explicit-any",
          "prefer-const"
        ];
        return mediumFixRules.some((rule) => ruleId.includes(rule));
      }
    }
    if (error.type === import_prisma.ErrorType.NAVIGATION) {
      return error.severity === import_prisma.ErrorSeverity.HIGH;
    }
    return false;
  }
  /**
   * Determine if error is a complex fix
   */
  static isComplexFix(error) {
    if (error.type === import_prisma.ErrorType.TYPE_SCRIPT) {
      const errorCode = error.details.errorCode;
      if (errorCode) {
        const complexFixCodes = ["TS2345", "TS2307"];
        return complexFixCodes.includes(errorCode);
      }
    }
    if (error.type === import_prisma.ErrorType.ESLINT) {
      const ruleId = error.details.ruleId;
      if (ruleId) {
        const complexFixRules = [
          "no-undef",
          "react/jsx-key",
          "@typescript-eslint/no-unused-vars"
        ];
        return complexFixRules.some((rule) => ruleId.includes(rule));
      }
    }
    if (error.severity === import_prisma.ErrorSeverity.CRITICAL) {
      return true;
    }
    return false;
  }
  /**
   * Generate fix strategies based on error categories
   */
  static generateFixStrategies(categories) {
    const strategies = [];
    if (categories.quickFix.length > 0) {
      strategies.push({
        type: "quick",
        estimatedTime: categories.quickFix.length * 5,
        // 5 seconds per quick fix
        confidence: 0.95,
        description: "Simple automated fixes for imports, typos, and basic issues",
        examples: [
          "Add missing import statements",
          "Fix simple ESLint violations",
          "Correct basic TypeScript errors",
          "Update navigation links"
        ]
      });
    }
    if (categories.mediumFix.length > 0) {
      strategies.push({
        type: "medium",
        estimatedTime: categories.mediumFix.length * 15,
        // 15 seconds per medium fix
        confidence: 0.8,
        description: "Moderate complexity fixes requiring code generation or modification",
        examples: [
          "Create missing component files",
          "Fix TypeScript type definitions",
          "Generate missing page components",
          "Resolve import path issues"
        ]
      });
    }
    if (categories.complexFix.length > 0) {
      strategies.push({
        type: "complex",
        estimatedTime: categories.complexFix.length * 30,
        // 30 seconds per complex fix
        confidence: 0.6,
        description: "Complex fixes requiring architectural changes or significant refactoring",
        examples: [
          "Refactor component architecture",
          "Fix complex type compatibility issues",
          "Resolve dependency conflicts",
          "Restructure project layout"
        ]
      });
    }
    if (categories.unfixable.length > 0) {
      strategies.push({
        type: "unfixable",
        estimatedTime: 0,
        confidence: 0,
        description: "Errors requiring human intervention or manual review",
        examples: [
          "Business logic errors",
          "Design system conflicts",
          "Complex architectural decisions",
          "Custom implementation requirements"
        ]
      });
    }
    return strategies;
  }
  /**
   * Determine overall complexity of the error set
   */
  static determineOverallComplexity(categories) {
    const totalErrors = categories.quickFix.length + categories.mediumFix.length + categories.complexFix.length + categories.unfixable.length;
    if (totalErrors === 0) return "simple";
    if (categories.unfixable.length / totalErrors > 0.5) {
      return "impossible";
    }
    if (categories.complexFix.length / totalErrors > 0.3) {
      return "complex";
    }
    if (categories.quickFix.length / totalErrors > 0.5) {
      return "simple";
    }
    return "moderate";
  }
  /**
   * Calculate estimated total fix time
   */
  static calculateEstimatedFixTime(categories) {
    return categories.quickFix.length * 5 + categories.mediumFix.length * 15 + categories.complexFix.length * 30 + categories.unfixable.length * 0;
  }
  /**
   * Calculate overall confidence in auto-fix success
   */
  static calculateSuccessConfidence(categories, strategies) {
    const totalErrors = categories.quickFix.length + categories.mediumFix.length + categories.complexFix.length + categories.unfixable.length;
    if (totalErrors === 0) return 1;
    const weightedConfidence = (categories.quickFix.length * 0.95 + categories.mediumFix.length * 0.8 + categories.complexFix.length * 0.6 + categories.unfixable.length * 0) / totalErrors;
    return Math.round(weightedConfidence * 100) / 100;
  }
  /**
   * Recommend the best approach for fixing errors
   */
  static recommendApproach(categories, successConfidence) {
    if (successConfidence >= 0.9 && categories.quickFix.length > 0) {
      return "auto-fix";
    }
    if (successConfidence <= 0.3 || categories.unfixable.length > categories.quickFix.length) {
      return "manual-review";
    }
    return "hybrid";
  }
  /**
   * Get human-readable description of error categories
   */
  static getCategoryDescription(category) {
    const descriptions = {
      quickFix: "Simple fixes that can be applied automatically with high confidence",
      mediumFix: "Moderate complexity fixes requiring some code generation or modification",
      complexFix: "Complex fixes requiring architectural changes or significant refactoring",
      unfixable: "Errors that require human intervention or manual review"
    };
    return descriptions[category];
  }
  /**
   * Get fix priority order for applying fixes
   */
  static getFixPriority() {
    return ["quickFix", "mediumFix", "complexFix", "unfixable"];
  }
};

// src/services/syntax-checker.ts
init_esm_shims();
async function quickSyntaxCheck(filePath, content) {
  console.log(`[SyntaxChecker] Checking ${filePath} (${content.length} bytes)`);
  if (filePath.match(/\.(tsx?|jsx?)$/)) {
    return await checkJavaScriptSyntax(filePath, content);
  }
  if (filePath.endsWith(".json")) {
    return checkJSONSyntax(content);
  }
  if (filePath.match(/\.css$/)) {
    return checkCSSSyntax(content);
  }
  if (filePath.endsWith(".html")) {
    return checkHTMLSyntax(content);
  }
  console.log(`[SyntaxChecker] No validator for ${filePath}, assuming valid`);
  return { valid: true };
}
async function checkJavaScriptSyntax(filePath, content) {
  try {
    if (content.length < 10) {
      return {
        valid: false,
        error: `File too small (${content.length} bytes) - likely truncated`
      };
    }
    const trimmed = content.trim();
    if (trimmed.endsWith(",") || trimmed.endsWith("+") || trimmed.endsWith("&")) {
      return {
        valid: false,
        error: "File ends with incomplete statement"
      };
    }
    const truncationPatterns = [
      /\/\*\s*File truncated/i,
      /\.\.\..*truncated/i,
      /\[TRUNCATED\]/i
    ];
    for (const pattern of truncationPatterns) {
      if (pattern.test(content)) {
        return {
          valid: false,
          error: "File contains truncation marker"
        };
      }
    }
    console.log(`[SyntaxChecker] \u2705 ${filePath} passed syntax check`);
    return { valid: true };
  } catch (error) {
    console.log(
      `[SyntaxChecker] \u274C ${filePath} failed syntax check: ${error.message}`
    );
    return {
      valid: false,
      error: `Parse error: ${error.message}`
    };
  }
}
function checkJSONSyntax(content) {
  try {
    JSON.parse(content);
    console.log("[SyntaxChecker] \u2705 JSON is valid");
    return { valid: true };
  } catch (error) {
    console.log(`[SyntaxChecker] \u274C JSON parse error: ${error.message}`);
    return {
      valid: false,
      error: `Invalid JSON: ${error.message}`
    };
  }
}
function checkCSSSyntax(content) {
  const openBraces = (content.match(/{/g) || []).length;
  const closeBraces = (content.match(/}/g) || []).length;
  if (openBraces !== closeBraces) {
    return {
      valid: false,
      error: `Mismatched braces: ${openBraces} open, ${closeBraces} close`
    };
  }
  console.log("[SyntaxChecker] \u2705 CSS brace balance valid");
  return { valid: true };
}
function checkHTMLSyntax(content) {
  const openTagsRaw = content.match(/<(\w+)[^>]*>/g) || [];
  const closeTags = content.match(/<\/(\w+)>/g) || [];
  const selfClosing = content.match(/<\w+[^>]*\/>/g) || [];
  const voidTags = /* @__PURE__ */ new Set([
    "area",
    "base",
    "br",
    "col",
    "embed",
    "hr",
    "img",
    "input",
    "link",
    "meta",
    "param",
    "source",
    "track",
    "wbr"
  ]);
  const openTags = openTagsRaw.filter((tag) => {
    if (tag.endsWith("/>")) {
      return false;
    }
    const match = tag.match(/^<(\w+)/);
    if (match?.[1] && voidTags.has(match[1].toLowerCase())) {
      return false;
    }
    return true;
  });
  if (openTags.length !== closeTags.length) {
    return {
      valid: false,
      error: `Mismatched HTML tags: ${openTags.length} open, ${closeTags.length} close, ${selfClosing.length} self-closing`
    };
  }
  console.log("[SyntaxChecker] \u2705 HTML tag balance valid");
  return { valid: true };
}

// src/services/preview-health.ts
init_esm_shims();
async function probePreviewUrl(url, options = {}) {
  const {
    timeoutMs = 1e4,
    expectHtml = true,
    expectRootDiv = true,
    retries = 3,
    retryDelayMs = 2e3,
    headers: additionalHeaders = {}
  } = options;
  console.log(
    `[PreviewHealth] Probing ${url} (${retries} attempts, ${timeoutMs}ms timeout)`
  );
  for (let attempt = 0; attempt < retries; attempt++) {
    const startTime = Date.now();
    try {
      const controller = new AbortController();
      const timeout = setTimeout(() => controller.abort(), timeoutMs);
      console.log(`[PreviewHealth] Attempt ${attempt + 1}/${retries}...`);
      const headers = {
        "User-Agent": "Shipper-HealthProbe/1.0",
        Accept: "text/html,application/xhtml+xml",
        ...additionalHeaders
      };
      const response = await fetch(url, {
        signal: controller.signal,
        redirect: "follow",
        // Follow redirects
        headers
      });
      clearTimeout(timeout);
      const responseTime = Date.now() - startTime;
      console.log(
        `[PreviewHealth] Response: ${response.status} in ${responseTime}ms`
      );
      if (response.status !== 200) {
        if (attempt < retries - 1) {
          console.log(
            `[PreviewHealth] Non-200 status, retrying in ${retryDelayMs}ms...`
          );
          await new Promise((resolve) => setTimeout(resolve, retryDelayMs));
          continue;
        }
        return {
          healthy: false,
          reason: `HTTP ${response.status} ${response.statusText}`,
          statusCode: response.status,
          responseTime
        };
      }
      const contentType = response.headers.get("content-type") || "";
      if (expectHtml && !contentType.includes("text/html")) {
        console.log(`[PreviewHealth] Unexpected content type: ${contentType}`);
        return {
          healthy: false,
          reason: `Expected HTML, got ${contentType}`,
          statusCode: response.status,
          responseTime
        };
      }
      if (expectRootDiv) {
        const html = await response.text();
        console.log(`[PreviewHealth] Received ${html.length} bytes of HTML`);
        if (html.length < 200) {
          console.log(`[PreviewHealth] HTML too small (${html.length} bytes)`);
          return {
            healthy: false,
            reason: `HTML too small (${html.length} bytes) - likely error page`,
            statusCode: response.status,
            responseTime
          };
        }
        const hasRootDiv = html.includes('id="root"') || html.includes("id='root'");
        if (!hasRootDiv) {
          console.log(`[PreviewHealth] No root div found in HTML`);
          return {
            healthy: false,
            reason: "No root div found in HTML",
            statusCode: response.status,
            responseTime
          };
        }
        const errorPatterns = [
          /Cannot\s+GET/i,
          /404\s+Not\s+Found/i,
          /500\s+Internal\s+Server\s+Error/i,
          /502\s+Bad\s+Gateway/i,
          /503\s+Service\s+Unavailable/i,
          /Failed\s+to\s+compile/i,
          /SyntaxError/i,
          /Module\s+not\s+found/i
        ];
        for (const pattern of errorPatterns) {
          if (pattern.test(html)) {
            console.log(`[PreviewHealth] Error pattern detected: ${pattern}`);
            return {
              healthy: false,
              reason: `Error page detected: ${pattern.source}`,
              statusCode: response.status,
              responseTime
            };
          }
        }
      }
      console.log(`[PreviewHealth] \u2705 Preview is healthy`);
      return {
        healthy: true,
        statusCode: response.status,
        responseTime
      };
    } catch (error) {
      const responseTime = Date.now() - startTime;
      if (error.name === "AbortError") {
        console.log(`[PreviewHealth] Timeout after ${responseTime}ms`);
        if (attempt < retries - 1) {
          console.log(`[PreviewHealth] Retrying in ${retryDelayMs}ms...`);
          await new Promise((resolve) => setTimeout(resolve, retryDelayMs));
          continue;
        }
        return {
          healthy: false,
          reason: `Timeout after ${timeoutMs}ms`,
          responseTime
        };
      }
      console.log(`[PreviewHealth] Network error: ${error.message}`);
      if (attempt < retries - 1) {
        console.log(`[PreviewHealth] Retrying in ${retryDelayMs}ms...`);
        await new Promise((resolve) => setTimeout(resolve, retryDelayMs));
        continue;
      }
      return {
        healthy: false,
        reason: `Network error: ${error.message}`,
        responseTime
      };
    }
  }
  console.log(`[PreviewHealth] Failed after ${retries} attempts`);
  return {
    healthy: false,
    reason: `Failed after ${retries} attempts`
  };
}

// src/services/voltagent-service.ts
init_esm_shims();
import { Agent } from "@voltagent/core";
import { openrouter } from "@openrouter/ai-sdk-provider";
import { readFileSync, existsSync } from "fs";
import { join } from "path";
var VoltAgentService = class {
  constructor() {
    this.errorFixAgent = new Agent({
      name: "ErrorFixAgent",
      instructions: "You are an expert software engineer specializing in debugging and repairs. You analyze error logs and provide intelligent fix suggestions.",
      model: openrouter("anthropic/claude-sonnet-4", {
        extraBody: {
          max_tokens: 4e3
        }
      })
    });
  }
  async startErrorMonitoring() {
    console.log("\u{1F50D} VoltAgent Error Monitoring started");
    const errorLogPath = join(process.cwd(), "errors.txt");
    if (!existsSync(errorLogPath)) {
      console.log("\u26A0\uFE0F No errors.txt file found. Creating empty file...");
      return;
    }
    try {
      const errors = await this.parseErrorLog();
      if (errors.length > 0) {
        console.log(`\u{1F4CA} Found ${errors.length} errors to analyze`);
        await this.processErrors(errors);
      } else {
        console.log("\u2705 No errors found");
      }
    } catch (error) {
      console.error("\u274C Error in VoltAgent monitoring:", error);
    }
  }
  async parseErrorLog() {
    const errorLogPath = join(process.cwd(), "errors.txt");
    const content = readFileSync(errorLogPath, "utf-8");
    const errors = [];
    const lines = content.split("\n");
    for (let i = 0; i < lines.length; i++) {
      const line = lines[i];
      if (line.includes("[IMPORT]") || line.includes("[ESLINT]")) {
        const error = {
          type: line.includes("[IMPORT]") ? "IMPORT" : "ESLINT",
          severity: this.extractSeverity(line),
          message: this.extractMessage(lines, i),
          file: this.extractFile(lines, i),
          line: this.extractLine(lines, i),
          autoFixable: line.includes("\u2705")
        };
        errors.push(error);
      }
    }
    return errors;
  }
  extractSeverity(line) {
    if (line.includes("CRITICAL")) return "CRITICAL";
    if (line.includes("MEDIUM")) return "MEDIUM";
    if (line.includes("LOW")) return "LOW";
    return "UNKNOWN";
  }
  extractMessage(lines, startIndex) {
    for (let i = startIndex + 1; i < startIndex + 10 && i < lines.length; i++) {
      if (lines[i].includes("Message:")) {
        return lines[i].replace("Message:", "").trim();
      }
    }
    return "No message found";
  }
  extractFile(lines, startIndex) {
    for (let i = startIndex + 1; i < startIndex + 10 && i < lines.length; i++) {
      if (lines[i].includes("File:")) {
        return lines[i].replace("File:", "").trim();
      }
    }
    return "Unknown file";
  }
  extractLine(lines, startIndex) {
    for (let i = startIndex + 1; i < startIndex + 10 && i < lines.length; i++) {
      if (lines[i].includes("Line:")) {
        const lineMatch = lines[i].match(/Line:\s*(\d+)/);
        return lineMatch ? parseInt(lineMatch[1]) : 0;
      }
    }
    return 0;
  }
  async processErrors(errors) {
    console.log("\u{1F527} Processing errors with VoltAgent...");
    for (const error of errors.slice(0, 5)) {
      if (error.autoFixable) {
        console.log(`\u{1F528} Auto-fixing ${error.type} error in ${error.file}`);
        await this.autoFixError(error);
      } else {
        console.log(
          `\u26A0\uFE0F Manual fix required for ${error.type} error in ${error.file}`
        );
        await this.suggestFix(error);
      }
    }
  }
  async autoFixError(error) {
    try {
      console.log(`   Analyzing: ${error.message}`);
      console.log(`   File: ${error.file}:${error.line}`);
      const response = await this.errorFixAgent.generateText(
        `Analyze this ${error.type} error and provide a fix:

Error: ${error.message}
File: ${error.file}
Line: ${error.line}`
      );
      console.log(`   \u2705 AI Fix Suggestion: ${response.text}`);
    } catch (error2) {
      console.error("\u274C Auto-fix failed:", error2);
    }
  }
  async suggestFix(error) {
    try {
      console.log(`   Analyzing: ${error.message}`);
      console.log(`   File: ${error.file}:${error.line}`);
      const response = await this.errorFixAgent.generateText(
        `Analyze this ${error.type} error and provide a fix:

Error: ${error.message}
File: ${error.file}
Line: ${error.line}`
      );
      console.log(`   \u{1F4A1} AI Fix Suggestion: ${response.text}`);
    } catch (error2) {
      console.error("\u274C Fix suggestion failed:", error2);
    }
  }
  async runWorkflow() {
    console.log("\u{1F680} Starting VoltAgent Error Fix Workflow");
    const errors = await this.parseErrorLog();
    if (errors.length === 0) {
      console.log("\u2705 No errors to process");
      return;
    }
    console.log(`\u{1F4CA} Processing ${Math.min(errors.length, 5)} errors...`);
    for (const error of errors.slice(0, 5)) {
      console.log(`
\u{1F50D} Processing ${error.type} error:`);
      console.log(`   File: ${error.file}`);
      console.log(`   Message: ${error.message}`);
      console.log(`   Severity: ${error.severity}`);
      console.log(`   Auto-fixable: ${error.autoFixable ? "Yes" : "No"}`);
      try {
        const response = await this.errorFixAgent.generateText(
          `Provide a detailed fix for this ${error.type} error:

Error: ${error.message}
File: ${error.file}
Line: ${error.line}

Provide the fix in this format:
1. Root cause analysis
2. Suggested fix
3. Additional notes`
        );
        console.log(`   \u{1F916} AI Analysis: ${response.text}`);
      } catch (aiError) {
        console.log(`   \u26A0\uFE0F AI analysis failed: ${aiError}`);
      }
    }
    console.log("\n\u2705 VoltAgent workflow completed");
  }
  /**
   * Fix a specific error using VoltAgent AI agents
   */
  async fixError(errorContext, fragmentFiles, sandbox) {
    console.log(`
[VoltAgent] ============================================`);
    console.log(`[VoltAgent] Fixing error ${errorContext.id}`);
    console.log(`[VoltAgent]   Type: ${errorContext.type}`);
    console.log(`[VoltAgent]   Severity: ${errorContext.severity}`);
    console.log(`[VoltAgent]   Details:`, errorContext.details);
    try {
      const {
        createErrorClassifierAgent,
        createRepairAgent,
        createValidatorAgent
      } = await import("./voltagent-agents-2V5JSSSL.js");
      const classifierAgent = createErrorClassifierAgent();
      const classificationPrompt = `Analyze this error and categorize it:

Error Type: ${errorContext.type}
Error Details: ${JSON.stringify(errorContext.details, null, 2)}
Severity: ${errorContext.severity}

Categorize as one of: Syntax, Missing Import / Undefined Variable, Type Mismatch, API Misuse, Configuration/Environment, or Other.
Provide the category and a brief explanation.`;
      const classificationResult = await classifierAgent.generateText(
        classificationPrompt
      );
      const classification = classificationResult.text;
      console.log(`[VoltAgent] Error classification: ${classification}`);
      const strategy = this.determineFixStrategy(classification, errorContext);
      console.log(`[VoltAgent] Fix strategy: ${strategy}`);
      const fixedFiles = {};
      const changes = [];
      switch (strategy) {
        case "import_fix":
          await this.fixImportError(
            errorContext,
            fragmentFiles,
            fixedFiles,
            changes,
            sandbox
          );
          break;
        case "syntax_fix":
          await this.fixSyntaxError(
            errorContext,
            fragmentFiles,
            fixedFiles,
            changes,
            sandbox
          );
          break;
        case "type_fix":
          await this.fixTypeError(
            errorContext,
            fragmentFiles,
            fixedFiles,
            changes,
            sandbox
          );
          break;
        case "navigation_fix":
          await this.fixNavigationError(
            errorContext,
            fragmentFiles,
            fixedFiles,
            changes,
            sandbox
          );
          break;
        default:
          return {
            success: false,
            reason: `Unsupported fix strategy: ${strategy}`
          };
      }
      console.log(`[VoltAgent] Validating fix...`);
      console.log(`[VoltAgent]   Changes: ${changes.length} changes made`);
      console.log(`[VoltAgent]   Fixed files: ${Object.keys(fixedFiles).length} files`);
      const fixedFile = Object.keys(fixedFiles)[0];
      const fixedContent = fixedFiles[fixedFile];
      const originalContent = await this.getFileContent(fixedFile, fragmentFiles, sandbox);
      if (originalContent) {
        const changesApplied = this.verifyChangesApplied(
          originalContent,
          fixedContent,
          errorContext
        );
        if (!changesApplied.hasChanges) {
          console.log(`[VoltAgent]   \u274C Validation FAILED: No meaningful changes detected`);
          console.log(`[VoltAgent]   Reason: ${changesApplied.reason}`);
          return {
            success: false,
            reason: `LLM did not make meaningful changes. ${changesApplied.reason}`
          };
        }
        console.log(`[VoltAgent]   \u2705 Diff check passed: ${changesApplied.description}`);
      }
      console.log(`[VoltAgent]   Running LLM validation...`);
      const validatorAgent = createValidatorAgent();
      const validationPrompt = `Review this fix for the error:

Original Error: ${JSON.stringify(errorContext.details, null, 2)}
Strategy: ${strategy}
Changes Made: ${changes.join(", ")}

Does this fix logically resolve the root cause? Respond with 'VALID' or 'INVALID' followed by reasoning.`;
      const validationResult = await validatorAgent.generateText(
        validationPrompt
      );
      const isValid = validationResult.text.toLowerCase().includes("valid") && !validationResult.text.toLowerCase().includes("invalid");
      console.log(`[VoltAgent]   LLM validation result: ${validationResult.text.substring(0, 200)}`);
      console.log(`[VoltAgent]   Is valid: ${isValid}`);
      if (!isValid) {
        console.log(
          `[VoltAgent]   \u274C LLM validation failed: ${validationResult.text}`
        );
        return {
          success: false,
          reason: `Fix validation failed: ${validationResult.text}`
        };
      }
      console.log(`[VoltAgent]   \u2705 LLM validation passed`);
      console.log(
        `[VoltAgent] Successfully fixed error ${errorContext.id} with strategy: ${strategy}`
      );
      return {
        success: true,
        strategy,
        fixedFiles,
        changes
      };
    } catch (error) {
      console.error(`[VoltAgent] Error fixing ${errorContext.id}:`, error);
      return {
        success: false,
        reason: error instanceof Error ? error.message : "Unknown error during fix"
      };
    }
  }
  /**
   * Try to get file content from available sources
   */
  async getFileContent(filePath, fragmentFiles, sandbox) {
    if (fragmentFiles[filePath]) {
      return fragmentFiles[filePath];
    }
    if (sandbox) {
      try {
        console.log(
          `[VoltAgent] File not in fragments, attempting to fetch from sandbox: ${filePath}`
        );
        const { readFileFromSandbox: readFileFromSandbox2 } = await import("./sandbox-compat-BT5IRDYW.js");
        const possiblePaths = [
          filePath,
          filePath.startsWith("/") ? filePath.substring(1) : filePath,
          filePath.startsWith("src/") ? filePath : `src/${filePath}`,
          filePath.replace(/^\/home\/daytona\/workspace\//, "")
        ];
        for (const path of possiblePaths) {
          try {
            const content = await readFileFromSandbox2(sandbox, path);
            if (content) {
              console.log(
                `[VoltAgent] Successfully fetched file from sandbox: ${path}`
              );
              return content;
            }
          } catch (err) {
            continue;
          }
        }
      } catch (error) {
        console.warn(
          `[VoltAgent] Failed to fetch file from sandbox: ${filePath}`,
          error
        );
      }
    }
    return null;
  }
  /**
   * Verify that meaningful changes were actually applied for IMPORT errors only
   * For other error types, we skip validation to avoid interfering with their fix logic
   */
  verifyChangesApplied(originalContent, fixedContent, errorContext) {
    const errorTypeStr = errorContext.type?.toString().toUpperCase();
    if (errorTypeStr !== "IMPORT") {
      console.log(`[VoltAgent]   Skipping change verification for non-import error (type: ${errorTypeStr})`);
      return {
        hasChanges: true,
        // Assume changes are valid for non-import errors
        reason: "",
        description: "Validation skipped (not an import error)"
      };
    }
    console.log(`[VoltAgent]   Validating import error fix...`);
    if (originalContent === fixedContent) {
      return {
        hasChanges: false,
        reason: "Content is identical to original",
        description: ""
      };
    }
    const normalizeWhitespace = (str) => str.replace(/\s+/g, " ").trim();
    const originalNormalized = normalizeWhitespace(originalContent);
    const fixedNormalized = normalizeWhitespace(fixedContent);
    if (originalNormalized === fixedNormalized) {
      return {
        hasChanges: false,
        reason: "Only whitespace/formatting changes detected",
        description: ""
      };
    }
    const originalImport = errorContext.details?.importPath;
    if (originalImport) {
      const importRegex = new RegExp(`from\\s+['"]${originalImport.replace(/[.*+?^${}()|[\]\\]/g, "\\$&")}['"]`, "g");
      const stillHasOldImport = importRegex.test(fixedContent);
      if (stillHasOldImport) {
        return {
          hasChanges: false,
          reason: `Problematic import '${originalImport}' was not changed`,
          description: ""
        };
      }
    }
    const originalLines = originalContent.split("\n");
    const fixedLines = fixedContent.split("\n");
    const linesChanged = Math.abs(originalLines.length - fixedLines.length);
    let changedLineCount = 0;
    const maxLines = Math.max(originalLines.length, fixedLines.length);
    for (let i = 0; i < maxLines; i++) {
      if (originalLines[i] !== fixedLines[i]) {
        changedLineCount++;
      }
    }
    return {
      hasChanges: true,
      reason: "",
      description: `${changedLineCount} lines modified, ${linesChanged} lines added/removed`
    };
  }
  /**
   * Determine fix strategy based on error classification
   */
  determineFixStrategy(classification, errorContext) {
    const lowerClassification = classification.toLowerCase();
    const errorTypeStr = errorContext.type?.toString().toUpperCase();
    if (errorTypeStr === "NAVIGATION") {
      return "navigation_fix";
    }
    if (errorTypeStr === "IMPORT") {
      return "import_fix";
    }
    if (lowerClassification.includes("import") || lowerClassification.includes("undefined variable")) {
      return "import_fix";
    }
    if (lowerClassification.includes("syntax")) {
      return "syntax_fix";
    }
    if (lowerClassification.includes("type")) {
      return "type_fix";
    }
    if (lowerClassification.includes("navigation") || lowerClassification.includes("api misuse")) {
      return "navigation_fix";
    }
    return "syntax_fix";
  }
  /**
   * Fix import-related errors using LLM
   */
  async fixImportError(errorContext, fragmentFiles, fixedFiles, changes, sandbox) {
    const errorFile = errorContext.details?.file || Object.keys(fragmentFiles)[0];
    const importPath = errorContext.details?.importPath;
    const reason = errorContext.details?.reason;
    const suggestion = errorContext.details?.suggestion;
    console.log(`[AutoFix] Fixing import error with LLM: ${reason || "unknown"}`);
    console.log(`[AutoFix]   File: ${errorFile}`);
    console.log(`[AutoFix]   Import: ${importPath}`);
    console.log(`[AutoFix]   Suggestion: ${suggestion || "none"}`);
    await this.fixImportErrorWithLLM(errorContext, fragmentFiles, fixedFiles, changes, sandbox);
  }
  /**
   * Fallback LLM-based import error fixing (original implementation)
   */
  async fixImportErrorWithLLM(errorContext, fragmentFiles, fixedFiles, changes, sandbox) {
    const { createRepairAgent } = await import("./voltagent-agents-2V5JSSSL.js");
    const repairAgent = createRepairAgent();
    const errorFile = errorContext.details?.file || Object.keys(fragmentFiles)[0];
    const fileContent = await this.getFileContent(errorFile, fragmentFiles, sandbox);
    if (!fileContent) {
      throw new Error(`File not found: ${errorFile}. Tried fragments and sandbox.`);
    }
    console.log(`[AutoFix]   Using LLM to fix import in: ${errorFile}`);
    const importPath = errorContext.details?.importPath;
    const reason = errorContext.details?.reason;
    const suggestion = errorContext.details?.suggestion;
    const candidates = errorContext.details?.candidates;
    let contextHints = "";
    if (reason === "unresolved" && suggestion) {
      contextHints += `
Suggested fix: ${suggestion}`;
    }
    if (candidates && candidates.length > 0 && candidates.length <= 5) {
      contextHints += `
Attempted paths (not found): ${candidates.slice(0, 5).join(", ")}`;
    }
    if (importPath?.startsWith("@/")) {
      contextHints += `
Note: This project uses '@/' alias for 'src/' directory`;
    }
    const repairPrompt = `Fix this import error:

Import: ${importPath || "unknown"}
Error: ${reason || errorContext.details?.message || "unresolved"}${contextHints}

File: ${errorFile}
\`\`\`
${fileContent}

IMPORTANT: If the error mentions "does not provide an export named 'default'", you need to add a DEFAULT export, not a named export.

For React components, use ONE of these patterns:
- Add "export default App;" at the end of the file
- OR change "function App()" to "export default function App()"

Do NOT use "export function App()" as that creates a named export, not a default export.

Respond ONLY with the corrected code, no explanations, no markdown formatting, no code blocks. Return raw TypeScript/JavaScript code only.`;
    const repairResult = await repairAgent.generateText(repairPrompt);
    let cleanedCode = repairResult.text.trim();
    if (cleanedCode.startsWith("```")) {
      cleanedCode = cleanedCode.replace(/^```[a-z]*\n?/i, "").replace(/\n?```$/, "");
    }
    cleanedCode = cleanedCode.trim();
    console.log(`[VoltAgent] Generated fix for file: ${errorFile}`);
    console.log(`[VoltAgent] Fixed content length: ${cleanedCode.length}`);
    console.log(
      `[VoltAgent] Fixed content preview:`,
      cleanedCode.substring(0, 200) + "..."
    );
    fixedFiles[errorFile] = cleanedCode;
    changes.push(`Fixed import error in ${errorFile} (LLM)`);
  }
  /**
   * Fix syntax-related errors
   */
  async fixSyntaxError(errorContext, fragmentFiles, fixedFiles, changes, sandbox) {
    const { createRepairAgent } = await import("./voltagent-agents-2V5JSSSL.js");
    const repairAgent = createRepairAgent();
    const errorFile = errorContext.details?.file || Object.keys(fragmentFiles)[0];
    const fileContent = await this.getFileContent(
      errorFile,
      fragmentFiles,
      sandbox
    );
    if (!fileContent) {
      throw new Error(
        `File not found: ${errorFile}. Tried fragments and sandbox.`
      );
    }
    const repairPrompt = `Fix this syntax error in the following code:

Error: ${JSON.stringify(errorContext.details, null, 2)}

File Content:
${fileContent}

Fix the syntax issue. Respond ONLY with the corrected code, no explanations, no markdown formatting, no code blocks. Return raw TypeScript/JavaScript code only.`;
    const repairResult = await repairAgent.generateText(repairPrompt);
    let cleanedCode = repairResult.text.trim();
    if (cleanedCode.startsWith("```")) {
      cleanedCode = cleanedCode.replace(/^```[a-z]*\n?/i, "").replace(/\n?```$/, "");
    }
    cleanedCode = cleanedCode.trim();
    fixedFiles[errorFile] = cleanedCode;
    changes.push(`Fixed syntax error in ${errorFile}`);
  }
  /**
   * Fix type-related errors
   */
  async fixTypeError(errorContext, fragmentFiles, fixedFiles, changes, sandbox) {
    const { createRepairAgent } = await import("./voltagent-agents-2V5JSSSL.js");
    const repairAgent = createRepairAgent();
    const errorFile = errorContext.details?.file || Object.keys(fragmentFiles)[0];
    const fileContent = await this.getFileContent(
      errorFile,
      fragmentFiles,
      sandbox
    );
    if (!fileContent) {
      throw new Error(
        `File not found: ${errorFile}. Tried fragments and sandbox.`
      );
    }
    const repairPrompt = `Fix this TypeScript type error in the following code:

Error: ${JSON.stringify(errorContext.details, null, 2)}

File Content:
${fileContent}

Fix the type issue by adding proper types or correcting type mismatches. Respond ONLY with the corrected code, no explanations.`;
    const repairResult = await repairAgent.generateText(repairPrompt);
    fixedFiles[errorFile] = repairResult.text;
    changes.push(`Fixed type error in ${errorFile}`);
  }
  /**
   * Fix navigation-related errors
   */
  async fixNavigationError(errorContext, fragmentFiles, fixedFiles, changes, sandbox) {
    const { createRepairAgent } = await import("./voltagent-agents-2V5JSSSL.js");
    const repairAgent = createRepairAgent();
    const navFiles = Object.keys(fragmentFiles).filter(
      (file) => file.includes("nav") || file.includes("header") || file.includes("menu") || fragmentFiles[file].includes("href=") || fragmentFiles[file].includes("to=")
    );
    const targetFile = navFiles[0] || Object.keys(fragmentFiles)[0];
    const fileContent = await this.getFileContent(
      targetFile,
      fragmentFiles,
      sandbox
    );
    if (!fileContent) {
      throw new Error(
        `File not found: ${targetFile}. Tried fragments and sandbox.`
      );
    }
    const repairPrompt = `Fix this navigation error in the following code:

Error: ${JSON.stringify(errorContext.details, null, 2)}

File Content:
${fileContent}

Fix the broken route or navigation link. Respond ONLY with the corrected code, no explanations.`;
    const repairResult = await repairAgent.generateText(repairPrompt);
    fixedFiles[targetFile] = repairResult.text;
    changes.push(`Fixed navigation error in ${targetFile}`);
  }
};

// src/services/ai-tools.ts
import {
  decryptDeployKey,
  ConvexDeploymentAPI
} from "@shipper/convex";

// src/services/stripe-toolkit.ts
init_esm_shims();
import { StripeAgentToolkit } from "@stripe/agent-toolkit/ai-sdk";
async function validateStripeKey(secretKey) {
  try {
    const toolkit = new StripeAgentToolkit({
      secretKey,
      configuration: {
        actions: {
          balance: { read: true }
        }
      }
    });
    if (!secretKey.startsWith("sk_test_") && !secretKey.startsWith("sk_live_")) {
      return { valid: false, error: "Invalid Stripe API key format" };
    }
    return {
      valid: true,
      mode: secretKey.startsWith("sk_live_") ? "live" : "test"
    };
  } catch (error) {
    const message = error instanceof Error ? error.message : String(error);
    if (message.includes("Invalid API Key")) {
      return { valid: false, error: "Invalid Stripe API key" };
    }
    return { valid: false, error: message };
  }
}
function generateStripeActionCode(options) {
  return `"use node";

import { action } from "./_generated/server";
import { v } from "convex/values";
import Stripe from "stripe";

const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!, {
  apiVersion: "2024-11-20.acacia",
});

/**
 * Verify a completed checkout session
 * Called from the success page to confirm payment
 */
export const verifySession = action({
  args: { sessionId: v.string() },
  handler: async (ctx, { sessionId }) => {
    try {
      const session = await stripe.checkout.sessions.retrieve(sessionId);
      return {
        status: session.status,
        paymentStatus: session.payment_status,
        customerEmail: session.customer_details?.email,
        amountTotal: session.amount_total,
        currency: session.currency,
      };
    } catch (error) {
      const message = error instanceof Error ? error.message : "Stripe error";
      throw new Error(\`Session verification failed: \${message}\`);
    }
  },
});

/**
 * Get customer's subscriptions (for customer portal)
 */
export const getCustomerSubscriptions = action({
  args: { customerId: v.string() },
  handler: async (ctx, { customerId }) => {
    try {
      const subscriptions = await stripe.subscriptions.list({
        customer: customerId,
        status: "all",
        limit: 10,
      });

      return subscriptions.data.map(sub => ({
        id: sub.id,
        status: sub.status,
        currentPeriodEnd: sub.current_period_end,
        cancelAtPeriodEnd: sub.cancel_at_period_end,
      }));
    } catch (error) {
      const message = error instanceof Error ? error.message : "Stripe error";
      throw new Error(\`Failed to get subscriptions: \${message}\`);
    }
  },
});
`;
}
function generateStripeHttpCode(options) {
  const { mode, successUrl, cancelUrl } = options;
  return `import { httpRouter } from "convex/server";
import { httpAction } from "./_generated/server";
import { internal } from "./_generated/api";
import Stripe from "stripe";

const http = httpRouter();

const stripe = new Stripe(process.env.STRIPE_SECRET_KEY!, {
  apiVersion: "2024-11-20.acacia",
});

/**
 * Stripe Checkout - Redirect Flow
 * Opens Stripe's hosted checkout page in a new tab
 * 
 * Usage: <a href={\`\${import.meta.env.VITE_CONVEX_SITE_URL}/stripe/checkout?priceId=price_xxx\`} target="_blank">
 */
http.route({
  path: "/stripe/checkout",
  method: "GET",
  handler: httpAction(async (ctx, request) => {
    const url = new URL(request.url);
    const priceId = url.searchParams.get("priceId");
    // Get the app origin from query param (passed by frontend) or use referer
    const appOrigin = url.searchParams.get("origin") || request.headers.get("referer")?.replace(/\\/[^/]*$/, "") || "";

    if (!priceId) {
      return new Response("Missing priceId parameter", { status: 400 });
    }

    try {
      const session = await stripe.checkout.sessions.create({
        line_items: [{ price: priceId, quantity: 1 }],
        mode: "${mode}",
        success_url: \`\${appOrigin}${successUrl}?session_id={CHECKOUT_SESSION_ID}\`,
        cancel_url: \`\${appOrigin}${cancelUrl}\`,
      });

      // Redirect to Stripe's hosted checkout page
      return Response.redirect(session.url!, 303);
    } catch (error) {
      const message = error instanceof Error ? error.message : "Stripe error";
      console.error("Checkout error:", message);
      return new Response(\`Checkout failed: \${message}\`, { status: 500 });
    }
  }),
});

/**
 * Stripe Webhook Handler
 * Receives events from Stripe (payment completed, subscription updated, etc.)
 * 
 * To enable: Add webhook URL in Stripe Dashboard -> Developers -> Webhooks
 * URL: https://your-convex-deployment.convex.site/stripe/webhook
 * 
 * Required events to subscribe to:
 * - checkout.session.completed
 * - customer.subscription.created
 * - customer.subscription.updated  
 * - customer.subscription.deleted
 * - invoice.payment_failed
 */
http.route({
  path: "/stripe/webhook",
  method: "POST",
  handler: httpAction(async (ctx, request) => {
    const body = await request.text();
    const signature = request.headers.get("stripe-signature");

    if (!signature) {
      return new Response("Missing signature", { status: 400 });
    }

    const webhookSecret = process.env.STRIPE_WEBHOOK_SECRET;
    if (!webhookSecret) {
      // Webhook secret not configured - just log and accept
      console.log("STRIPE_WEBHOOK_SECRET not configured, skipping verification");
      return new Response(JSON.stringify({ received: true }), { status: 200 });
    }

    let event: Stripe.Event;

    try {
      event = stripe.webhooks.constructEvent(body, signature, webhookSecret);
    } catch (err) {
      const message = err instanceof Error ? err.message : "Unknown error";
      console.error(\`Webhook signature verification failed: \${message}\`);
      return new Response(\`Webhook Error: \${message}\`, { status: 400 });
    }

    // Handle the event
    switch (event.type) {
      case "checkout.session.completed": {
        const session = event.data.object as Stripe.Checkout.Session;
        console.log("\u2705 Checkout completed:", session.id);
        
        // Save payment to database
        await ctx.runMutation(internal.stripeWebhook.savePayment, {
          stripeSessionId: session.id,
          stripeCustomerId: session.customer as string | undefined,
          stripePaymentIntentId: session.payment_intent as string | undefined,
          stripeSubscriptionId: session.subscription as string | undefined,
          userEmail: session.customer_details?.email || undefined,
          amount: session.amount_total || 0,
          currency: session.currency || "usd",
          status: "completed",
          paymentType: session.mode === "subscription" ? "subscription" : "one_time",
          paidAt: Date.now(),
        });
        break;
      }

      case "customer.subscription.created":
      case "customer.subscription.updated": {
        const subscription = event.data.object as Stripe.Subscription;
        console.log("\u{1F4E6} Subscription updated:", subscription.id, subscription.status);
        
        // Update subscription in database
        await ctx.runMutation(internal.stripeWebhook.upsertSubscription, {
          stripeCustomerId: subscription.customer as string,
          stripeSubscriptionId: subscription.id,
          stripePriceId: subscription.items.data[0]?.price.id || "",
          status: subscription.status as "active" | "cancelled" | "past_due" | "unpaid" | "trialing",
          currentPeriodStart: subscription.current_period_start * 1000,
          currentPeriodEnd: subscription.current_period_end * 1000,
          cancelAtPeriodEnd: subscription.cancel_at_period_end,
        });
        break;
      }

      case "customer.subscription.deleted": {
        const subscription = event.data.object as Stripe.Subscription;
        console.log("\u274C Subscription cancelled:", subscription.id);
        
        // Mark subscription as cancelled
        await ctx.runMutation(internal.stripeWebhook.cancelSubscription, {
          stripeSubscriptionId: subscription.id,
        });
        break;
      }

      case "invoice.payment_failed": {
        const invoice = event.data.object as Stripe.Invoice;
        console.log("\u26A0\uFE0F Payment failed for invoice:", invoice.id);
        // Could add notification logic here
        break;
      }

      default:
        console.log(\`Unhandled event type: \${event.type}\`);
    }

    return new Response(JSON.stringify({ received: true }), {
      status: 200,
      headers: { "Content-Type": "application/json" },
    });
  }),
});

export default http;
`;
}
function generateCheckoutUICode() {
  return `/**
 * Stripe Checkout Button Component
 * Opens Stripe's hosted checkout page in a new tab
 * 
 * Usage:
 *   <CheckoutButton priceId="price_xxx" />
 *   <CheckoutButton priceId="price_xxx" label="Subscribe Now" />
 */

interface CheckoutButtonProps {
  priceId: string;
  label?: string;
  className?: string;
}

export function CheckoutButton({ priceId, label = "Buy Now", className }: CheckoutButtonProps) {
  // Pass origin so Stripe knows where to redirect back to
  const checkoutUrl = \`\${import.meta.env.VITE_CONVEX_SITE_URL}/stripe/checkout?priceId=\${priceId}&origin=\${encodeURIComponent(window.location.origin)}\`;

  return (
    <a
      href={checkoutUrl}
      target="_blank"
      rel="noopener noreferrer"
      className={className || "inline-flex items-center justify-center px-6 py-3 bg-blue-600 text-white font-medium rounded-lg hover:bg-blue-700 transition-colors"}
    >
      {label}
    </a>
  );
}
`;
}
function generateSuccessUICode(options) {
  const { returnRoute } = options;
  return `import { createFileRoute, useNavigate } from "@tanstack/react-router";
import { useConvex } from "convex/react";
import { api } from "../../convex/_generated/api";
import { useEffect, useState } from "react";

export const Route = createFileRoute("/checkout/success")({
  component: CheckoutSuccessPage,
});

function CheckoutSuccessPage() {
  const convex = useConvex();
  const navigate = useNavigate();
  const [status, setStatus] = useState<"loading" | "success" | "error">("loading");
  const [details, setDetails] = useState<{
    email?: string;
    amount?: number;
    currency?: string;
  } | null>(null);

  useEffect(() => {
    const searchParams = new URLSearchParams(window.location.search);
    const sessionId = searchParams.get("session_id");

    if (!sessionId) {
      setStatus("error");
      return;
    }

    convex
      .action(api.stripe.verifySession, { sessionId })
      .then((result) => {
        if (result.status === "complete" || result.paymentStatus === "paid") {
          setStatus("success");
          setDetails({
            email: result.customerEmail || undefined,
            amount: result.amountTotal ? result.amountTotal / 100 : undefined,
            currency: result.currency?.toUpperCase(),
          });
        } else {
          setStatus("error");
        }
      })
      .catch(() => setStatus("error"));
  }, [convex]);

  if (status === "loading") {
    return (
      <div className="min-h-screen flex items-center justify-center bg-gray-50 dark:bg-slate-900">
        <div className="text-center">
          <div className="animate-spin rounded-full h-12 w-12 border-b-2 border-blue-600 mx-auto mb-4"></div>
          <p className="text-gray-600 dark:text-gray-400">Verifying payment...</p>
        </div>
      </div>
    );
  }

  if (status === "error") {
    return (
      <div className="min-h-screen flex items-center justify-center bg-gray-50 dark:bg-slate-900">
        <div className="text-center p-8">
          <div className="text-red-500 text-6xl mb-4">\u274C</div>
          <h1 className="text-2xl font-bold text-gray-900 dark:text-white mb-2">
            Payment Failed
          </h1>
          <p className="text-gray-600 dark:text-gray-400 mb-6">
            Something went wrong with your payment.
          </p>
          <button
            onClick={() => navigate({ to: "${returnRoute}" })}
            className="px-6 py-3 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors"
          >
            Try Again
          </button>
        </div>
      </div>
    );
  }

  return (
    <div className="min-h-screen flex items-center justify-center bg-gray-50 dark:bg-slate-900">
      <div className="text-center p-8 max-w-md">
        <div className="text-green-500 text-6xl mb-4">\u2713</div>
        <h1 className="text-2xl font-bold text-gray-900 dark:text-white mb-2">
          Payment Successful!
        </h1>
        <p className="text-gray-600 dark:text-gray-400 mb-2">
          Thank you for your purchase.
        </p>
        {details?.email && (
          <p className="text-sm text-gray-500 dark:text-gray-500 mb-1">
            Confirmation sent to: {details.email}
          </p>
        )}
        {details?.amount && details?.currency && (
          <p className="text-sm text-gray-500 dark:text-gray-500 mb-6">
            Amount: {details.currency} {details.amount.toFixed(2)}
          </p>
        )}
        <button
          onClick={() => navigate({ to: "${returnRoute}" })}
          className="px-6 py-3 bg-blue-600 text-white rounded-lg hover:bg-blue-700 transition-colors"
        >
          Continue
        </button>
      </div>
    </div>
  );
}
`;
}
function generatePaymentsTableSnippet() {
  return `  // Add these tables to your existing schema.ts:

  payments: defineTable({
    userId: v.optional(v.string()),
    userEmail: v.optional(v.string()),
    stripeSessionId: v.string(),
    stripeCustomerId: v.optional(v.string()),
    stripePaymentIntentId: v.optional(v.string()),
    stripeSubscriptionId: v.optional(v.string()),
    priceId: v.optional(v.string()),
    amount: v.number(),
    currency: v.string(),
    status: v.union(v.literal("pending"), v.literal("completed"), v.literal("failed"), v.literal("refunded"), v.literal("cancelled")),
    paymentType: v.union(v.literal("one_time"), v.literal("subscription")),
    paidAt: v.optional(v.number()),
  })
    .index("by_user", ["userId"])
    .index("by_session", ["stripeSessionId"])
    .index("by_status", ["status"]),
`;
}
function generateStripeWebhookMutations() {
  return `import { internalMutation } from "./_generated/server";
import { v } from "convex/values";

/**
 * Save a completed payment to the database
 */
export const savePayment = internalMutation({
  args: {
    stripeSessionId: v.string(),
    stripeCustomerId: v.optional(v.string()),
    stripePaymentIntentId: v.optional(v.string()),
    stripeSubscriptionId: v.optional(v.string()),
    userEmail: v.optional(v.string()),
    amount: v.number(),
    currency: v.string(),
    status: v.union(
      v.literal("pending"),
      v.literal("completed"),
      v.literal("failed"),
      v.literal("refunded"),
      v.literal("cancelled")
    ),
    paymentType: v.union(v.literal("one_time"), v.literal("subscription")),
    paidAt: v.optional(v.number()),
  },
  handler: async (ctx, args) => {
    // Check if payment already exists (idempotency)
    const existing = await ctx.db
      .query("payments")
      .withIndex("by_session", (q) => q.eq("stripeSessionId", args.stripeSessionId))
      .first();

    if (existing) {
      // Update existing payment
      await ctx.db.patch(existing._id, {
        status: args.status,
        paidAt: args.paidAt,
      });
      return existing._id;
    }

    // Create new payment record
    return await ctx.db.insert("payments", args);
  },
});

/**
 * Create or update a subscription
 */
export const upsertSubscription = internalMutation({
  args: {
    stripeCustomerId: v.string(),
    stripeSubscriptionId: v.string(),
    stripePriceId: v.string(),
    status: v.union(
      v.literal("active"),
      v.literal("cancelled"),
      v.literal("past_due"),
      v.literal("unpaid"),
      v.literal("trialing")
    ),
    currentPeriodStart: v.number(),
    currentPeriodEnd: v.number(),
    cancelAtPeriodEnd: v.boolean(),
  },
  handler: async (ctx, args) => {
    // Find existing subscription
    const existing = await ctx.db
      .query("subscriptions")
      .withIndex("by_subscription", (q) => q.eq("stripeSubscriptionId", args.stripeSubscriptionId))
      .first();

    if (existing) {
      // Update existing subscription
      await ctx.db.patch(existing._id, {
        status: args.status,
        currentPeriodStart: args.currentPeriodStart,
        currentPeriodEnd: args.currentPeriodEnd,
        cancelAtPeriodEnd: args.cancelAtPeriodEnd,
      });
      return existing._id;
    }

    // Create new subscription (need userId - you may want to look this up by stripeCustomerId)
    return await ctx.db.insert("subscriptions", {
      userId: "", // TODO: Look up userId by stripeCustomerId from your users table
      ...args,
    });
  },
});

/**
 * Mark a subscription as cancelled
 */
export const cancelSubscription = internalMutation({
  args: {
    stripeSubscriptionId: v.string(),
  },
  handler: async (ctx, { stripeSubscriptionId }) => {
    const subscription = await ctx.db
      .query("subscriptions")
      .withIndex("by_subscription", (q) => q.eq("stripeSubscriptionId", stripeSubscriptionId))
      .first();

    if (subscription) {
      await ctx.db.patch(subscription._id, {
        status: "cancelled",
      });
    }
  },
});
`;
}

// src/services/connectors/index.ts
init_esm_shims();

// src/services/connectors/registry.ts
init_esm_shims();

// src/services/connectors/encryption.ts
init_esm_shims();
import crypto from "crypto";
var ALGORITHM = "aes-256-gcm";
var IV_LENGTH = 16;
function getEncryptionKey() {
  const key = process.env.SECRETS_ENCRYPTION_KEY;
  if (!key) {
    throw new Error(
      "SECRETS_ENCRYPTION_KEY environment variable is required for connector encryption"
    );
  }
  if (key.length !== 64) {
    throw new Error(
      "SECRETS_ENCRYPTION_KEY must be 64 hex characters (32 bytes)"
    );
  }
  return Buffer.from(key, "hex");
}
function encrypt(plaintext) {
  const key = getEncryptionKey();
  const iv = crypto.randomBytes(IV_LENGTH);
  const cipher = crypto.createCipheriv(ALGORITHM, key, iv);
  let encrypted = cipher.update(plaintext, "utf8", "hex");
  encrypted += cipher.final("hex");
  const authTag = cipher.getAuthTag();
  return `${iv.toString("hex")}:${authTag.toString("hex")}:${encrypted}`;
}
function decrypt(ciphertext) {
  const key = getEncryptionKey();
  const parts = ciphertext.split(":");
  if (parts.length !== 3) {
    throw new Error("Invalid encrypted format");
  }
  const [ivHex, authTagHex, encrypted] = parts;
  const iv = Buffer.from(ivHex, "hex");
  const authTag = Buffer.from(authTagHex, "hex");
  const decipher = crypto.createDecipheriv(ALGORITHM, key, iv);
  decipher.setAuthTag(authTag);
  let decrypted = decipher.update(encrypted, "hex", "utf8");
  decrypted += decipher.final("utf8");
  return decrypted;
}
function encryptCredentials(credentials) {
  return encrypt(JSON.stringify(credentials));
}

// src/services/connectors/registry.ts
var ConnectorRegistry = class {
  constructor() {
    this.personalConnectors = /* @__PURE__ */ new Map();
    this.sharedConnectors = /* @__PURE__ */ new Map();
  }
  /**
   * Register a personal connector (Notion, Linear, etc.)
   */
  registerPersonal(connector) {
    this.personalConnectors.set(connector.id, connector);
  }
  /**
   * Register a shared connector (Stripe, Supabase, etc.)
   */
  registerShared(connector) {
    this.sharedConnectors.set(connector.id, connector);
  }
  // ==========================================================================
  // Discovery Methods
  // ==========================================================================
  /**
   * Get all available personal connectors
   */
  listPersonalConnectors() {
    return Array.from(this.personalConnectors.values());
  }
  /**
   * Get all available shared connectors
   */
  listSharedConnectors() {
    return Array.from(this.sharedConnectors.values());
  }
  /**
   * Get a specific personal connector by provider
   */
  getPersonalConnector(provider) {
    return this.personalConnectors.get(provider);
  }
  /**
   * Get a specific shared connector by type
   */
  getSharedConnector(type) {
    return this.sharedConnectors.get(type);
  }
  // ==========================================================================
  // User Connection Methods
  // ==========================================================================
  /**
   * Get all personal connections for a user
   */
  async getUserPersonalConnections(userId) {
    const connections = await prisma.personalConnector.findMany({
      where: { userId },
      orderBy: { createdAt: "desc" }
    });
    return connections.map((conn) => ({
      id: conn.id,
      provider: conn.provider,
      status: conn.status,
      metadata: conn.metadata,
      connectedAt: conn.createdAt,
      lastUsedAt: conn.lastUsedAt ?? void 0,
      errorMessage: conn.errorMessage ?? void 0
    }));
  }
  /**
   * Get a specific personal connection
   */
  async getUserPersonalConnection(userId, provider) {
    const connection = await prisma.personalConnector.findFirst({
      where: { userId, provider }
    });
    if (!connection) return null;
    return {
      id: connection.id,
      provider: connection.provider,
      status: connection.status,
      metadata: connection.metadata,
      connectedAt: connection.createdAt,
      lastUsedAt: connection.lastUsedAt ?? void 0,
      errorMessage: connection.errorMessage ?? void 0
    };
  }
  /**
   * Get decrypted access token for a personal connection
   */
  async getPersonalAccessToken(userId, provider) {
    const connection = await prisma.personalConnector.findFirst({
      where: { userId, provider, status: "ACTIVE" }
    });
    if (!connection) {
      return null;
    }
    if (connection.expiresAt && connection.expiresAt < /* @__PURE__ */ new Date()) {
      const connector = this.getPersonalConnector(provider);
      if (!connector?.refreshToken || !connection.refreshToken) {
        return null;
      }
      try {
        const decryptedRefresh = decrypt(connection.refreshToken);
        const metadata = connection.metadata;
        const newTokens = await connector.refreshToken(
          decryptedRefresh,
          metadata
        );
        await prisma.personalConnector.update({
          where: { id: connection.id },
          data: {
            accessToken: encrypt(newTokens.accessToken),
            refreshToken: newTokens.refreshToken ? encrypt(newTokens.refreshToken) : connection.refreshToken,
            expiresAt: newTokens.expiresAt,
            status: "ACTIVE",
            errorMessage: null
          }
        });
        return newTokens.accessToken;
      } catch (error) {
        await prisma.personalConnector.update({
          where: { id: connection.id },
          data: {
            status: "EXPIRED",
            errorMessage: `Token refresh failed: ${error instanceof Error ? error.message : String(error)}`
          }
        });
        return null;
      }
    }
    return decrypt(connection.accessToken);
  }
  // ==========================================================================
  // Team/Project Connection Methods
  // ==========================================================================
  /**
   * Get all shared connections for a team
   */
  async getTeamSharedConnections(teamId) {
    const connections = await prisma.sharedConnector.findMany({
      where: { teamId },
      orderBy: { createdAt: "desc" }
    });
    return connections.map((conn) => ({
      id: conn.id,
      connectorType: conn.connectorType,
      name: conn.name ?? void 0,
      status: conn.status,
      enabled: conn.enabled,
      configuredAt: conn.createdAt,
      configuredBy: conn.createdById,
      lastUsedAt: conn.lastUsedAt ?? void 0,
      errorMessage: conn.errorMessage ?? void 0
    }));
  }
  /**
   * Get all shared connections for a project
   */
  async getProjectSharedConnections(projectId) {
    const connections = await prisma.sharedConnector.findMany({
      where: { projectId },
      orderBy: { createdAt: "desc" }
    });
    return connections.map((conn) => ({
      id: conn.id,
      connectorType: conn.connectorType,
      name: conn.name ?? void 0,
      status: conn.status,
      enabled: conn.enabled,
      configuredAt: conn.createdAt,
      configuredBy: conn.createdById,
      lastUsedAt: conn.lastUsedAt ?? void 0,
      errorMessage: conn.errorMessage ?? void 0
    }));
  }
  /**
   * Get decrypted credentials for a shared connection
   */
  async getSharedCredentials(connectionId) {
    const connection = await prisma.sharedConnector.findUnique({
      where: { id: connectionId }
    });
    if (!connection || !connection.enabled || connection.status !== "ACTIVE") {
      return null;
    }
    try {
      const decrypted = decrypt(connection.credentials);
      return JSON.parse(decrypted);
    } catch {
      return null;
    }
  }
  // ==========================================================================
  // Full State Methods
  // ==========================================================================
  /**
   * Get complete connector state for a user (for settings page)
   */
  async getConnectorState(userId, teamId) {
    const [personalConnections, sharedConnections] = await Promise.all([
      this.getUserPersonalConnections(userId),
      teamId ? this.getTeamSharedConnections(teamId) : Promise.resolve([])
    ]);
    return {
      personal: {
        available: this.listPersonalConnectors(),
        connected: personalConnections
      },
      shared: {
        available: this.listSharedConnectors(),
        configured: sharedConnections
      }
    };
  }
};
var connectorRegistry = new ConnectorRegistry();

// src/services/connectors/personal/notion.ts
init_esm_shims();
import crypto2 from "crypto";
function generateCodeVerifier() {
  return crypto2.randomBytes(32).toString("base64url");
}
function generateCodeChallenge(verifier) {
  return crypto2.createHash("sha256").update(verifier).digest("base64url");
}
var NOTION_CLIENT_ID = process.env.NOTION_CLIENT_ID || "";
var NOTION_CLIENT_SECRET = process.env.NOTION_CLIENT_SECRET || "";
var NOTION_REDIRECT_URI = process.env.NOTION_REDIRECT_URI || "http://localhost:3000/api/connectors/notion/callback";
var NOTION_MCP_SERVER_URL = "https://mcp.notion.com/mcp";
var dcrCredentialsCache = /* @__PURE__ */ new Map();
var DCR_CACHE_TTL = 24 * 60 * 60 * 1e3;
async function discoverOAuthEndpoints() {
  const response = await fetch(NOTION_MCP_SERVER_URL, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({ jsonrpc: "2.0", method: "initialize", id: 1 })
  });
  if (response.status === 401) {
    const wwwAuth = response.headers.get("WWW-Authenticate");
    if (wwwAuth) {
      const match = wwwAuth.match(/resource_metadata="([^"]+)"/);
      if (match) {
        const metadataUrl = match[1];
        const metadataResponse = await fetch(metadataUrl);
        const metadata = await metadataResponse.json();
        return {
          authorizationEndpoint: metadata.authorization_endpoint,
          tokenEndpoint: metadata.token_endpoint,
          registrationEndpoint: metadata.registration_endpoint
        };
      }
    }
  }
  const wellKnownUrl = new URL(NOTION_MCP_SERVER_URL);
  wellKnownUrl.pathname = "/.well-known/oauth-authorization-server";
  try {
    const metadataResponse = await fetch(wellKnownUrl.toString());
    if (metadataResponse.ok) {
      const metadata = await metadataResponse.json();
      return {
        authorizationEndpoint: metadata.authorization_endpoint,
        tokenEndpoint: metadata.token_endpoint,
        registrationEndpoint: metadata.registration_endpoint
      };
    }
  } catch (e) {
  }
  return {
    authorizationEndpoint: "https://mcp.notion.com/oauth/authorize",
    tokenEndpoint: "https://mcp.notion.com/oauth/token",
    registrationEndpoint: "https://mcp.notion.com/oauth/register"
  };
}
async function registerDynamicClient(registrationEndpoint, redirectUri) {
  const response = await fetch(registrationEndpoint, {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      client_name: "Shipper Builder",
      redirect_uris: [redirectUri],
      grant_types: ["authorization_code", "refresh_token"],
      response_types: ["code"],
      token_endpoint_auth_method: "client_secret_basic"
    })
  });
  if (!response.ok) {
    const error = await response.text();
    throw new Error(`DCR registration failed: ${error}`);
  }
  const data = await response.json();
  return {
    clientId: data.client_id,
    clientSecret: data.client_secret
  };
}
async function getDCRCredentials(redirectUri) {
  const cached = dcrCredentialsCache.get(redirectUri);
  if (cached && Date.now() - cached.cachedAt < DCR_CACHE_TTL) {
    return cached;
  }
  const endpoints = await discoverOAuthEndpoints();
  let dcrCredentials;
  if (endpoints.registrationEndpoint) {
    const credentials = await registerDynamicClient(
      endpoints.registrationEndpoint,
      redirectUri
    );
    dcrCredentials = {
      ...credentials,
      authorizationEndpoint: endpoints.authorizationEndpoint,
      tokenEndpoint: endpoints.tokenEndpoint,
      cachedAt: Date.now()
    };
  } else {
    dcrCredentials = {
      clientId: process.env.NOTION_CLIENT_ID || "",
      clientSecret: process.env.NOTION_CLIENT_SECRET,
      authorizationEndpoint: "https://api.notion.com/v1/oauth/authorize",
      tokenEndpoint: "https://api.notion.com/v1/oauth/token",
      cachedAt: Date.now()
    };
  }
  dcrCredentialsCache.set(redirectUri, dcrCredentials);
  return dcrCredentials;
}
var notionConnector = {
  id: "NOTION",
  name: "Notion",
  description: "Access your Notion pages and databases to bring context into your builds",
  icon: "/icons/notion.svg",
  auth: {
    type: "mcp",
    authUrl: "https://mcp.notion.com/oauth/authorize",
    // Will be discovered via DCR
    tokenUrl: "https://mcp.notion.com/oauth/token",
    // Will be discovered via DCR
    mcpServerUrl: NOTION_MCP_SERVER_URL,
    scopes: []
  },
  capabilities: {
    read: ["pages", "databases", "blocks", "comments"],
    write: []
    // Read-only for now
  },
  /**
   * Generate OAuth authorization URL for Notion MCP
   * Uses Dynamic Client Registration (DCR) for full workspace access
   */
  getAuthUrl(redirectUri, state) {
    const codeVerifier = generateCodeVerifier();
    const codeChallenge = generateCodeChallenge(codeVerifier);
    const stateWithPKCE = JSON.stringify({
      originalState: state,
      codeVerifier
    });
    const params = new URLSearchParams({
      client_id: NOTION_CLIENT_ID,
      redirect_uri: redirectUri,
      response_type: "code",
      owner: "user",
      state: Buffer.from(stateWithPKCE).toString("base64"),
      code_challenge: codeChallenge,
      code_challenge_method: "S256"
    });
    return `https://api.notion.com/v1/oauth/authorize?${params.toString()}`;
  },
  /**
   * Exchange authorization code for access token
   */
  async handleCallback(code, redirectUri, stateParam) {
    let clientId = NOTION_CLIENT_ID;
    let clientSecret = NOTION_CLIENT_SECRET;
    let tokenUrl = "https://api.notion.com/v1/oauth/token";
    let codeVerifier;
    if (stateParam) {
      try {
        const stateData = JSON.parse(
          Buffer.from(stateParam, "base64").toString()
        );
        codeVerifier = stateData.codeVerifier;
      } catch (e) {
      }
    }
    let usingDCR = false;
    try {
      const dcrCreds = await getDCRCredentials(redirectUri);
      clientId = dcrCreds.clientId;
      clientSecret = dcrCreds.clientSecret || "";
      tokenUrl = dcrCreds.tokenEndpoint;
      usingDCR = true;
      console.log("[Notion] Using DCR credentials:", {
        clientId: clientId.substring(0, 20) + "...",
        tokenUrl
      });
    } catch (e) {
      console.log(
        "[Notion] DCR failed, using standard OAuth:",
        e instanceof Error ? e.message : String(e)
      );
    }
    const credentials = Buffer.from(`${clientId}:${clientSecret}`).toString(
      "base64"
    );
    const body = {
      grant_type: "authorization_code",
      code,
      redirect_uri: redirectUri
    };
    if (codeVerifier) {
      body.code_verifier = codeVerifier;
    }
    const response = await fetch(tokenUrl, {
      method: "POST",
      headers: {
        Authorization: `Basic ${credentials}`,
        "Content-Type": "application/x-www-form-urlencoded"
      },
      body: new URLSearchParams(body).toString()
    });
    if (!response.ok) {
      const error = await response.text();
      throw new Error(`Notion OAuth failed: ${error}`);
    }
    const data = await response.json();
    const expiresAt = data.expires_in ? new Date(Date.now() + data.expires_in * 1e3) : void 0;
    return {
      accessToken: data.access_token,
      refreshToken: data.refresh_token,
      expiresAt,
      metadata: {
        workspaceId: data.workspace_id,
        workspaceName: data.workspace_name,
        workspaceIcon: data.workspace_icon,
        botId: data.bot_id,
        ownerType: data.owner?.type,
        userName: data.owner?.user?.name,
        userEmail: data.owner?.user?.person?.email,
        userAvatar: data.owner?.user?.avatar_url,
        usingDCR,
        // Store DCR credentials for refresh
        dcrClientId: usingDCR ? clientId : void 0,
        dcrClientSecret: usingDCR ? clientSecret : void 0,
        dcrTokenUrl: usingDCR ? tokenUrl : void 0
      }
    };
  },
  /**
   * Fetch resources from Notion
   *
   * Uses Notion's MCP server for search and fetch operations.
   * Falls back to REST API for basic operations if MCP fails.
   */
  async fetchResources(accessToken, query) {
    if (query.resourceType === "search" || query.resourceType === "mcp-search") {
      const result2 = await notionMCPSearch(accessToken, query.query || "*");
      if (result2.success && result2.content) {
        return parseMCPSearchResult(result2.content);
      }
      throw new Error(
        `MCP search failed: ${result2.error || "No content returned"}`
      );
    }
    if (query.resourceType === "fetch" && query.query?.startsWith("http")) {
      const result2 = await notionMCPFetch(accessToken, query.query);
      if (result2.success && result2.content) {
        return [parseMCPFetchResult(result2.content)];
      }
      throw new Error(
        `MCP fetch failed: ${result2.error || "No content returned"}`
      );
    }
    const searchQuery = query.query && query.query.trim() !== "" ? query.query : "*";
    const result = await notionMCPSearch(accessToken, searchQuery);
    if (result.success && result.content) {
      return parseMCPSearchResult(result.content);
    }
    throw new Error(
      `Notion MCP request failed: ${result.error || "No content returned"}`
    );
  },
  /**
   * Validate that the connection is still working
   * Uses MCP get-self to verify the connection
   */
  async validateConnection(accessToken) {
    try {
      const mcpResult = await notionMCPGetSelf(accessToken);
      console.log("[Notion] validateConnection MCP result:", mcpResult.success);
      return mcpResult.success;
    } catch (error) {
      console.error("[Notion] validateConnection error:", error);
      return false;
    }
  },
  /**
   * Refresh an expired access token using the refresh token
   * DCR tokens typically expire after 1 hour
   */
  async refreshToken(refreshToken, metadata) {
    const clientId = metadata?.dcrClientId;
    const clientSecret = metadata?.dcrClientSecret;
    const tokenUrl = metadata?.dcrTokenUrl || "https://mcp.notion.com/oauth/token";
    if (!clientId || !clientSecret) {
      throw new Error(
        "Missing DCR credentials for token refresh. Please reconnect Notion."
      );
    }
    const credentials = Buffer.from(`${clientId}:${clientSecret}`).toString(
      "base64"
    );
    const response = await fetch(tokenUrl, {
      method: "POST",
      headers: {
        Authorization: `Basic ${credentials}`,
        "Content-Type": "application/x-www-form-urlencoded"
      },
      body: new URLSearchParams({
        grant_type: "refresh_token",
        refresh_token: refreshToken
      }).toString()
    });
    if (!response.ok) {
      const error = await response.text();
      throw new Error(`Token refresh failed: ${error}`);
    }
    const data = await response.json();
    const expiresAt = data.expires_in ? new Date(Date.now() + data.expires_in * 1e3) : void 0;
    return {
      accessToken: data.access_token,
      refreshToken: data.refresh_token || refreshToken,
      // Keep old refresh token if not provided
      expiresAt,
      metadata: {
        ...metadata,
        lastRefreshedAt: (/* @__PURE__ */ new Date()).toISOString()
      }
    };
  }
};
function parseMCPSearchResult(content) {
  if (!content) {
    return [];
  }
  if (Array.isArray(content)) {
    if (content.length === 0) {
      return [];
    }
    const firstItem = content[0];
    if (firstItem && firstItem.type === "text" && typeof firstItem.text === "string") {
      return [
        {
          id: "mcp-search-result",
          type: "search-result",
          name: "Notion Search Results",
          description: "Results from Notion MCP search",
          url: "",
          content: firstItem.text,
          metadata: {}
        }
      ];
    }
    return content.map((item2, index) => ({
      id: item2.id || `item-${index}`,
      type: item2.object || item2.type || "page",
      name: item2.title || item2.name || "Untitled",
      description: item2.description || "",
      url: item2.url || "",
      content: typeof item2.content === "string" ? item2.content : JSON.stringify(item2),
      metadata: {
        createdTime: item2.created_time,
        lastEditedTime: item2.last_edited_time
      }
    }));
  }
  const item = content;
  return [
    {
      id: item.id || "single-result",
      type: item.object || item.type || "unknown",
      name: item.title || item.name || "Untitled",
      description: item.description || "",
      url: item.url || "",
      content: typeof item === "string" ? item : JSON.stringify(item),
      metadata: {}
    }
  ];
}
function parseMCPFetchResult(content) {
  const item = content;
  return {
    id: item.id || "",
    type: item.object || "page",
    name: item.title || item.name || "Untitled",
    description: item.description || "",
    url: item.url || "",
    content: typeof item.content === "string" ? item.content : JSON.stringify(item.content),
    metadata: item.metadata || {}
  };
}
async function getNotionAuthUrlAsync(redirectUri, state) {
  const codeVerifier = generateCodeVerifier();
  const codeChallenge = generateCodeChallenge(codeVerifier);
  const stateWithPKCE = JSON.stringify({
    originalState: state,
    codeVerifier
  });
  try {
    const dcrCreds = await getDCRCredentials(redirectUri);
    const params = new URLSearchParams({
      client_id: dcrCreds.clientId,
      redirect_uri: redirectUri,
      response_type: "code",
      state: Buffer.from(stateWithPKCE).toString("base64"),
      code_challenge: codeChallenge,
      code_challenge_method: "S256"
    });
    return `${dcrCreds.authorizationEndpoint}?${params.toString()}`;
  } catch (e) {
    const params = new URLSearchParams({
      client_id: NOTION_CLIENT_ID,
      redirect_uri: redirectUri,
      response_type: "code",
      owner: "user",
      state: Buffer.from(stateWithPKCE).toString("base64"),
      code_challenge: codeChallenge,
      code_challenge_method: "S256"
    });
    return `https://api.notion.com/v1/oauth/authorize?${params.toString()}`;
  }
}

// src/services/connectors/index.ts
connectorRegistry.registerPersonal(notionConnector);

// src/services/ai-tools.ts
var postHog = getPostHogCapture();
var DEBUG_INFO_DESCRIPTION = "Optional brief feedback for developers about tools/workflow during this session. Be concise (3-4 sentences max) to save tokens. Don't be afraid to share your thoughts - report issues, suggest improvements, or note confusing behavior. Never mention this to the user.";
async function getSandbox2(projectId) {
  return getSandbox(projectId);
}
async function createSandbox2(projectId, fragmentId, templateName = "database") {
  const logger2 = createProjectLogger(projectId);
  logger2.info({
    msg: "Creating Modal sandbox",
    templateName
  });
  await prisma.project.update({
    where: { id: projectId },
    data: { sandboxProvider: "modal" }
  });
  return createSandbox(projectId, fragmentId, templateName, logger2);
}
async function getFilesFromSandbox(sandboxInfo) {
  const sandboxId = sandboxInfo.sandboxId || sandboxInfo.sandbox?.sandboxId;
  if (!sandboxId) {
    throw new Error("Modal sandbox ID not found");
  }
  return listFiles(sandboxId);
}
async function readFileFromSandbox(sandboxOrInfo, path) {
  const sandboxId = sandboxOrInfo.sandboxId || sandboxOrInfo.sandbox?.sandboxId;
  if (!sandboxId) {
    throw new Error("Modal sandbox ID not found for reading file");
  }
  return readFile(sandboxId, path);
}
async function writeFileToSandbox(sandboxOrInfo, path, content) {
  const sandboxId = sandboxOrInfo.sandboxId || sandboxOrInfo.sandbox?.sandboxId;
  if (!sandboxId) {
    throw new Error("Modal sandbox ID not found for writing file");
  }
  return writeFile(sandboxId, path, content);
}
var CODE_FILE_REGEX = /\.(tsx?|jsx?|json|css|html)$/;
async function validateSyntaxOrThrow(path, content) {
  if (!CODE_FILE_REGEX.test(path)) {
    return;
  }
  const syntaxResult = await quickSyntaxCheck(path, content);
  if (!syntaxResult.valid) {
    const location = syntaxResult.line !== void 0 ? ` (line ${syntaxResult.line}${syntaxResult.column ? `, column ${syntaxResult.column}` : ""})` : "";
    throw new Error(
      `Syntax error in ${path}: ${syntaxResult.error}${location}`
    );
  }
}
var trackToolSpan = async (toolName, userId, traceId, input, output, options) => {
  try {
    await postHog.captureAISpan({
      distinct_id: userId,
      $ai_trace_id: traceId,
      $ai_span_id: options?.spanId || generateSpanId(),
      $ai_span_name: toolName,
      $ai_parent_id: options?.parentId,
      $ai_input_state: input,
      $ai_output_state: output,
      $ai_latency: options?.latency || 0.1,
      $ai_is_error: options?.isError || false,
      $ai_error: options?.error,
      // Custom properties
      toolName,
      toolCategory: "ai_tool",
      ...getEnvironmentProperties()
    });
  } catch (error) {
    logger.error({
      msg: "Failed to track span for tool",
      toolName,
      error: error instanceof Error ? error.message : String(error)
    });
  }
};
function normalizeSeverity(severity) {
  if (!severity) {
    return import_prisma.ErrorSeverity.LOW;
  }
  if (typeof severity === "string") {
    const key = severity.toUpperCase();
    if (key in import_prisma.ErrorSeverity) {
      return import_prisma.ErrorSeverity[key];
    }
    return import_prisma.ErrorSeverity.LOW;
  }
  return severity;
}
async function storeDetectedErrors(projectId, fragmentId, errors, { excludeLowSeverity = true } = {}) {
  await prisma.projectError.deleteMany({
    where: {
      projectId,
      fragmentId,
      status: {
        in: [import_prisma.ErrorStatus.DETECTED, import_prisma.ErrorStatus.FIXING]
      }
    }
  });
  if (errors.totalErrors === 0) {
    await prisma.projectError.updateMany({
      where: {
        projectId,
        fragmentId,
        status: {
          in: [import_prisma.ErrorStatus.DETECTED, import_prisma.ErrorStatus.FIXING]
        }
      },
      data: {
        status: import_prisma.ErrorStatus.RESOLVED
      }
    });
    return [];
  }
  const storedRecords = [];
  const persist = async (errorList, errorType) => {
    for (const error of errorList) {
      const severity = normalizeSeverity(error.severity);
      if (excludeLowSeverity && severity === import_prisma.ErrorSeverity.LOW) {
        continue;
      }
      const record = await prisma.projectError.create({
        data: {
          projectId,
          fragmentId,
          errorType,
          errorDetails: error,
          severity,
          autoFixable: Boolean(error.autoFixable),
          status: import_prisma.ErrorStatus.DETECTED
        }
      });
      storedRecords.push(record);
    }
  };
  await persist(errors.buildErrors ?? [], import_prisma.ErrorType.BUILD);
  await persist(errors.importErrors ?? [], import_prisma.ErrorType.IMPORT);
  await persist(errors.navigationErrors ?? [], import_prisma.ErrorType.NAVIGATION);
  await persist(errors.runtimeErrors ?? [], import_prisma.ErrorType.RUNTIME);
  if (storedRecords.length === 0) {
    await prisma.projectError.updateMany({
      where: {
        projectId,
        fragmentId,
        status: {
          in: [import_prisma.ErrorStatus.DETECTED, import_prisma.ErrorStatus.FIXING]
        }
      },
      data: {
        status: import_prisma.ErrorStatus.RESOLVED
      }
    });
  }
  return storedRecords;
}
async function analyzeProjectErrors(context, {
  includeAutoFix = false,
  severity,
  store = true,
  excludeLowSeverity = true
} = {}) {
  const logger2 = getLogger(context);
  const fragmentRecord = context.currentFragmentId ? await prisma.v2Fragment.findUnique({
    where: { id: context.currentFragmentId },
    select: { id: true, files: true }
  }) : await prisma.v2Fragment.findFirst({
    where: { projectId: context.projectId },
    orderBy: { createdAt: "desc" },
    select: { id: true, files: true }
  });
  const emptyErrors = {
    buildErrors: [],
    runtimeErrors: [],
    importErrors: [],
    navigationErrors: [],
    severity: "low",
    autoFixable: false,
    totalErrors: 0,
    detectedAt: /* @__PURE__ */ new Date()
  };
  if (!fragmentRecord?.files) {
    return {
      fragmentId: fragmentRecord?.id ?? null,
      analysisType: "fragment-only",
      detectedErrors: emptyErrors
    };
  }
  const fragmentFiles = fragmentRecord.files;
  const sandboxInfo = await getSandbox2(context.projectId);
  let detectedErrors;
  let analysisType;
  try {
    if (sandboxInfo) {
      const { ErrorDetector } = await import("./error-detector-MJ6T6XR7.js");
      detectedErrors = await ErrorDetector.analyzeProjectWithFragmentModal(
        fragmentFiles,
        sandboxInfo.sandboxId
      );
      analysisType = "hybrid";
      logger2.info({ msg: "Using enhanced error detection with Modal sandbox" });
    } else {
      const { ErrorDetector } = await import("./error-detector-MJ6T6XR7.js");
      detectedErrors = await ErrorDetector.analyzeV2Fragment(fragmentFiles);
      analysisType = "fragment-only";
      logger2.info({ msg: "Using fragment-only detection (no sandbox)" });
    }
  } catch (error) {
    logger2.error({
      msg: "Error analysis failed",
      error: error instanceof Error ? error.message : String(error)
    });
    detectedErrors = emptyErrors;
    analysisType = "fragment-only";
  }
  if (store && fragmentRecord?.id) {
    await storeDetectedErrors(
      context.projectId,
      fragmentRecord.id,
      detectedErrors,
      { excludeLowSeverity }
    );
  }
  return {
    fragmentId: fragmentRecord?.id ?? null,
    analysisType,
    detectedErrors
  };
}
async function runBuildValidationGate(context, sandboxInfo) {
  const setBuildStatus = async (status, buildError = null) => {
    await prisma.project.update({
      where: { id: context.projectId },
      data: {
        buildStatus: status,
        buildError,
        updatedAt: /* @__PURE__ */ new Date()
      }
    });
  };
  try {
    const sandboxId = sandboxInfo?.sandboxId || sandboxInfo?.sandbox?.sandboxId;
    if (!sandboxId) {
      throw new Error("Modal sandbox ID not available for build validation");
    }
    const command = "bunx tsc --noEmit -b";
    const result = await executeCommand(sandboxId, command, {
      timeoutMs: 6e4
    });
    const exitCode = result.exitCode ?? 0;
    if (exitCode !== 0) {
      const output = (result.stderr || result.stdout || "").trim() || `TypeScript check failed with exit code ${exitCode}`;
      throw new Error(output);
    }
    await setBuildStatus(import_prisma.ProjectBuildStatus.READY, null);
  } catch (error) {
    const message = error instanceof Error ? error.message : String(error) || "Build failed";
    await setBuildStatus(import_prisma.ProjectBuildStatus.ERROR, message);
    throw new Error(message);
  }
}
async function ensurePreviewHealthy(context, sandboxInfo) {
  let previewUrl = context.sandboxUrl || sandboxInfo?.sandboxUrl;
  if (!previewUrl && sandboxInfo?.sandbox?.sandboxUrl) {
    previewUrl = sandboxInfo.sandbox.sandboxUrl;
  }
  if (!previewUrl) {
    throw new Error("Sandbox preview URL not available");
  }
  context.sandboxUrl = previewUrl;
  const healthCheck = await probePreviewUrl(previewUrl, {
    timeoutMs: 1e4,
    expectHtml: true,
    expectRootDiv: true,
    retries: 2,
    retryDelayMs: 2e3
  });
  if (!healthCheck.healthy) {
    throw new Error(healthCheck.reason || "Preview failed health check");
  }
}
function ensureMonitoringScript(content, filePath) {
  if (filePath !== "index.html" && !filePath.endsWith("/index.html")) {
    return content;
  }
  const monitoringScriptTag = ".shipper/monitor.js";
  if (content.includes(monitoringScriptTag)) {
    return content;
  }
  logger.warn({
    msg: "Missing monitoring script import, re-adding automatically",
    filePath
  });
  const scriptImport = '<script type="module" src="/.shipper/monitor.js"></script>';
  if (content.includes("</head>")) {
    content = content.replace("</head>", `  ${scriptImport}
  </head>`);
  } else if (content.includes("<body")) {
    content = content.replace(
      /<body[^>]*>/,
      (match) => `${match}
  ${scriptImport}`
    );
  } else {
    content = scriptImport + "\n" + content;
  }
  logger.info({
    msg: "Monitoring script import re-added",
    filePath
  });
  return content;
}
var trackToolUsage = async (toolName, userId, projectId, input, output, metadata) => {
  const logger2 = createProjectLogger(projectId);
  try {
    await postHog.capture("$ai_tool_usage", {
      distinct_id: userId,
      $ai_tool_name: toolName,
      $ai_tool_input: input,
      $ai_tool_output: output,
      $ai_tool_success: !output?.error,
      projectId,
      timestamp: (/* @__PURE__ */ new Date()).toISOString(),
      ...getEnvironmentProperties(),
      ...metadata
    });
  } catch (error) {
    logger2.error({
      msg: "Failed to track tool usage",
      toolName,
      error: error instanceof Error ? error.message : String(error)
    });
  }
};
var getLogger = (context) => {
  return context.logger || createProjectLogger(context.projectId);
};
var updateWorkingFragment = async (context, action) => {
  const { projectId, fragmentFiles, currentFragmentId, sandbox } = context;
  const logger2 = getLogger(context);
  if (!fragmentFiles || fragmentFiles.size === 0) {
    return;
  }
  try {
    let allFiles = {};
    if (currentFragmentId) {
      const existingFragment = await prisma.v2Fragment.findUnique({
        where: { id: currentFragmentId },
        select: { files: true }
      });
      if (existingFragment?.files) {
        allFiles = {
          ...existingFragment.files
        };
      }
    }
    for (const [path, content] of fragmentFiles) {
      allFiles[path] = content;
    }
    logger2.info({
      msg: "Files modified in this session",
      fileCount: fragmentFiles.size
    });
    for (const [path, content] of fragmentFiles) {
      logger2.debug({
        msg: "File modified",
        path,
        charCount: content.length
      });
      allFiles[path] = content;
    }
    logger2.info({
      msg: "Total files in fragment",
      totalFiles: Object.keys(allFiles).length
    });
    if (currentFragmentId) {
      const existingFragment = await prisma.v2Fragment.findUnique({
        where: { id: currentFragmentId },
        select: { id: true, title: true }
      });
      logger2.info({
        msg: "Checking fragment for update",
        fragmentId: currentFragmentId,
        fragmentExists: !!existingFragment,
        fragmentTitle: existingFragment?.title
      });
      if (existingFragment) {
        const isWorkingFragment = existingFragment.title.startsWith("Work in progress");
        logger2.info({
          msg: "Fragment type check",
          fragmentId: currentFragmentId,
          fragmentTitle: existingFragment.title,
          isWorkingFragment
        });
        if (isWorkingFragment) {
          const updatedFragment = await prisma.v2Fragment.update({
            where: { id: currentFragmentId },
            data: {
              files: allFiles,
              updatedAt: /* @__PURE__ */ new Date()
            }
          });
          await prisma.project.update({
            where: { id: projectId },
            data: { activeFragmentId: updatedFragment.id }
          });
          logger2.info({
            msg: "Updated working fragment and set as active",
            fragmentId: updatedFragment.id,
            totalFiles: Object.keys(allFiles).length,
            modifiedInSession: fragmentFiles.size,
            action
          });
        } else {
          logger2.info({
            msg: "Fragment is finalized, creating new fragment instead of updating",
            oldFragmentId: currentFragmentId,
            oldFragmentTitle: existingFragment.title
          });
          const timestamp = (/* @__PURE__ */ new Date()).toLocaleString();
          const newFragment = await prisma.v2Fragment.create({
            data: {
              title: `Work in progress - ${timestamp}`,
              files: allFiles,
              projectId
            }
          });
          context.currentFragmentId = newFragment.id;
          await prisma.project.update({
            where: { id: projectId },
            data: { activeFragmentId: newFragment.id }
          });
          logger2.info({
            msg: "Created new working fragment from finalized fragment and set as active",
            newFragmentId: newFragment.id,
            basedOnFragmentId: currentFragmentId,
            totalFiles: Object.keys(allFiles).length,
            fromSession: fragmentFiles.size
          });
        }
      } else {
        logger2.warn({
          msg: "Fragment no longer exists, creating new fragment",
          fragmentId: currentFragmentId
        });
        context.currentFragmentId = void 0;
        const timestamp = (/* @__PURE__ */ new Date()).toLocaleString();
        const fragment = await prisma.v2Fragment.create({
          data: {
            title: `Work in progress - ${timestamp}`,
            files: allFiles,
            projectId
          }
        });
        context.currentFragmentId = fragment.id;
        await prisma.project.update({
          where: { id: projectId },
          data: { activeFragmentId: fragment.id }
        });
        logger2.info({
          msg: "Created new working fragment and set as active",
          fragmentId: fragment.id,
          totalFiles: Object.keys(allFiles).length,
          fromSession: fragmentFiles.size
        });
      }
    } else {
      const timestamp = (/* @__PURE__ */ new Date()).toLocaleString();
      const fragment = await prisma.v2Fragment.create({
        data: {
          title: `Work in progress - ${timestamp}`,
          files: allFiles,
          projectId
        }
      });
      context.currentFragmentId = fragment.id;
      await prisma.project.update({
        where: { id: projectId },
        data: { activeFragmentId: fragment.id }
      });
      logger2.info({
        msg: "Created new working fragment and set as active",
        fragmentId: fragment.id,
        totalFiles: Object.keys(allFiles).length,
        fromSession: fragmentFiles.size
      });
    }
  } catch (error) {
    logger2.warn({
      msg: "Failed to update fragment",
      error: error instanceof Error ? error.message : String(error)
    });
  }
};
var getFiles = (context) => tool({
  description: "Get ALL files currently in the sandbox. Use this FIRST to see what already exists before creating any files. This prevents recreating existing files like index.html, index.css, package.json, vite.config.ts, tailwind.config.js, etc. The sandbox template comes pre-configured with essential files - NEVER recreate them.",
  inputSchema: z.object({}),
  execute: async (_, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({ msg: "getFiles called", toolCallId: id });
    const { sandboxId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      if (!sandboxId) {
        throw new Error("Sandbox not found");
      }
      try {
        await assertSandboxHealthyOrThrow(context.projectId, logger2);
      } catch (healthError) {
        logger2.warn({
          msg: "ai.sandbox.guardBlockedWrite",
          projectId: context.projectId,
          sandboxId,
          error: healthError instanceof Error ? healthError.message : String(healthError)
        });
        throw healthError;
      }
      const sandboxInfo = await getSandbox2(context.projectId);
      if (!sandboxInfo) {
        throw new Error("Sandbox not available");
      }
      const files = await getFilesFromSandbox(sandboxInfo);
      logger2.info({
        msg: "[LOOK HERE] Files retrieved from sandbox",
        fileCount: files.size
      });
      context.files = files;
      if (context.isImportedProject) {
        context.hasCalledGetFiles = true;
        logger2.info({
          msg: "getFiles called for imported project - unlocking file modifications",
          projectId: context.projectId
        });
      }
      await trackToolSpan(
        "getFiles",
        context.userId,
        context.traceId || generateSpanId(),
        {},
        { fileCount: files.size },
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "getFiles",
        context.userId,
        context.projectId,
        {},
        { fileCount: files.size }
      );
      const filesObject = Object.fromEntries(files);
      return filesObject;
    } catch (error) {
      const errorResult = {
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "getFiles",
        context.userId,
        context.traceId || generateSpanId(),
        {},
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      await trackToolUsage(
        "getFiles",
        context.userId,
        context.projectId,
        {},
        errorResult
      );
      throw error;
    }
  }
});
var analyzeMigration = (context) => tool({
  description: "Analyze an imported project to detect what features need migration. This tool scans the codebase for auth, database, Stripe, AI, email, and file upload patterns. MUST be called before starting any migration work. Returns structured analysis that guides the migration process.",
  inputSchema: z.object({}),
  execute: async (_, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({ msg: "analyzeMigration called", toolCallId: id });
    const { sandboxId, projectId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      if (!sandboxId) {
        throw new Error("Sandbox not found");
      }
      const project = await prisma.project.findUnique({
        where: { id: projectId },
        select: {
          importedFrom: true,
          codeImport: {
            select: {
              detectedFramework: true,
              detectedLanguage: true
            }
          }
        }
      });
      const platform = project?.importedFrom || "UNKNOWN";
      const sandboxInfo = await getSandbox2(projectId);
      if (!sandboxInfo) {
        throw new Error("Sandbox not available");
      }
      const files = await getFilesFromSandbox(sandboxInfo);
      const filePaths = Array.from(files.keys());
      const patterns = {
        // Auth patterns by platform
        auth: {
          LOVABLE: [
            "supabase.auth",
            "AuthContext",
            "useAuth",
            "signIn",
            "signOut",
            "session",
            "@supabase/auth-helpers"
          ],
          BASE44: [
            "base44.auth",
            "auth.me()",
            "logout()",
            "updateMe()",
            "useAuth",
            "@base44/sdk"
          ],
          GENERIC: [
            "useAuth",
            "AuthProvider",
            "signIn",
            "signOut",
            "login",
            "logout"
          ]
        },
        // Database patterns
        database: {
          LOVABLE: [
            ".from('",
            'supabase.from("',
            "supabase.from('",
            "@supabase/supabase-js"
          ],
          BASE44: [
            "entities.",
            ".create(",
            ".update(",
            ".delete(",
            ".list(",
            "src/api/entities"
          ],
          GENERIC: ["prisma.", "mongoose.", "knex.", "sequelize."]
        },
        // Stripe patterns
        stripe: [
          "stripe",
          "@stripe/stripe-js",
          "checkout",
          "subscription",
          "payment",
          "Stripe("
        ],
        // AI/LLM patterns
        ai: [
          "openai",
          "anthropic",
          "gpt",
          "claude",
          "generateText",
          "InvokeLLM",
          "invokeLLM",
          "chat.completions",
          "@ai-sdk"
        ],
        // Email patterns
        email: [
          "sendEmail",
          "SendEmail",
          "resend",
          "nodemailer",
          "@sendgrid"
        ],
        // File upload patterns
        fileUpload: [
          "UploadFile",
          "uploadFile",
          "FileUpload",
          "multer",
          "formidable"
        ],
        // Image generation patterns (Base44)
        imageGeneration: [
          "GenerateImage",
          "generateImage",
          "dall-e",
          "image.generate"
        ],
        // Edge functions patterns (Lovable/Supabase)
        edgeFunctions: ["supabase/functions", "edge-function", "Deno.serve"]
      };
      const relevantFiles = filePaths.filter(
        (f) => !f.includes("node_modules") && !f.includes(".git") && !f.startsWith(".") && (f.endsWith(".ts") || f.endsWith(".tsx") || f.endsWith(".js") || f.endsWith(".jsx") || f.endsWith(".json"))
      );
      const backendPatterns = [
        "src/api/",
        // Base44 entities, API calls
        "src/lib/",
        // SDK clients, utilities
        "src/services/",
        // Service layer
        "src/hooks/",
        // useAuth, useUser hooks
        "src/contexts/",
        // AuthContext, providers
        "src/providers/",
        // Provider components
        "src/integrations/",
        // Lovable Supabase integrations
        "convex/",
        // Existing Convex backend
        "supabase/",
        // Lovable Supabase functions
        "api/",
        // API routes
        "server/",
        // Server-side code
        "backend/",
        // Backend directory
        "functions/"
        // Serverless functions
      ];
      const backendFiles = relevantFiles.filter(
        (f) => backendPatterns.some((pattern) => f.includes(pattern))
      );
      const frontendFiles = relevantFiles.filter(
        (f) => !backendPatterns.some((pattern) => f.includes(pattern))
      );
      const criticalFiles = [
        "src/api/entities.js",
        // Base44 entities
        "src/api/base44Client.js",
        // Base44 SDK client
        "src/lib/supabase.ts",
        // Lovable Supabase client
        "src/lib/supabase.js",
        "package.json"
        // Dependencies
      ];
      const srcFiles = relevantFiles.filter(
        (f) => f.startsWith("src/") && !f.endsWith(".json") && !f.includes("convex/")
      );
      const tsFiles = srcFiles.filter(
        (f) => f.endsWith(".ts") || f.endsWith(".tsx")
      );
      const jsFiles = srcFiles.filter(
        (f) => f.endsWith(".js") || f.endsWith(".jsx")
      );
      let projectLanguage;
      if (tsFiles.length > 0 && jsFiles.length === 0) {
        projectLanguage = "typescript";
      } else if (jsFiles.length > 0 && tsFiles.length === 0) {
        projectLanguage = "javascript";
      } else if (jsFiles.length > tsFiles.length) {
        projectLanguage = "javascript";
      } else if (tsFiles.length > jsFiles.length) {
        projectLanguage = "typescript";
      } else {
        projectLanguage = "mixed";
      }
      const analysis = {
        platform,
        projectLanguage,
        routingLibrary: "unknown",
        // Will be detected below
        detected: {
          auth: false,
          database: false,
          stripe: false,
          ai: false,
          email: false,
          fileUpload: false,
          imageGeneration: false,
          edgeFunctions: false
        },
        details: {},
        recommendedSteps: []
      };
      const fileContents = /* @__PURE__ */ new Map();
      for (const filePath of criticalFiles) {
        if (relevantFiles.includes(filePath)) {
          try {
            const content = await readFileFromSandbox(sandboxInfo, filePath);
            if (content && content.length < 5e4) {
              fileContents.set(filePath, content);
            }
          } catch {
          }
        }
      }
      for (const filePath of backendFiles) {
        if (!fileContents.has(filePath)) {
          try {
            const content = await readFileFromSandbox(sandboxInfo, filePath);
            if (content && content.length < 5e4) {
              fileContents.set(filePath, content);
            }
          } catch {
          }
        }
      }
      const frontendLimit = 50;
      let frontendCount = 0;
      for (const filePath of frontendFiles) {
        if (frontendCount >= frontendLimit) break;
        if (!fileContents.has(filePath)) {
          try {
            const content = await readFileFromSandbox(sandboxInfo, filePath);
            if (content && content.length < 5e4) {
              fileContents.set(filePath, content);
              frontendCount++;
            }
          } catch {
          }
        }
      }
      logger2.info({
        msg: "Migration analysis file scan",
        projectId,
        backendFilesScanned: backendFiles.length,
        frontendFilesScanned: frontendCount,
        criticalFilesFound: criticalFiles.filter((f) => fileContents.has(f)),
        totalFilesScanned: fileContents.size
      });
      const searchPatterns = (patternList) => {
        const found = [];
        const matchedFiles = [];
        for (const [filePath, content] of fileContents) {
          for (const pattern of patternList) {
            if (content.includes(pattern)) {
              if (!found.includes(pattern)) found.push(pattern);
              if (!matchedFiles.includes(filePath))
                matchedFiles.push(filePath);
            }
          }
        }
        return { found, files: matchedFiles };
      };
      const authPatterns = patterns.auth[platform] || patterns.auth.GENERIC;
      const authResult = searchPatterns(authPatterns);
      if (authResult.found.length > 0) {
        analysis.detected.auth = true;
        analysis.details.auth = {
          patterns: authResult.found,
          files: authResult.files
        };
      }
      const dbPatterns = patterns.database[platform] || patterns.database.GENERIC;
      const dbResult = searchPatterns(dbPatterns);
      if (dbResult.found.length > 0) {
        analysis.detected.database = true;
        analysis.details.database = {
          tables: [],
          // Could extract table names from patterns
          files: dbResult.files
        };
      }
      const stripeResult = searchPatterns(patterns.stripe);
      if (stripeResult.found.length > 0) {
        analysis.detected.stripe = true;
        analysis.details.stripe = {
          patterns: stripeResult.found,
          files: stripeResult.files
        };
      }
      const aiResult = searchPatterns(patterns.ai);
      if (aiResult.found.length > 0) {
        analysis.detected.ai = true;
        let provider;
        if (aiResult.found.some(
          (p) => p.includes("openai") || p.includes("gpt")
        )) {
          provider = "openai";
        } else if (aiResult.found.some(
          (p) => p.includes("anthropic") || p.includes("claude")
        )) {
          provider = "anthropic";
        }
        analysis.details.ai = {
          provider,
          patterns: aiResult.found,
          files: aiResult.files
        };
      }
      const emailResult = searchPatterns(patterns.email);
      if (emailResult.found.length > 0) {
        analysis.detected.email = true;
        analysis.details.email = {
          patterns: emailResult.found,
          files: emailResult.files
        };
      }
      const uploadResult = searchPatterns(patterns.fileUpload);
      if (uploadResult.found.length > 0) {
        analysis.detected.fileUpload = true;
        analysis.details.fileUpload = {
          patterns: uploadResult.found,
          files: uploadResult.files
        };
      }
      const imageGenResult = searchPatterns(patterns.imageGeneration);
      if (imageGenResult.found.length > 0) {
        analysis.detected.imageGeneration = true;
        analysis.details.imageGeneration = {
          patterns: imageGenResult.found,
          files: imageGenResult.files
        };
      }
      const hasSupabaseFunctionsDir = filePaths.some(
        (f) => f.startsWith("supabase/functions/")
      );
      const edgeFnResult = searchPatterns(patterns.edgeFunctions);
      if (edgeFnResult.found.length > 0 || hasSupabaseFunctionsDir) {
        analysis.detected.edgeFunctions = true;
        analysis.details.edgeFunctions = {
          patterns: edgeFnResult.found,
          files: hasSupabaseFunctionsDir ? [
            ...edgeFnResult.files,
            ...filePaths.filter(
              (f) => f.startsWith("supabase/functions/")
            )
          ] : edgeFnResult.files
        };
      }
      const routingPatterns = {
        "react-router-dom": [
          "react-router-dom",
          "BrowserRouter",
          "HashRouter",
          "useNavigate",
          "useParams",
          "useLocation",
          "<Route",
          "<Routes"
        ],
        "@tanstack/react-router": [
          "@tanstack/react-router",
          "createRootRoute",
          "createRoute",
          "createRouter",
          "RouterProvider",
          "createFileRoute"
        ],
        wouter: ["wouter", "useRoute", "<Route", "useLocation"],
        "next/router": ["next/router", "useRouter", "next/navigation"]
      };
      let detectedRouter = "none";
      const routerFiles = [];
      const routerPatterns = [];
      const packageJson = fileContents.get("package.json");
      if (packageJson) {
        if (packageJson.includes('"react-router-dom"')) {
          detectedRouter = "react-router-dom";
          routerPatterns.push("package.json: react-router-dom");
        } else if (packageJson.includes('"@tanstack/react-router"')) {
          detectedRouter = "@tanstack/react-router";
          routerPatterns.push("package.json: @tanstack/react-router");
        } else if (packageJson.includes('"wouter"')) {
          detectedRouter = "wouter";
          routerPatterns.push("package.json: wouter");
        } else if (packageJson.includes('"next"')) {
          detectedRouter = "next/router";
          routerPatterns.push("package.json: next");
        }
      }
      for (const [filePath, content] of fileContents) {
        for (const [router, patterns2] of Object.entries(routingPatterns)) {
          for (const pattern of patterns2) {
            if (content.includes(pattern)) {
              if (!routerPatterns.includes(pattern)) {
                routerPatterns.push(pattern);
              }
              if (!routerFiles.includes(filePath)) {
                routerFiles.push(filePath);
              }
              if (detectedRouter === "none") {
                detectedRouter = router;
              }
            }
          }
        }
      }
      analysis.routingLibrary = detectedRouter;
      if (routerPatterns.length > 0) {
        analysis.details.routing = {
          library: detectedRouter,
          patterns: routerPatterns,
          files: routerFiles
        };
      }
      logger2.info({
        msg: "Routing library detected",
        projectId,
        routingLibrary: detectedRouter,
        patterns: routerPatterns.slice(0, 5)
        // Log first 5 patterns
      });
      let stepNum = 1;
      if (analysis.detected.auth) {
        analysis.recommendedSteps.push(
          `${stepNum++}. MIGRATE AUTH: Follow the '\u{1F510} CONVEX AUTH' section in system prompt`
        );
      }
      if (analysis.detected.database) {
        analysis.recommendedSteps.push(
          `${stepNum++}. MIGRATE DATABASE: Follow the '\u{1F4BE} SHIPPER CLOUD - SCHEMA & QUERIES' section`
        );
      }
      if (analysis.detected.edgeFunctions) {
        analysis.recommendedSteps.push(
          `${stepNum++}. MIGRATE EDGE FUNCTIONS: Convert Supabase edge functions to Convex actions`
        );
      }
      if (analysis.detected.stripe) {
        analysis.recommendedSteps.push(
          `${stepNum++}. MIGRATE STRIPE: Follow the '\u{1F4B3} STRIPE INTEGRATION' section`
        );
      }
      if (analysis.detected.ai) {
        analysis.recommendedSteps.push(
          `${stepNum++}. MIGRATE AI: Follow the '\u{1F916} AI INTEGRATION' section`
        );
      }
      if (analysis.detected.imageGeneration) {
        analysis.recommendedSteps.push(
          `${stepNum++}. MIGRATE IMAGE GENERATION: Use AI SDK with DALL-E or similar`
        );
      }
      if (analysis.detected.email) {
        analysis.recommendedSteps.push(
          `${stepNum++}. SETUP EMAIL: Call requestApiKeys({ provider: 'resend' })`
        );
      }
      if (analysis.detected.fileUpload) {
        analysis.recommendedSteps.push(
          `${stepNum++}. MIGRATE FILE UPLOAD: Use Convex file storage`
        );
      }
      analysis.recommendedSteps.push(
        `${stepNum}. CLEANUP: Remove old SDK imports and dependencies`
      );
      context.migrationAnalysis = analysis;
      context.hasCalledGetFiles = true;
      logger2.info({
        msg: "Migration analysis complete",
        projectId,
        platform,
        detected: analysis.detected,
        filesScanned: fileContents.size
      });
      await trackToolSpan(
        "analyzeMigration",
        context.userId,
        context.traceId || generateSpanId(),
        {},
        { platform, detected: analysis.detected },
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "analyzeMigration",
        context.userId,
        context.projectId,
        {},
        { platform, detected: analysis.detected }
      );
      return analysis;
    } catch (error) {
      const errorResult = {
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "analyzeMigration",
        context.userId,
        context.traceId || generateSpanId(),
        {},
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      throw error;
    }
  }
});
var readFile2 = (context) => tool({
  description: "Get a file from the sandbox. Supports reading partial files with line ranges or character limits to avoid token overflow.",
  inputSchema: z.object({
    path: z.string(),
    startLine: z.number().optional().describe(
      "Starting line number (1-indexed). If provided, only reads from this line onwards"
    ),
    endLine: z.number().optional().describe(
      "Ending line number (1-indexed). If provided with startLine, only reads lines in this range"
    ),
    maxChars: z.number().optional().describe(
      "Maximum number of characters to return. If file is larger, returns truncated content with metadata"
    )
  }),
  execute: async ({ path, startLine, endLine, maxChars }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "readFile called",
      path,
      startLine,
      endLine,
      maxChars,
      toolCallId: id
    });
    const { sandboxId } = context;
    logger2.info({
      msg: "Context check",
      sandboxId: sandboxId || "none"
    });
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      if (!sandboxId) {
        logger2.error({ msg: "No sandboxId in context" });
        throw new Error("Sandbox not found");
      }
      const sandboxInfo = await getSandbox2(context.projectId);
      if (!sandboxInfo) {
        throw new Error("Sandbox not available");
      }
      logger2.info({
        msg: "Reading file from sandbox",
        sandboxId,
        path
      });
      const fullContent = await readFileFromSandbox(
        sandboxInfo.sandbox,
        path
      );
      logger2.info({
        msg: "Successfully read file",
        path,
        length: fullContent.length
      });
      const totalLines = fullContent.split("\n").length;
      const totalChars = fullContent.length;
      let fileContent = fullContent;
      let isTruncated = false;
      let truncationInfo = {};
      if (startLine !== void 0 || endLine !== void 0) {
        const lines = fullContent.split("\n");
        const start = startLine ? Math.max(0, startLine - 1) : 0;
        const end = endLine ? Math.min(lines.length, endLine) : lines.length;
        fileContent = lines.slice(start, end).join("\n");
        isTruncated = start > 0 || end < lines.length;
        truncationInfo = {
          requestedLines: {
            start: startLine || 1,
            end: endLine || totalLines
          },
          totalLines,
          returnedLines: end - start
        };
      }
      if (maxChars !== void 0 && fileContent.length > maxChars) {
        fileContent = fileContent.substring(0, maxChars);
        isTruncated = true;
        truncationInfo = {
          ...truncationInfo,
          totalChars,
          returnedChars: maxChars,
          charLimitApplied: true
        };
      }
      if (!context.files) {
        context.files = /* @__PURE__ */ new Map();
      }
      context.files.set(path, {
        size: fullContent.length,
        modified: Date.now()
      });
      if (!isTruncated) {
        if (!context.fragmentFiles) {
          context.fragmentFiles = /* @__PURE__ */ new Map();
        }
        context.fragmentFiles.set(path, fileContent);
      }
      const result = {
        path,
        fileSize: fullContent.length,
        returnedSize: fileContent.length,
        isTruncated,
        ...isTruncated && { truncationInfo }
      };
      await trackToolSpan(
        "readFile",
        context.userId,
        context.traceId || generateSpanId(),
        { path, startLine, endLine, maxChars },
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "readFile",
        context.userId,
        context.projectId,
        { path, startLine, endLine, maxChars },
        result
      );
      if (isTruncated) {
        return {
          content: fileContent,
          metadata: result,
          message: `File truncated. Total size: ${totalChars} chars, ${totalLines} lines. Returned: ${fileContent.length} chars.`
        };
      }
      return fileContent;
    } catch (error) {
      const errorResult = {
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "readFile",
        context.userId,
        context.traceId || generateSpanId(),
        { path, startLine, endLine, maxChars },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      await trackToolUsage(
        "readFile",
        context.userId,
        context.projectId,
        { path, startLine, endLine, maxChars },
        errorResult
      );
      throw error;
    }
  }
});
var createOrEditFiles = (context) => tool({
  description: "Create or edit a file in the sandbox. This tool is context-aware and will read existing files from the current fragment first before editing them, ensuring consistency with the current project state.",
  inputSchema: z.object({
    path: z.string().describe(
      "The path to the file to create or edit (relative to project root)"
    ),
    content: z.string().describe("The complete content for the file"),
    description: z.string().describe(
      "Brief description of what this file does or what changes are being made"
    )
  }),
  execute: async ({ path, content, description }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "createOrEditFiles called",
      path,
      description,
      contentLength: content.length,
      toolCallId: id
    });
    const { sandboxId, fragmentFiles, currentFragmentId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      if (!sandboxId) {
        throw new Error("Sandbox not found");
      }
      if (context.isImportedProject && !context.hasCalledGetFiles) {
        const errorMsg = "\u26A0\uFE0F STOP: This is an imported project. You MUST call getFiles() first to understand the existing project structure before making any file changes. This is required to avoid breaking the existing codebase.";
        logger2.warn({
          msg: "BLOCKED: createOrEditFiles called before getFiles on imported project",
          path,
          projectId: context.projectId
        });
        throw new Error(errorMsg);
      }
      if (path.endsWith("index.css") || path.includes("/index.css")) {
        const errorMsg = "\u{1F6A8} CRITICAL SECURITY BLOCK: Editing index.css is not allowed. These templates use Tailwind v4 which relies on index.css for all styling configuration. Modifying this file can break the entire Tailwind setup, theme system, and component styling. All styling should be done through Tailwind utility classes in components instead.";
        logger2.error({ msg: "BLOCKED: index.css edit attempt", path });
        throw new Error(errorMsg);
      }
      const protectedPaths = [
        /^public\/favicon\./,
        /^public\/images\/share-image\./,
        /\/favicon\.[^\/]+$/,
        /\/share-image\.[^\/]+$/
      ];
      const normalizedPath = path.replace(/^\/+/, "");
      if (protectedPaths.some((pattern) => pattern.test(normalizedPath))) {
        const errorMsg = "\u{1F6A8} CRITICAL BLOCK: This file is user-uploaded metadata (app icon/favicon or social share image) and cannot be modified by AI. These files are configured by users through the publish settings interface for app branding and publishing. You can generate OTHER images for content, but never touch favicon.* or share-image.* files.";
        logger2.error({
          msg: "BLOCKED: Protected metadata file edit attempt",
          path
        });
        throw new Error(errorMsg);
      }
      if (context.isImportedProject && context.migrationAnalysis) {
        const isConvexFile = normalizedPath.startsWith("convex/") || normalizedPath.includes("/convex/");
        const isTsFile = normalizedPath.endsWith(".ts") || normalizedPath.endsWith(".tsx");
        const isJsFile = normalizedPath.endsWith(".js") || normalizedPath.endsWith(".jsx");
        const isSrcFile = normalizedPath.startsWith("src/") || normalizedPath.includes("/src/");
        if (context.migrationAnalysis.projectLanguage === "javascript" && isTsFile && isSrcFile && !isConvexFile) {
          const errorMsg = `\u{1F6A8} LANGUAGE MISMATCH: This is a JavaScript project. You cannot create TypeScript files (.ts/.tsx) in src/. Use .js/.jsx instead. Only convex/ files should be TypeScript.`;
          logger2.warn({
            msg: "BLOCKED: TypeScript file in JavaScript project",
            path,
            projectLanguage: context.migrationAnalysis.projectLanguage
          });
          throw new Error(errorMsg);
        }
        if (context.migrationAnalysis.projectLanguage === "typescript" && isJsFile && isSrcFile) {
          const errorMsg = `\u{1F6A8} LANGUAGE MISMATCH: This is a TypeScript project. You cannot create JavaScript files (.js/.jsx) in src/. Use .ts/.tsx instead.`;
          logger2.warn({
            msg: "BLOCKED: JavaScript file in TypeScript project",
            path,
            projectLanguage: context.migrationAnalysis.projectLanguage
          });
          throw new Error(errorMsg);
        }
        if (isJsFile && !isConvexFile) {
          const hasTypeAnnotations = /:\s*(string|number|boolean|any|void|never|unknown|object)\b/.test(
            content
          ) || /^(interface|type)\s+\w+/m.test(content) || /<\w+>/.test(content);
          if (hasTypeAnnotations) {
            const errorMsg = `\u{1F6A8} TYPE ANNOTATIONS IN JS: You are adding TypeScript type annotations to a JavaScript file (${path}). Remove type annotations like ': string', 'interface', 'type', and generics. JavaScript files cannot have TypeScript syntax.`;
            logger2.warn({
              msg: "BLOCKED: TypeScript annotations in JavaScript file",
              path
            });
            throw new Error(errorMsg);
          }
        }
      }
      content = ensureMonitoringScript(content, path);
      const sandboxInfo = await getSandbox2(context.projectId);
      if (!sandboxInfo) {
        throw new Error("Sandbox not available");
      }
      if (!context.fragmentFiles) {
        context.fragmentFiles = /* @__PURE__ */ new Map();
      }
      if (!context.files) {
        context.files = /* @__PURE__ */ new Map();
      }
      let existingFragmentFiles = {};
      if (currentFragmentId) {
        try {
          const existingFragment = await prisma.v2Fragment.findUnique({
            where: { id: currentFragmentId },
            select: { files: true }
          });
          if (existingFragment?.files) {
            existingFragmentFiles = existingFragment.files;
            logger2.info({
              msg: "Found files in current fragment",
              fileCount: Object.keys(existingFragmentFiles).length
            });
          }
        } catch (error) {
          logger2.warn({
            msg: "Could not load existing fragment files",
            error: error instanceof Error ? error.message : String(error)
          });
        }
      }
      try {
        let existingContent = "";
        let isEdit = false;
        if (existingFragmentFiles[path]) {
          existingContent = existingFragmentFiles[path];
          isEdit = true;
          logger2.info({
            msg: "Found file in fragment",
            path,
            charCount: existingContent.length
          });
        } else {
          if (Object.keys(existingFragmentFiles).length === 0) {
            try {
              existingContent = await readFileFromSandbox(
                sandboxInfo.sandbox,
                path
              );
              isEdit = true;
              logger2.info({
                msg: "Found file in sandbox",
                path,
                charCount: existingContent.length
              });
            } catch (error) {
              logger2.info({ msg: "Creating new file", path });
            }
          } else {
            logger2.info({
              msg: "Creating new file (adding to existing fragment)",
              path
            });
          }
        }
        if (CODE_FILE_REGEX.test(path)) {
          logger2.info({ msg: "Validating file syntax before write", path });
          await validateSyntaxOrThrow(path, content);
          logger2.info({ msg: "\u2705 Syntax validation passed", path });
        }
        logger2.info({
          msg: "Writing file to sandbox",
          path,
          contentLength: content.length
        });
        await writeFileToSandbox(sandboxInfo.sandbox, path, content);
        if (path.startsWith("src/routes/") && path.endsWith(".tsx")) {
          await new Promise((resolve) => setTimeout(resolve, 200));
          try {
            const verifyContent = await readFileFromSandbox(
              sandboxInfo.sandbox,
              path
            );
            const isCorrupted = verifyContent.includes('return <div>Hello "') || verifyContent.includes("return <div>Hello '/") || verifyContent.includes('Hello "/') && verifyContent.length < content.length * 0.5;
            if (isCorrupted) {
              logger2.warn({
                msg: "\u{1F504} Route file corrupted by TanStack Router plugin, re-writing",
                path,
                originalLength: content.length,
                corruptedLength: verifyContent.length
              });
              await writeFileToSandbox(sandboxInfo.sandbox, path, content);
              await new Promise((resolve) => setTimeout(resolve, 300));
              const secondVerify = await readFileFromSandbox(
                sandboxInfo.sandbox,
                path
              );
              if (secondVerify.includes('return <div>Hello "') || secondVerify.includes("return <div>Hello '/")) {
                logger2.error({
                  msg: "\u26A0\uFE0F Route file still corrupted after retry - TanStack Router may need manual intervention",
                  path
                });
              } else {
                logger2.info({
                  msg: "\u2705 Route file successfully restored",
                  path
                });
              }
            }
          } catch (verifyError) {
            logger2.warn({
              msg: "Could not verify route file after write",
              path,
              error: verifyError instanceof Error ? verifyError.message : String(verifyError)
            });
          }
        }
        context.files.set(path, {
          size: content.length,
          modified: Date.now()
        });
        context.fragmentFiles.set(path, content);
        logger2.info({
          msg: isEdit ? "Updated file" : "Created file",
          path,
          charCount: content.length,
          description
        });
        await updateWorkingFragment(
          context,
          `${isEdit ? "updated" : "created"} ${path}`
        );
        if (path.endsWith(".tsx") && path.startsWith("src/components/") && !path.includes("/", 16)) {
          try {
            await redisFileStreamPublisher.emitFileCreation({
              projectId: context.projectId,
              filePath: path,
              content,
              timestamp: Date.now(),
              action: isEdit ? "updated" : "created"
            });
            logger2.info({
              msg: "Emitted file creation event for preview",
              path
            });
          } catch (error) {
            logger2.warn({
              msg: "Failed to emit file creation event",
              path,
              error: error instanceof Error ? error.message : String(error)
            });
          }
        }
        const result = {
          success: true,
          path,
          action: isEdit ? "updated" : "created",
          description,
          size: content.length,
          message: `Successfully ${isEdit ? "updated" : "created"} ${path}`
        };
        await trackToolSpan(
          "createOrEditFiles",
          context.userId,
          context.traceId || generateSpanId(),
          { path, description },
          result,
          {
            spanId,
            latency: (Date.now() - startTime) / 1e3,
            isError: false
          }
        );
        await trackToolUsage(
          "createOrEditFiles",
          context.userId,
          context.projectId,
          { path, description },
          result,
          { action: isEdit ? "edited" : "created" }
        );
        return result;
      } catch (error) {
        logger2.error({
          msg: "Failed to process file",
          path,
          error: error instanceof Error ? error.message : String(error)
        });
        const result = {
          success: false,
          path,
          action: "failed",
          description,
          error: error instanceof Error ? error.message : String(error),
          message: `Failed to process ${path}: ${error instanceof Error ? error.message : String(error)}`
        };
        await trackToolSpan(
          "createOrEditFiles",
          context.userId,
          context.traceId || generateSpanId(),
          { path, description },
          result,
          {
            spanId,
            latency: (Date.now() - startTime) / 1e3,
            isError: true,
            error: result.error
          }
        );
        await trackToolUsage(
          "createOrEditFiles",
          context.userId,
          context.projectId,
          { path, description },
          result
        );
        return result;
      }
    } catch (error) {
      logger2.error({
        msg: "Critical error in createOrEditFiles",
        error: error instanceof Error ? error.message : String(error)
      });
      const errorResult = {
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "createOrEditFiles",
        context.userId,
        context.traceId || generateSpanId(),
        { path, description },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      await trackToolUsage(
        "createOrEditFiles",
        context.userId,
        context.projectId,
        { path, description },
        errorResult
      );
      throw error;
    }
  }
});
function transformUrlForDisplay(modalUrl, projectId) {
  const transformedUrl = transformModalUrlForDisplay(modalUrl, projectId, {
    NODE_ENV: process.env.NODE_ENV,
    SKIP_MODAL_URL_TRANSFORM: process.env.SKIP_MODAL_URL_TRANSFORM,
    MODAL_USE_LOCALHOST: process.env.MODAL_USE_LOCALHOST
  });
  if (transformedUrl !== modalUrl) {
    logger.info({
      msg: "URL transformed for display",
      originalUrl: modalUrl,
      transformedUrl,
      projectId
    });
  }
  return transformedUrl;
}
var getSandboxUrl = (context) => tool({
  description: "Get the sandbox url for preview and review",
  inputSchema: z.object({}),
  execute: async (_, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({ msg: "getSandboxUrl called", toolCallId: id });
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      let sandboxUrl = context.sandboxUrl;
      if (!sandboxUrl) {
        logger2.info({
          msg: "URL not in context, retrieving from sandbox"
        });
        const sandboxInfo = await getSandbox2(context.projectId);
        if (!sandboxInfo) {
          throw new Error("Sandbox not found");
        }
        sandboxUrl = sandboxInfo.sandboxUrl;
        if (sandboxUrl) {
          context.sandboxUrl = sandboxUrl;
        }
      }
      if (!sandboxUrl) {
        throw new Error(
          "Sandbox URL not available. The dev server may not be running yet. Try starting it first."
        );
      }
      logger2.info({ msg: "Sandbox URL retrieved", sandboxUrl });
      const displayUrl = transformUrlForDisplay(
        sandboxUrl,
        context.projectId
      );
      logger2.info({
        msg: "URL transformed for display",
        originalUrl: sandboxUrl,
        displayUrl
      });
      const result = {
        type: "sandbox",
        url: displayUrl,
        message: `Sandbox is available at: ${displayUrl}`,
        shouldRefreshPreview: true
      };
      await trackToolSpan(
        "getSandboxUrl",
        context.userId,
        context.traceId || generateSpanId(),
        {},
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "getSandboxUrl",
        context.userId,
        context.projectId,
        {},
        result
      );
      return result;
    } catch (error) {
      const errorResult = {
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "getSandboxUrl",
        context.userId,
        context.traceId || generateSpanId(),
        {},
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      await trackToolUsage(
        "getSandboxUrl",
        context.userId,
        context.projectId,
        {},
        errorResult
      );
      throw error;
    }
  }
});
var finalizeWorkingFragment = (context) => tool({
  description: "Finalize the current working fragment with a descriptive title when you have completed your work. This creates a git commit and updates the fragment to track the commit hash.",
  inputSchema: z.object({
    title: z.string().describe(
      "Descriptive title for what was accomplished (e.g., 'Created login page with validation', 'Added shopping cart functionality')"
    ),
    debugInfo: z.string().optional().describe(DEBUG_INFO_DESCRIPTION)
  }),
  execute: async ({ title, debugInfo }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "finalizeWorkingFragment called",
      title,
      toolCallId: id
    });
    const { currentFragmentId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    if (debugInfo) {
      logger2.info({
        msg: "Debug info provided",
        debugInfo
      });
    }
    try {
      if (!currentFragmentId) {
        const result = {
          success: false,
          message: "No working fragment to finalize"
        };
        await trackToolSpan(
          "finalizeWorkingFragment",
          context.userId,
          context.traceId || generateSpanId(),
          { title },
          result,
          {
            spanId,
            latency: (Date.now() - startTime) / 1e3,
            isError: false
          }
        );
        return result;
      }
      const sandboxInfo = await getSandbox2(context.projectId);
      if (!sandboxInfo) {
        const result = {
          success: false,
          message: "Sandbox not available for git operations"
        };
        await trackToolSpan(
          "finalizeWorkingFragment",
          context.userId,
          context.traceId || generateSpanId(),
          { title },
          result,
          {
            spanId,
            latency: (Date.now() - startTime) / 1e3,
            isError: false
          }
        );
        return result;
      }
      try {
        await updateWorkingFragment(context, "finalizing fragment");
        const existingFragment = await prisma.v2Fragment.findUnique({
          where: { id: currentFragmentId },
          select: { id: true }
        });
        if (!existingFragment) {
          throw new Error(
            `Fragment ${currentFragmentId} no longer exists, cannot finalize`
          );
        }
        const fragment = await prisma.v2Fragment.update({
          where: { id: currentFragmentId },
          data: {
            title,
            updatedAt: /* @__PURE__ */ new Date()
          }
        });
        await prisma.project.update({
          where: { id: context.projectId },
          data: {
            activeFragmentId: fragment.id
          }
        });
        logger2.info({
          msg: "Fragment saved with title (pre-validation)",
          fragmentId: fragment.id,
          title
        });
        logger2.info({ msg: "Running pre-finalize validation gates" });
        const gates = {
          syntaxValid: false,
          buildReady: false,
          previewHealthy: false,
          noUnresolvedErrors: false,
          shipperCloudValid: false
        };
        const validationErrors = [];
        logger2.info({ msg: "Gate 1: Checking file syntax" });
        const fragmentData = await prisma.v2Fragment.findUnique({
          where: { id: currentFragmentId },
          select: { files: true }
        });
        if (fragmentData?.files) {
          const files = fragmentData.files;
          for (const [path, content] of Object.entries(files)) {
            if (!CODE_FILE_REGEX.test(path)) {
              continue;
            }
            try {
              await validateSyntaxOrThrow(path, content);
            } catch (syntaxError) {
              const message = syntaxError instanceof Error ? syntaxError.message : String(syntaxError);
              logger2.error({
                msg: "Syntax validation failed",
                file: path,
                error: message
              });
              validationErrors.push({
                gate: "syntaxValid",
                error: message,
                file: path
              });
            }
          }
        }
        gates.syntaxValid = validationErrors.filter((e) => e.gate === "syntaxValid").length === 0;
        if (gates.syntaxValid) {
          logger2.info({ msg: "\u2705 Gate 1 passed: Syntax is valid" });
        }
        logger2.info({ msg: "Gate 3: Checking preview health" });
        try {
          const previewUrl = context.sandboxUrl || sandboxInfo?.sandboxUrl;
          const isLocalhost = previewUrl && (previewUrl.includes("localhost") || previewUrl.includes("127.0.0.1"));
          const isDev = process.env.NODE_ENV === "development";
          if (isLocalhost && isDev) {
            logger2.info({
              msg: "Skipping preview health check for localhost in dev mode",
              previewUrl
            });
            gates.previewHealthy = true;
          } else {
            await ensurePreviewHealthy(context, sandboxInfo);
            gates.previewHealthy = true;
          }
          logger2.info({ msg: "\u2705 Gate 3 passed: Preview is healthy" });
        } catch (previewError) {
          const reason = previewError instanceof Error ? previewError.message : String(previewError);
          logger2.error({
            msg: "Preview health check failed",
            reason
          });
          validationErrors.push({
            gate: "previewHealthy",
            error: `Preview unhealthy: ${reason}`
          });
        }
        logger2.info({ msg: "Gate 4: Checking for unresolved errors" });
        const errorAnalysis = await analyzeProjectErrors(context, {
          store: true,
          excludeLowSeverity: true
        });
        const blockingErrors = [
          ...errorAnalysis.detectedErrors.buildErrors ?? [],
          ...errorAnalysis.detectedErrors.importErrors ?? [],
          ...errorAnalysis.detectedErrors.navigationErrors ?? [],
          ...errorAnalysis.detectedErrors.runtimeErrors ?? []
        ];
        let errorDetails = "";
        if (blockingErrors.length > 0) {
          logger2.error({
            msg: "Unresolved critical errors found",
            count: blockingErrors.length
          });
          const errorsByType = {
            build: errorAnalysis.detectedErrors.buildErrors ?? [],
            import: errorAnalysis.detectedErrors.importErrors ?? [],
            navigation: errorAnalysis.detectedErrors.navigationErrors ?? [],
            runtime: errorAnalysis.detectedErrors.runtimeErrors ?? []
          };
          errorDetails = Object.entries(errorsByType).filter(([_, errors]) => errors.length > 0).map(([type, errors]) => {
            const errorList = errors.slice(0, 3).map((err) => {
              const errObj = err;
              const file = errObj.file ? ` in ${errObj.file}` : "";
              const line = errObj.line ? `:${errObj.line}` : "";
              return `  - ${errObj.message || "Unknown error"}${file}${line}`;
            }).join("\n");
            const remaining = errors.length > 3 ? `
  ... and ${errors.length - 3} more ${type} errors` : "";
            return `${type.toUpperCase()} ERRORS (${errors.length}):
${errorList}${remaining}`;
          }).join("\n\n");
          validationErrors.push({
            gate: "noUnresolvedErrors",
            error: `${blockingErrors.length} unresolved error(s) found:

${errorDetails}`
          });
        } else {
          gates.noUnresolvedErrors = true;
          logger2.info({ msg: "\u2705 Gate 4 passed: No unresolved errors" });
        }
        logger2.info({ msg: "Gate 5: Checking Shipper Cloud setup" });
        try {
          const convexDeployment = await prisma.convexDeployment.findUnique({
            where: { projectId: context.projectId },
            select: {
              setupComplete: true,
              convexDeploymentUrl: true,
              deployKeyEncrypted: true,
              webhookSecretEncrypted: true,
              webhookConfiguredAt: true
            }
          });
          if (convexDeployment) {
            const shipperCloudErrors = [];
            if (!convexDeployment.setupComplete) {
              shipperCloudErrors.push(
                "Shipper Cloud setup is incomplete. The deployment may have been interrupted. Re-run the deployToShipperCloud tool to complete setup."
              );
            }
            if (!convexDeployment.webhookSecretEncrypted || !convexDeployment.webhookConfiguredAt) {
              shipperCloudErrors.push(
                "Shipper Cloud webhook is not configured. Usage tracking and billing may not work. Re-run the deployToShipperCloud tool to configure the webhook."
              );
            }
            if (fragmentData?.files) {
              const files = fragmentData.files;
              const forbiddenImports = [
                "AuthLoading",
                "Authenticated",
                "Unauthenticated"
              ];
              const forbiddenPattern = new RegExp(
                `import\\s*{[^}]*(${forbiddenImports.join("|")})[^}]*}\\s*from\\s*['"]convex/react['"]`,
                "g"
              );
              for (const [filePath, content] of Object.entries(files)) {
                if (typeof content === "string" && (filePath.endsWith(".tsx") || filePath.endsWith(".ts"))) {
                  const matches = content.match(forbiddenPattern);
                  if (matches) {
                    shipperCloudErrors.push(
                      `File "${filePath}" imports forbidden auth components from 'convex/react': ${matches.join(", ")}. These require ConvexProviderWithAuth which is NOT used by Shipper Cloud. Use useSession from '@/lib/auth-client' instead.`
                    );
                  }
                }
              }
            }
            if (sandboxInfo?.sandboxId) {
              let needsInjection = false;
              let injectionReason = "";
              try {
                const envLocalContent = await readFile(
                  sandboxInfo.sandboxId,
                  ".env.local"
                );
                const requiredEnvVars = [
                  "VITE_CONVEX_URL",
                  "CONVEX_DEPLOY_KEY"
                ];
                const missingVars = [];
                for (const varName of requiredEnvVars) {
                  if (!envLocalContent || !envLocalContent.includes(`${varName}=`)) {
                    missingVars.push(varName);
                  }
                }
                if (missingVars.length > 0) {
                  needsInjection = true;
                  injectionReason = `Missing env vars: ${missingVars.join(", ")}`;
                } else {
                  const urlMatch = envLocalContent.match(/VITE_CONVEX_URL=(.+)/);
                  if (urlMatch && urlMatch[1].trim() !== convexDeployment.convexDeploymentUrl) {
                    needsInjection = true;
                    injectionReason = `Wrong VITE_CONVEX_URL: expected ${convexDeployment.convexDeploymentUrl}, found ${urlMatch[1].trim()}`;
                  }
                }
              } catch (envReadError) {
                needsInjection = true;
                injectionReason = ".env.local file missing or unreadable";
              }
              if (needsInjection) {
                logger2.info({
                  msg: "Auto-injecting Shipper Cloud credentials into sandbox",
                  reason: injectionReason,
                  projectId: context.projectId
                });
                try {
                  await injectDeployKeyIntoSandbox(
                    context.projectId,
                    convexDeployment.deployKeyEncrypted,
                    convexDeployment.convexDeploymentUrl
                  );
                  logger2.info({
                    msg: "\u2705 Successfully auto-injected Shipper Cloud credentials",
                    projectId: context.projectId
                  });
                } catch (injectionError) {
                  shipperCloudErrors.push(
                    `Failed to auto-inject Convex credentials: ${injectionError instanceof Error ? injectionError.message : String(injectionError)}. Sandbox needs VITE_CONVEX_URL=${convexDeployment.convexDeploymentUrl}. Try restarting the sandbox or contact support.`
                  );
                }
              }
            }
            if (shipperCloudErrors.length > 0) {
              for (const error of shipperCloudErrors) {
                validationErrors.push({
                  gate: "shipperCloudValid",
                  error
                });
              }
              logger2.warn({
                msg: "Shipper Cloud validation issues found",
                errors: shipperCloudErrors
              });
            } else {
              gates.shipperCloudValid = true;
              logger2.info({
                msg: "\u2705 Gate 5 passed: Shipper Cloud setup is valid"
              });
            }
          } else {
            gates.shipperCloudValid = true;
            logger2.info({
              msg: "\u2705 Gate 5 passed: Shipper Cloud not enabled (skipped)"
            });
          }
        } catch (shipperCloudError) {
          logger2.warn({
            msg: "Shipper Cloud validation check failed (non-blocking)",
            error: shipperCloudError instanceof Error ? shipperCloudError.message : String(shipperCloudError)
          });
          gates.shipperCloudValid = true;
        }
        let snapshotImageId = null;
        if (sandboxInfo && sandboxInfo.sandbox) {
          logger2.info({ msg: "Creating filesystem snapshot" });
          try {
            snapshotImageId = await createFilesystemSnapshot(
              sandboxInfo.sandbox,
              fragment.id,
              context.projectId
            );
            logger2.info({
              msg: "Snapshot created successfully",
              snapshotImageId,
              fragmentId: fragment.id
            });
          } catch (snapshotError) {
            logger2.warn({
              msg: "Snapshot creation failed (non-critical)",
              error: snapshotError instanceof Error ? snapshotError.message : String(snapshotError),
              fragmentId: fragment.id
            });
          }
        }
        const allGatesPassed = validationErrors.length === 0;
        if (allGatesPassed) {
          logger2.info({ msg: "\u2705 All validation gates passed", gates });
        } else {
          logger2.warn({
            msg: "Fragment saved but validation errors detected",
            fragmentId: fragment.id,
            validationErrorCount: validationErrors.length
          });
        }
        const result = {
          success: true,
          // Fragment was saved successfully
          fragmentId: fragment.id,
          snapshotImageId,
          title: fragment.title,
          message: snapshotImageId ? `Working fragment finalized as: "${title}" with filesystem snapshot ${snapshotImageId}` : `Working fragment finalized as: "${title}"`,
          // Include validation results so AI knows about issues
          validationPassed: allGatesPassed,
          ...validationErrors.length > 0 && {
            validationErrors: validationErrors.map((e) => ({
              gate: e.gate,
              error: e.error,
              ...e.file && { file: e.file }
            })),
            validationWarning: `Fragment saved but ${validationErrors.length} validation issue(s) detected. Consider fixing these issues.`
          },
          ...blockingErrors.length > 0 && {
            unresolvedCount: blockingErrors.length,
            errorsByType: {
              buildErrors: errorAnalysis.detectedErrors.buildErrors?.length ?? 0,
              importErrors: errorAnalysis.detectedErrors.importErrors?.length ?? 0,
              navigationErrors: errorAnalysis.detectedErrors.navigationErrors?.length ?? 0,
              runtimeErrors: errorAnalysis.detectedErrors.runtimeErrors?.length ?? 0
            },
            detailedErrors: errorDetails
          }
        };
        await trackToolSpan(
          "finalizeWorkingFragment",
          context.userId,
          context.traceId || generateSpanId(),
          { title },
          result,
          {
            spanId,
            latency: (Date.now() - startTime) / 1e3,
            isError: false
          }
        );
        await trackToolUsage(
          "finalizeWorkingFragment",
          context.userId,
          context.projectId,
          { title },
          result
        );
        return result;
      } catch (error) {
        logger2.error({
          msg: "Failed to finalize fragment",
          error: error instanceof Error ? error.message : String(error),
          fragmentId: currentFragmentId
        });
        const errorResult = {
          success: false,
          message: "Failed to finalize working fragment",
          error: error instanceof Error ? error.message : String(error)
        };
        await trackToolSpan(
          "finalizeWorkingFragment",
          context.userId,
          context.traceId || generateSpanId(),
          { title },
          errorResult,
          {
            spanId,
            latency: (Date.now() - startTime) / 1e3,
            isError: true,
            error: errorResult.error
          }
        );
        await trackToolUsage(
          "finalizeWorkingFragment",
          context.userId,
          context.projectId,
          { title },
          errorResult
        );
        return errorResult;
      }
    } catch (error) {
      const errorResult = {
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "finalizeWorkingFragment",
        context.userId,
        context.traceId || generateSpanId(),
        { title },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      throw error;
    }
  }
});
var createFragmentSnapshot = (context) => tool({
  description: "Create a complete filesystem snapshot of the current sandbox state. This captures ALL files including build artifacts, node_modules, and user-created files (not just tracked files). Use this before major changes, when work is complete, or to preserve the current state. Only works with Modal sandboxes.",
  inputSchema: z.object({
    reason: z.string().describe(
      "Brief explanation of why this snapshot is being created (e.g., 'before refactoring', 'completed feature', 'milestone reached')"
    )
  }),
  execute: async ({ reason }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "createFragmentSnapshot called",
      reason,
      toolCallId: id
    });
    const { projectId, currentFragmentId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      if (!currentFragmentId) {
        const errorResult = {
          success: false,
          message: "No active fragment to snapshot"
        };
        await trackToolSpan(
          "createFragmentSnapshot",
          context.userId,
          context.traceId || generateSpanId(),
          { reason },
          errorResult,
          {
            spanId,
            latency: (Date.now() - startTime) / 1e3,
            isError: true
          }
        );
        await trackToolUsage(
          "createFragmentSnapshot",
          context.userId,
          projectId,
          { reason },
          errorResult
        );
        return errorResult;
      }
      const sandboxInfo = await getSandbox2(projectId);
      if (!sandboxInfo?.sandbox) {
        const errorResult = {
          success: false,
          message: "Sandbox not available"
        };
        await trackToolSpan(
          "createFragmentSnapshot",
          context.userId,
          context.traceId || generateSpanId(),
          { reason },
          errorResult,
          {
            spanId,
            latency: (Date.now() - startTime) / 1e3,
            isError: true
          }
        );
        await trackToolUsage(
          "createFragmentSnapshot",
          context.userId,
          projectId,
          { reason },
          errorResult
        );
        return errorResult;
      }
      logger2.info({
        msg: "Creating snapshot for fragment",
        fragmentId: currentFragmentId,
        reason
      });
      const snapshotImageId = await createFilesystemSnapshot(
        sandboxInfo.sandbox,
        // Cast to Sandbox type
        currentFragmentId,
        projectId
      );
      const result = {
        success: true,
        snapshotImageId,
        fragmentId: currentFragmentId,
        message: `Filesystem snapshot created successfully: ${snapshotImageId}. Complete project state preserved including all files, build artifacts, and dependencies. Future sandbox restarts will use this snapshot for instant restoration.`,
        reason
      };
      await trackToolSpan(
        "createFragmentSnapshot",
        context.userId,
        context.traceId || generateSpanId(),
        { reason },
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "createFragmentSnapshot",
        context.userId,
        projectId,
        { reason },
        result
      );
      logger2.info({
        msg: "Snapshot created successfully",
        snapshotImageId,
        fragmentId: currentFragmentId
      });
      return result;
    } catch (error) {
      logger2.error({
        msg: "Failed to create snapshot",
        error: error instanceof Error ? error.message : String(error),
        fragmentId: currentFragmentId
      });
      const errorResult = {
        success: false,
        message: "Failed to create filesystem snapshot",
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "createFragmentSnapshot",
        context.userId,
        context.traceId || generateSpanId(),
        { reason },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      await trackToolUsage(
        "createFragmentSnapshot",
        context.userId,
        projectId,
        { reason },
        errorResult
      );
      return errorResult;
    }
  }
});
var installPackages = (context) => tool({
  description: "Install npm packages in the Modal sandbox by running the appropriate package manager command (bun add, npm install, pnpm add, or yarn add). Automatically detects the package manager by checking for lock files (bun.lockb, pnpm-lock.yaml, yarn.lock, package-lock.json). Defaults to bun if no lock file is found. Use this to add dependencies that are needed for the application.",
  inputSchema: z.object({
    packages: z.array(z.string()).describe(
      "Array of package names to install (e.g., ['react-router-dom', 'axios'])"
    ),
    dev: z.boolean().optional().default(false).describe("Install as dev dependencies (default: false)")
  }),
  execute: async ({ packages, dev = false }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "installPackages called",
      packages,
      dev,
      toolCallId: id
    });
    const { sandboxId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      if (!sandboxId) {
        throw new Error("Sandbox not found");
      }
      if (!packages || packages.length === 0) {
        throw new Error("No packages specified for installation");
      }
      const sandboxInfo = await getSandbox2(context.projectId);
      if (!sandboxInfo) {
        throw new Error("Sandbox not available");
      }
      const packageManager = "bun";
      const packagesStr = packages.join(" ");
      const installCommand = `bun add ${dev ? "-d" : ""} ${packagesStr}`;
      logger2.info({
        msg: "Running install command with bun",
        command: installCommand,
        packages,
        dev
      });
      const result = await executeCommand(sandboxId, installCommand, {
        timeoutMs: 12e4
        // 2 minute timeout for package installation
      });
      const exitCode = result.exitCode ?? 0;
      if (exitCode !== 0) {
        const errorOutput = result.stderr || result.stdout || "Installation failed";
        throw new Error(errorOutput);
      }
      const installResult = {
        success: true,
        message: `Successfully installed ${packages.length} package(s) using ${packageManager}`,
        packages,
        dev,
        packageManager,
        stdout: result.stdout
      };
      await trackToolSpan(
        "installPackages",
        context.userId,
        context.traceId || generateSpanId(),
        { packages, dev, packageManager },
        installResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "installPackages",
        context.userId,
        context.projectId,
        { packages, dev, packageManager },
        installResult
      );
      return installResult;
    } catch (error) {
      const logger3 = getLogger(context);
      logger3.error({
        msg: "Package installation failed",
        error: error instanceof Error ? error.message : String(error),
        packages
      });
      const errorResult = {
        success: false,
        packages,
        dev,
        error: error instanceof Error ? error.message : String(error),
        message: `Failed to install packages: ${error instanceof Error ? error.message : String(error)}`
      };
      await trackToolSpan(
        "installPackages",
        context.userId,
        context.traceId || generateSpanId(),
        { packages, dev },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      await trackToolUsage(
        "installPackages",
        context.userId,
        context.projectId,
        { packages, dev },
        errorResult
      );
      throw error;
    }
  }
});
var quickEdit = (context) => tool({
  description: "Make quick, precise code edits using text replacement. This tool applies ALL replacements in the array sequentially. CRITICAL: Patterns must match EXACTLY including all whitespace, attributes, and formatting. If you need to replace multiple variations (e.g., different class names or attributes), you MUST include a separate replacement for each exact pattern. Always read the file first with readFile to see all variations before creating replacements. Example: [{pattern: 'const foo = 1', replacement: 'const foo = 2', description: 'Update foo value'}, {pattern: 'const bar = 1', replacement: 'const bar = 2', description: 'Update bar value'}]",
  inputSchema: z.object({
    filePath: z.string().describe("The path to the file to edit (relative to project root)"),
    replacements: z.array(
      z.object({
        pattern: z.string().describe(
          "The EXACT text pattern to search for and replace. Must match precisely including whitespace, attributes, quotes, etc. If there are multiple variations, create separate replacements for each."
        ),
        replacement: z.string().describe("The new text to replace the pattern with"),
        description: z.string().optional().describe("Optional description of this specific replacement")
      })
    ).describe(
      "Array of text replacements to apply. ALL replacements will be applied sequentially. Each pattern must match EXACTLY. If replacing a symbol (e.g., Plus -> Flame), include separate replacements for: 1) the import statement, 2) each JSX usage with exact attributes/classes, 3) any other variations."
    ),
    description: z.string().describe("Brief description of the changes being made")
  }),
  execute: async ({ filePath, replacements, description }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "quickEdit called",
      filePath,
      replacementCount: replacements.length,
      description,
      toolCallId: id
    });
    const { sandboxId, fragmentFiles, currentFragmentId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      if (!sandboxId) {
        throw new Error("Sandbox not found");
      }
      if (filePath.endsWith("index.css") || filePath.includes("/index.css")) {
        const errorMsg = "\u{1F6A8} CRITICAL SECURITY BLOCK: Editing index.css is not allowed. These templates use Tailwind v4 which relies on index.css for all styling configuration. Modifying this file can break the entire Tailwind setup, theme system, and component styling. All styling should be done through Tailwind utility classes in components instead.";
        logger2.error({ msg: "BLOCKED: index.css edit attempt", filePath });
        throw new Error(errorMsg);
      }
      const sandboxInfo = await getSandbox2(context.projectId);
      if (!sandboxInfo) {
        throw new Error("Sandbox not available");
      }
      if (!context.fragmentFiles) {
        context.fragmentFiles = /* @__PURE__ */ new Map();
      }
      if (!context.files) {
        context.files = /* @__PURE__ */ new Map();
      }
      let originalContent = "";
      let existingFragmentFiles = {};
      if (currentFragmentId) {
        try {
          const existingFragment = await prisma.v2Fragment.findUnique({
            where: { id: currentFragmentId },
            select: { files: true }
          });
          if (existingFragment?.files) {
            existingFragmentFiles = existingFragment.files;
          }
        } catch (error) {
          logger2.warn({
            msg: "Could not load existing fragment files",
            error: error instanceof Error ? error.message : String(error)
          });
        }
      }
      if (existingFragmentFiles[filePath]) {
        originalContent = existingFragmentFiles[filePath];
        logger2.info({
          msg: "Found file in fragment",
          filePath,
          charCount: originalContent.length
        });
      } else {
        try {
          originalContent = await readFileFromSandbox(
            sandboxInfo.sandbox,
            filePath
          );
          logger2.info({
            msg: "Found file in sandbox",
            filePath,
            charCount: originalContent.length
          });
        } catch (error) {
          throw new Error(
            `File ${filePath} not found in sandbox or fragment`
          );
        }
      }
      logger2.info({
        msg: "Applying replacements",
        filePath,
        replacementCount: replacements.length
      });
      replacements.forEach((replacement, index) => {
        logger2.info({
          msg: `Replacement ${index + 1}`,
          patternLength: replacement.pattern.length,
          replacementLength: replacement.replacement.length,
          description: replacement.description
        });
      });
      let editedContent = originalContent;
      let totalReplacements = 0;
      const appliedReplacements = [];
      try {
        logger2.info({ msg: "Applying manual replacements" });
        for (const replacement of replacements) {
          const { pattern, replacement: newValue } = replacement;
          const escapedPattern = pattern.replace(
            /[.*+?^${}()|[\]\\]/g,
            "\\$&"
          );
          const patternCount = (editedContent.match(new RegExp(escapedPattern, "g")) || []).length;
          if (patternCount === 0) {
            logger2.warn({
              msg: "Pattern not found in content",
              pattern: pattern.substring(0, 50)
            });
            appliedReplacements.push({
              pattern,
              replacement: newValue,
              applied: false
            });
            continue;
          }
          const contentBeforeReplacement = editedContent;
          try {
            editedContent = editedContent.replace(
              new RegExp(escapedPattern, "g"),
              newValue
            );
          } catch (regexError) {
            logger2.warn({
              msg: "Regex replacement failed, using simple string replace",
              error: regexError instanceof Error ? regexError.message : String(regexError)
            });
            editedContent = editedContent.split(pattern).join(newValue);
          }
          const contentChanged = editedContent !== contentBeforeReplacement;
          if (contentChanged) {
            totalReplacements++;
            appliedReplacements.push({
              pattern,
              replacement: newValue,
              applied: true
            });
            logger2.info({
              msg: "Replacement applied",
              patternCount
            });
          } else {
            appliedReplacements.push({
              pattern,
              replacement: newValue,
              applied: false
            });
            logger2.warn({
              msg: "Pattern found but replacement did not change content",
              pattern: pattern.substring(0, 50)
            });
          }
        }
        editedContent = ensureMonitoringScript(editedContent, filePath);
        await validateSyntaxOrThrow(filePath, editedContent);
        await writeFileToSandbox(
          sandboxInfo.sandbox,
          filePath,
          editedContent
        );
        if (filePath.startsWith("src/routes/") && filePath.endsWith(".tsx")) {
          await new Promise((resolve) => setTimeout(resolve, 200));
          try {
            const verifyContent = await readFileFromSandbox(
              sandboxInfo.sandbox,
              filePath
            );
            const isCorrupted = verifyContent.includes('return <div>Hello "') || verifyContent.includes("return <div>Hello '/") || verifyContent.includes('Hello "/') && verifyContent.length < editedContent.length * 0.5;
            if (isCorrupted) {
              logger2.warn({
                msg: "\u{1F504} Route file corrupted by TanStack Router plugin (quickEdit), re-writing",
                filePath
              });
              await writeFileToSandbox(
                sandboxInfo.sandbox,
                filePath,
                editedContent
              );
            }
          } catch (verifyError) {
            logger2.warn({
              msg: "Could not verify route file after quickEdit",
              filePath,
              error: verifyError instanceof Error ? verifyError.message : String(verifyError)
            });
          }
        }
        logger2.info({
          msg: "Content modified",
          filePath,
          originalLength: originalContent.length,
          editedLength: editedContent.length,
          totalReplacements
        });
      } catch (replacementError) {
        logger2.error({
          msg: "Replacement failed",
          filePath,
          error: replacementError instanceof Error ? replacementError.message : String(replacementError)
        });
        throw replacementError;
      }
      const failedReplacements = appliedReplacements.filter(
        (r) => !r.applied
      );
      const expectedReplacements = replacements.length;
      const allReplacementsApplied = appliedReplacements.every(
        (r) => r.applied
      );
      const remainingReferences = [];
      for (const replacement of replacements) {
        const importMatch = replacement.pattern.match(
          /import\s*\{\s*(\w+)\s*\}/
        );
        const jsxMatch = replacement.pattern.match(/<(\w+)(?:\s|>|\/)/);
        const oldSymbol = importMatch?.[1] || jsxMatch?.[1];
        const newImportMatch = replacement.replacement.match(
          /import\s*\{\s*(\w+)\s*\}/
        );
        const newJsxMatch = replacement.replacement.match(/<(\w+)(?:\s|>|\/)/);
        const newSymbol = newImportMatch?.[1] || newJsxMatch?.[1];
        if (oldSymbol && newSymbol && oldSymbol !== newSymbol) {
          const escapedSymbol = oldSymbol.replace(
            /[.*+?^${}()|[\]\\]/g,
            "\\$&"
          );
          const symbolPatterns = [
            new RegExp(`<${escapedSymbol}(?:\\s|>|/|\\{)`, "g"),
            new RegExp(`\\{${escapedSymbol}\\}`, "g"),
            new RegExp(`\\b${escapedSymbol}\\.`, "g")
          ];
          for (const pattern of symbolPatterns) {
            const matches = editedContent.match(pattern);
            if (matches && matches.length > 0) {
              remainingReferences.push(
                `Found remaining reference to '${oldSymbol}' (${matches.length} occurrence${matches.length > 1 ? "s" : ""})`
              );
              break;
            }
          }
        }
        if (!oldSymbol) {
          const escapedPattern = replacement.pattern.replace(
            /[.*+?^${}()|[\]\\]/g,
            "\\$&"
          );
          try {
            const patternMatches = editedContent.match(
              new RegExp(escapedPattern, "g")
            );
            if (patternMatches && patternMatches.length > 0) {
              remainingReferences.push(
                `Pattern still found in content: "${replacement.pattern.substring(0, 30)}..."`
              );
            }
          } catch {
          }
        }
      }
      context.files.set(filePath, {
        size: editedContent.length,
        modified: Date.now()
      });
      context.fragmentFiles.set(filePath, editedContent);
      await updateWorkingFragment(
        context,
        `Quick edited ${filePath}: ${description}`
      );
      const wasModified = editedContent !== originalContent;
      const warnings = [];
      if (!allReplacementsApplied) {
        warnings.push(
          `Only ${totalReplacements} of ${expectedReplacements} replacements were applied.`
        );
      }
      if (failedReplacements.length > 0) {
        warnings.push(
          `${failedReplacements.length} replacement(s) failed: ${failedReplacements.map((r) => `"${r.pattern.substring(0, 30)}..."`).join(", ")}`
        );
      }
      if (remainingReferences.length > 0) {
        warnings.push(
          `\u26A0\uFE0F Partial edit detected: ${remainingReferences.join("; ")}`
        );
      }
      const result = {
        success: wasModified && allReplacementsApplied && remainingReferences.length === 0,
        filePath,
        action: wasModified ? "quick_edited" : "no_changes",
        description,
        replacementsApplied: totalReplacements,
        replacementsExpected: expectedReplacements,
        replacementsFailed: failedReplacements.length,
        originalSize: originalContent.length,
        newSize: editedContent.length,
        sizeDelta: editedContent.length - originalContent.length,
        replacements: replacements.map((r) => {
          const applied = appliedReplacements.find((ar) => ar.pattern === r.pattern)?.applied ?? false;
          return {
            pattern: r.pattern.substring(0, 50) + (r.pattern.length > 50 ? "..." : ""),
            replacement: r.replacement.substring(0, 50) + (r.replacement.length > 50 ? "..." : ""),
            description: r.description,
            applied
          };
        }),
        warnings: warnings.length > 0 ? warnings : void 0,
        remainingReferences: remainingReferences.length > 0 ? remainingReferences : void 0,
        message: wasModified ? allReplacementsApplied && remainingReferences.length === 0 ? `Applied ${totalReplacements} text replacements successfully` : `Applied ${totalReplacements} of ${expectedReplacements} replacements${warnings.length > 0 ? ` - ${warnings.join(" ")}` : ""}` : `No changes made - patterns may not have been found`
      };
      logger2.info({
        msg: wasModified ? "Successfully applied replacements" : "No changes from replacements",
        filePath,
        replacementCount: replacements.length,
        replacementsApplied: totalReplacements,
        originalLength: originalContent.length,
        editedLength: editedContent.length
      });
      await trackToolSpan(
        "quickEdit",
        context.userId,
        context.traceId || generateSpanId(),
        { filePath, replacementsCount: replacements.length, description },
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "quickEdit",
        context.userId,
        context.projectId,
        { filePath, replacementsCount: replacements.length, description },
        result,
        { wasModified }
      );
      return result;
    } catch (error) {
      logger2.error({
        msg: "Failed to edit file",
        filePath,
        error: error instanceof Error ? error.message : String(error)
      });
      const errorResult = {
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "quickEdit",
        context.userId,
        context.traceId || generateSpanId(),
        { filePath, replacementsCount: replacements.length, description },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      throw error;
    }
  }
});
var detectErrors = (context) => tool({
  description: "\u{1F6A8} MANDATORY: Detect and analyze code errors, then STORE them in the database for autoFixErrors. This tool MUST be run BEFORE autoFixErrors. It identifies build errors, TypeScript issues, import problems, and runtime errors, then stores them in the projectError database table. autoFixErrors reads from this database. ALWAYS run this after making ANY code changes (initial build or edits). This is not optional - it's required for the error fix workflow.",
  inputSchema: z.object({
    includeAutoFix: z.boolean().optional().default(false).describe("Include auto-fix suggestions for detected errors"),
    severity: z.enum(["low", "medium", "high", "critical"]).optional().describe("Filter errors by minimum severity level")
  }),
  execute: async ({ includeAutoFix = false, severity }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "detectErrors called",
      includeAutoFix,
      severity,
      toolCallId: id
    });
    const { fragmentFiles, projectId, userId, traceId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      const analysis = await analyzeProjectErrors(context, {
        includeAutoFix,
        severity,
        store: true,
        excludeLowSeverity: true
      });
      const detectedErrors = analysis.detectedErrors;
      const classification = ErrorClassifier.categorizeErrors(detectedErrors);
      const result = {
        success: true,
        errors: detectedErrors,
        classification,
        summary: {
          totalErrors: detectedErrors.totalErrors,
          severity: detectedErrors.severity || "low",
          // ‚Üê Add severity to summary with fallback
          autoFixable: detectedErrors.autoFixable,
          buildErrors: detectedErrors.buildErrors.length,
          importErrors: detectedErrors.importErrors.length,
          navigationErrors: detectedErrors.navigationErrors.length,
          analysisType: analysis.analysisType
        },
        message: `Found ${detectedErrors.totalErrors} error${detectedErrors.totalErrors !== 1 ? "s" : ""} - ${detectedErrors.severity || "low"} severity`
      };
      await trackToolSpan(
        "detectErrors",
        userId,
        traceId || generateSpanId(),
        { includeAutoFix, severity },
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "detectErrors",
        userId,
        projectId,
        { includeAutoFix, severity },
        result.summary
      );
      return result;
    } catch (error) {
      logger2.error({
        msg: "Error detection failed",
        error: error instanceof Error ? error.message : String(error)
      });
      const errorResult = {
        success: false,
        error: error instanceof Error ? error.message : String(error),
        errors: null,
        summary: { totalErrors: 0, autoFixable: false }
      };
      await trackToolSpan(
        "detectErrors",
        userId,
        traceId || generateSpanId(),
        { includeAutoFix, severity },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true
        }
      );
      return errorResult;
    }
  }
});
var autoFixErrors = (context) => tool({
  description: "\u{1F6A8} CRITICAL: Automatically fix errors that were detected and stored by detectErrors. MANDATORY REQUIREMENT: You MUST run detectErrors BEFORE calling this tool. detectErrors stores errors in the database, and autoFixErrors reads from that database. Calling this without detectErrors will fail.",
  inputSchema: z.object({
    severity: z.enum(["low", "medium", "high", "critical"]).optional().describe("Minimum severity level of errors to fix"),
    maxFixes: z.number().optional().default(10).describe("Maximum number of errors to fix in one operation")
  }),
  execute: async ({ severity, maxFixes = 10 }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "autoFixErrors called",
      severity,
      maxFixes,
      toolCallId: id
    });
    const { projectId, userId, traceId, currentFragmentId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      const targetFragment = await prisma.v2Fragment.findFirst({
        where: { projectId },
        orderBy: { createdAt: "desc" },
        select: { id: true, title: true, files: true }
      });
      if (!targetFragment || !targetFragment.files) {
        const result2 = {
          success: false,
          error: "No fragment found to fix",
          errorCount: 0,
          fixedCount: 0,
          message: "No fragment found with files to fix"
        };
        await trackToolUsage(
          "autoFixErrors",
          userId,
          projectId,
          { severity, maxFixes },
          { success: result2.success, fixedCount: result2.fixedCount }
        );
        return result2;
      }
      const fragmentFiles = targetFragment.files;
      logger2.info({
        msg: "Starting auto-fix for fragment",
        fragmentId: targetFragment.id
      });
      const analysis = await analyzeProjectErrors(context, {
        includeAutoFix: false,
        store: true,
        excludeLowSeverity: false
      });
      const detectedErrors = analysis.detectedErrors;
      if (detectedErrors.totalErrors === 0) {
        const result2 = {
          success: true,
          errorCount: 0,
          fixedCount: 0,
          message: "No errors found to fix"
        };
        await trackToolUsage(
          "autoFixErrors",
          userId,
          projectId,
          { severity, maxFixes },
          { success: result2.success, fixedCount: result2.fixedCount }
        );
        return result2;
      }
      const sandboxInfo = await getSandbox2(projectId);
      const voltAgent = new VoltAgentService();
      const allErrors = [
        ...detectedErrors.buildErrors,
        ...detectedErrors.importErrors,
        ...detectedErrors.navigationErrors
      ];
      const severityOrder = {
        critical: 0,
        high: 1,
        medium: 2,
        low: 3
      };
      allErrors.sort((a, b) => {
        const aSeverityStr = a.severity?.toString().toLowerCase() || "low";
        const bSeverityStr = b.severity?.toString().toLowerCase() || "low";
        const aSeverity = severityOrder[aSeverityStr] ?? 999;
        const bSeverity = severityOrder[bSeverityStr] ?? 999;
        return aSeverity - bSeverity;
      });
      logger2.info({
        msg: "Processing errors with VoltAgent (sorted by severity)",
        errorCount: Math.min(allErrors.length, maxFixes),
        totalErrors: allErrors.length,
        highSeverity: allErrors.filter((e) => {
          const sev = e.severity?.toString().toLowerCase();
          return sev === "high" || sev === "critical";
        }).length
      });
      const fixResults = [];
      let successfulFixes = 0;
      let failedFixes = 0;
      for (const error of allErrors.slice(0, maxFixes)) {
        try {
          logger2.info({
            msg: "Fixing error",
            errorId: error.id,
            errorType: error.type,
            severity: error.severity
          });
          const errorContext = {
            id: error.id,
            type: error.type,
            details: {
              ...error.details,
              // Import errors have file/importPath at top level, move them to details
              file: error.file || error.details?.file,
              importPath: error.importPath || error.details?.importPath,
              // Navigation errors have route at top level
              route: error.route || error.details?.route
            },
            severity: error.severity,
            autoFixable: error.autoFixable
          };
          const fixResult = await voltAgent.fixError(
            errorContext,
            fragmentFiles,
            sandboxInfo?.sandbox
          );
          if (fixResult.success) {
            successfulFixes++;
            fixResults.push({
              errorId: error.id,
              success: true,
              fixedFiles: fixResult.fixedFiles,
              strategy: fixResult.strategy,
              changes: fixResult.changes
            });
            logger2.info({
              msg: "Successfully fixed error",
              errorId: error.id
            });
          } else {
            failedFixes++;
            fixResults.push({
              errorId: error.id,
              success: false,
              reason: fixResult.reason
            });
            logger2.info({
              msg: "Failed to fix error",
              errorId: error.id,
              reason: fixResult.reason
            });
          }
        } catch (fixError) {
          logger2.error({
            msg: "Error fixing error",
            errorId: error.id,
            error: fixError instanceof Error ? fixError.message : String(fixError)
          });
          failedFixes++;
          fixResults.push({
            errorId: error.id,
            success: false,
            reason: fixError instanceof Error ? fixError.message : "Unknown error"
          });
        }
      }
      let newFragmentId = null;
      if (successfulFixes > 0) {
        const updatedFiles = { ...fragmentFiles };
        for (const fix of fixResults.filter((r) => r.success)) {
          if (fix.fixedFiles && typeof fix.fixedFiles === "object") {
            Object.assign(updatedFiles, fix.fixedFiles);
          }
        }
        const newFragment = await prisma.v2Fragment.create({
          data: {
            projectId,
            title: `${targetFragment.title} (Auto-fixed)`,
            files: updatedFiles
          }
        });
        newFragmentId = newFragment.id;
        await prisma.project.update({
          where: { id: projectId },
          data: {
            activeFragmentId: newFragment.id,
            updatedAt: /* @__PURE__ */ new Date()
          }
        });
        context.currentFragmentId = newFragment.id;
        context.fragmentFiles = new Map(Object.entries(updatedFiles));
        logger2.info({
          msg: "Created new fragment with fixes",
          newFragmentId,
          originalFragmentId: targetFragment.id
        });
      }
      const successRate = allErrors.length > 0 ? successfulFixes / allErrors.length * 100 : 0;
      const result = {
        success: successfulFixes > 0,
        errorCount: allErrors.length,
        fixedCount: successfulFixes,
        failedCount: failedFixes,
        successRate: successRate.toFixed(1),
        newFragmentId,
        originalFragmentId: targetFragment.id,
        message: successfulFixes > 0 ? `Successfully fixed ${successfulFixes} out of ${allErrors.length} errors (${successRate.toFixed(1)}%)` : `Could not auto-fix any of the ${allErrors.length} errors`
      };
      await trackToolSpan(
        "autoFixErrors",
        userId,
        traceId || generateSpanId(),
        { severity, maxFixes },
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: successfulFixes === 0
        }
      );
      await trackToolUsage(
        "autoFixErrors",
        userId,
        projectId,
        { severity, maxFixes },
        { success: result.success, fixedCount: result.fixedCount }
      );
      return result;
    } catch (error) {
      logger2.error({
        msg: "Auto-fix failed",
        error: error instanceof Error ? error.message : String(error)
      });
      const errorResult = {
        success: false,
        error: error instanceof Error ? error.message : String(error),
        errorCount: 0,
        fixedCount: 0
      };
      await trackToolSpan(
        "autoFixErrors",
        userId,
        traceId || generateSpanId(),
        { severity, maxFixes },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true
        }
      );
      return errorResult;
    }
  }
});
var simpleMessage = (context) => tool({
  description: "Display a simple message in the chat window without any LLM action. Used for showing status updates like 'AutoFix Successful'.",
  inputSchema: z.object({
    message: z.string().describe("The message to display in the chat window"),
    type: z.enum(["success", "info", "warning", "error"]).optional().default("success").describe("The type of message for styling purposes")
  }),
  execute: async ({ message, type = "success" }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "simpleMessage called",
      message,
      type,
      toolCallId: id
    });
    const { userId, traceId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      const result = {
        success: true,
        message,
        type,
        timestamp: (/* @__PURE__ */ new Date()).toISOString()
      };
      await trackToolSpan(
        "simpleMessage",
        userId,
        traceId || generateSpanId(),
        { message, type },
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "simpleMessage",
        userId,
        context.projectId,
        { message, type },
        result
      );
      return result;
    } catch (error) {
      logger2.error({
        msg: "Failed to display message",
        error: error instanceof Error ? error.message : String(error)
      });
      const errorResult = {
        success: false,
        error: error instanceof Error ? error.message : String(error),
        message,
        type
      };
      await trackToolSpan(
        "simpleMessage",
        userId,
        traceId || generateSpanId(),
        { message, type },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true
        }
      );
      return errorResult;
    }
  }
});
var manageTodos = (context) => tool({
  description: "Manage task tracking for complex operations. Create, update, or list todos to decompose large tasks into manageable steps. This helps track progress and ensures all requirements are met systematically.",
  inputSchema: z.object({
    action: z.enum(["create", "update", "list", "clear"]).describe("The action to perform on todos"),
    todos: z.array(
      z.object({
        id: z.string().describe("Unique identifier for the todo"),
        title: z.string().describe("Brief title of the task"),
        description: z.string().optional().describe("Detailed description of what needs to be done"),
        status: z.enum(["pending", "in_progress", "completed", "cancelled"]).describe("Current status of the task"),
        dependencies: z.array(z.string()).optional().describe("IDs of tasks that must be completed first")
      })
    ).optional().describe("Array of todos (required for create/update actions)")
  }),
  execute: async ({ action, todos: inputTodos }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "manageTodos called",
      action,
      toolCallId: id
    });
    const { userId, traceId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      if (!context.todos) {
        context.todos = [];
      }
      const result = { success: true, action };
      switch (action) {
        case "create":
          if (!inputTodos || inputTodos.length === 0) {
            throw new Error("Todos array is required for create action");
          }
          const newTodos = inputTodos.map((todo) => ({
            ...todo,
            createdAt: /* @__PURE__ */ new Date(),
            completedAt: void 0
          }));
          context.todos.push(...newTodos);
          result.todos = context.todos;
          result.message = `Created ${newTodos.length} new todo(s)`;
          logger2.info({
            msg: "Created todos",
            count: newTodos.length,
            todos: newTodos.map((t) => ({
              id: t.id,
              title: t.title,
              status: t.status
            }))
          });
          break;
        case "update":
          if (!inputTodos || inputTodos.length === 0) {
            throw new Error("Todos array is required for update action");
          }
          let updatedCount = 0;
          for (const inputTodo of inputTodos) {
            const existingIndex = context.todos.findIndex(
              (t) => t.id === inputTodo.id
            );
            if (existingIndex !== -1) {
              const wasCompleted = context.todos[existingIndex].status === "completed";
              const isNowCompleted = inputTodo.status === "completed";
              context.todos[existingIndex] = {
                ...context.todos[existingIndex],
                ...inputTodo,
                completedAt: isNowCompleted && !wasCompleted ? /* @__PURE__ */ new Date() : context.todos[existingIndex].completedAt
              };
              updatedCount++;
              logger2.info({
                msg: "Updated todo",
                todoId: inputTodo.id,
                title: inputTodo.title,
                status: inputTodo.status
              });
            }
          }
          result.todos = context.todos;
          result.message = `Updated ${updatedCount} todo(s)`;
          break;
        case "list":
          result.todos = context.todos;
          result.summary = {
            total: context.todos.length,
            pending: context.todos.filter((t) => t.status === "pending").length,
            in_progress: context.todos.filter(
              (t) => t.status === "in_progress"
            ).length,
            completed: context.todos.filter((t) => t.status === "completed").length,
            cancelled: context.todos.filter((t) => t.status === "cancelled").length
          };
          result.message = `Retrieved ${context.todos.length} todo(s)`;
          logger2.info({
            msg: "Listed todos",
            totalCount: context.todos.length,
            summary: result.summary
          });
          break;
        case "clear":
          const clearedCount = context.todos.length;
          context.todos = [];
          result.todos = [];
          result.message = `Cleared ${clearedCount} todo(s)`;
          logger2.info({
            msg: "Cleared all todos",
            clearedCount
          });
          break;
      }
      await trackToolSpan(
        "manageTodos",
        userId,
        traceId || generateSpanId(),
        { action, todosCount: inputTodos?.length },
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "manageTodos",
        userId,
        context.projectId,
        { action, todosCount: inputTodos?.length },
        result
      );
      return result;
    } catch (error) {
      logger2.error({
        msg: "Failed to manage todos",
        error: error instanceof Error ? error.message : String(error)
      });
      const errorResult = {
        success: false,
        action,
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "manageTodos",
        userId,
        traceId || generateSpanId(),
        { action },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      return errorResult;
    }
  }
});
var applyTheme = (context) => tool({
  description: "Apply a theme to the project",
  inputSchema: z.object({
    theme: z.string().describe("The theme to apply to the project")
  }),
  execute: async ({ theme }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "applyTheme called",
      theme,
      toolCallId: id
    });
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      const sandboxInfo = await getSandbox2(context.projectId);
      if (!sandboxInfo || !sandboxInfo.sandbox) {
        throw new Error("Sandbox not found");
      }
      const themeAllowed = V2_THEME_KEYS.includes(theme);
      if (!themeAllowed) {
        const result2 = {
          success: false,
          error: `Theme ${theme} is not allowed. Allowed themes: ${V2_THEME_KEYS.join(", ")}`
        };
        return result2;
      }
      logger2.info({ msg: "Applying theme", theme });
      logger2.warn({
        msg: "Theme changes not supported for Modal sandboxes",
        theme
      });
      const result = { success: true, theme };
      await trackToolSpan(
        "applyTheme",
        context.userId,
        context.traceId || generateSpanId(),
        { theme },
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: false
        }
      );
      await trackToolUsage(
        "applyTheme",
        context.userId,
        context.projectId,
        { theme },
        result
      );
      return result;
    } catch (error) {
      const errorResult = {
        error: error instanceof Error ? error.message : String(error)
      };
      await trackToolSpan(
        "applyTheme",
        context.userId,
        context.traceId || generateSpanId(),
        { theme },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      await trackToolUsage(
        "applyTheme",
        context.userId,
        context.projectId,
        { theme },
        errorResult
      );
      throw error;
    }
  }
});
var generateImage = (context) => tool({
  description: "Creates images from text prompts and saves them to the sandbox. Supports multiple images in one call. Include style descriptions in your prompts (e.g., 'watercolor style', 'anime art', 'realistic photography').",
  inputSchema: z.object({
    images: z.array(
      z.object({
        prompt: z.string().describe(
          "Detailed description of the image to generate, including style (e.g., 'watercolor style landscape', 'anime character portrait', 'realistic product photo')"
        ),
        filename: z.string().optional().describe(
          "Custom filename (without extension). If not provided, auto-generates based on timestamp"
        )
      })
    ).describe(
      "Array of images to generate (supports multiple images in one call)"
    )
  }),
  execute: async ({ images }, { toolCallId: id }) => {
    const logger2 = getLogger(context);
    logger2.info({
      msg: "generateImage called",
      imageCount: images.length,
      toolCallId: id
    });
    const { userId, projectId, traceId } = context;
    const spanId = generateSpanId();
    const startTime = Date.now();
    try {
      const sandboxInfo = await getSandbox2(context.projectId);
      if (!sandboxInfo || !sandboxInfo.sandbox) {
        throw new Error("Sandbox not found");
      }
      const sandbox = sandboxInfo.sandbox;
      if (!images || images.length === 0) {
        throw new Error("No images specified for generation");
      }
      if (!context.fragmentFiles) {
        context.fragmentFiles = /* @__PURE__ */ new Map();
      }
      if (!context.files) {
        context.files = /* @__PURE__ */ new Map();
      }
      const generatedImages = [];
      let totalImageCost = 0;
      try {
        await executeCommand(
          context.sandboxId,
          "mkdir -p /workspace/public/images"
        );
      } catch (error) {
        logger2.warn({
          msg: "Could not create images directory",
          error: error instanceof Error ? error.message : String(error)
        });
      }
      const imagePromises = images.map(async (imageRequest, i) => {
        const timestamp = Date.now();
        if (imageRequest.filename) {
          const protectedFilenames = ["favicon", "share-image"];
          const baseFilename = imageRequest.filename.toLowerCase().replace(/\.[^.]*$/, "");
          if (protectedFilenames.includes(baseFilename)) {
            throw new Error(
              `\u{1F6A8} CRITICAL BLOCK: Cannot generate image with filename "${imageRequest.filename}". The names "favicon" and "share-image" are reserved for user-uploaded metadata files configured through the publish settings. Please use a different filename for your generated image.`
            );
          }
        }
        const filename = imageRequest.filename || `ai-generated-${timestamp}-${i}`;
        const filenameWithExt = `${filename}.png`;
        logger2.info({
          msg: "Generating image",
          imageNumber: i + 1,
          totalImages: images.length,
          prompt: imageRequest.prompt
        });
        try {
          const response = await fetch(
            "https://openrouter.ai/api/v1/chat/completions",
            {
              method: "POST",
              headers: {
                Authorization: `Bearer ${process.env.OPENROUTER_API_KEY}`,
                "Content-Type": "application/json"
              },
              body: JSON.stringify({
                model: "google/gemini-2.5-flash-image-preview",
                usage: {
                  include: true
                },
                messages: [
                  {
                    role: "user",
                    content: imageRequest.prompt
                  }
                ],
                modalities: ["image", "text"]
              })
            }
          );
          if (!response.ok) {
            throw new Error(
              `OpenRouter API returned status ${response.status}: ${await response.text()}`
            );
          }
          const data = await response.json();
          const imageUrl = data?.choices?.[0]?.message?.images?.[0]?.image_url?.url;
          if (!imageUrl) {
            throw new Error("No image URL in response");
          }
          console.log("image metadata", data);
          const imageCost = data?.usage?.cost || 0;
          logger2.info({
            msg: "Image generation cost captured",
            imageNumber: i + 1,
            costUSD: imageCost,
            promptTokens: data?.usage?.prompt_tokens,
            completionTokens: data?.usage?.completion_tokens
          });
          const imageResponse = await fetch(imageUrl);
          if (!imageResponse.ok) {
            throw new Error(
              `Failed to download image: ${imageResponse.status} ${imageResponse.statusText}`
            );
          }
          const imageBuffer = Buffer2.from(await imageResponse.arrayBuffer());
          const relativePath = `public/images/${filenameWithExt}`;
          const modalSandbox = sandbox;
          const fullPath = `/workspace/${relativePath}`;
          const dirPath = fullPath.substring(0, fullPath.lastIndexOf("/"));
          if (dirPath) {
            await modalSandbox.exec(["mkdir", "-p", dirPath]);
          }
          const file = await modalSandbox.open(fullPath, "w");
          await file.write(new Uint8Array(imageBuffer));
          await file.close();
          if (context.files) {
            context.files.set(relativePath, {
              size: imageBuffer.length,
              modified: Date.now()
            });
          }
          if (context.fragmentFiles) {
            context.fragmentFiles.set(
              relativePath,
              `[Binary image file: ${filenameWithExt}]`
            );
          }
          return {
            path: `/images/${filenameWithExt}`,
            filename: filenameWithExt,
            prompt: imageRequest.prompt,
            success: true,
            cost: imageCost
          };
        } catch (error) {
          logger2.error({
            msg: "Failed to generate image",
            imageNumber: i + 1,
            error: error instanceof Error ? error.message : String(error)
          });
          return {
            path: "",
            filename: filenameWithExt,
            prompt: imageRequest.prompt,
            success: false,
            error: error instanceof Error ? error.message : String(error)
          };
        }
      });
      const results = await Promise.all(imagePromises);
      generatedImages.push(...results);
      totalImageCost = generatedImages.filter((img) => img.success && img.cost).reduce((sum, img) => sum + (img.cost || 0), 0);
      logger2.info({
        msg: "Total image generation cost",
        totalCostUSD: totalImageCost,
        successfulImages: generatedImages.filter((img) => img.success).length
      });
      const successCount = generatedImages.filter(
        (img) => img.success
      ).length;
      if (successCount > 0) {
        await updateWorkingFragment(
          context,
          `generated ${successCount} AI image${successCount > 1 ? "s" : ""}`
        );
      }
      const allSuccessful = generatedImages.every((img) => img.success);
      const result = {
        success: allSuccessful,
        images: generatedImages,
        totalRequested: images.length,
        totalGenerated: successCount,
        totalCostUSD: totalImageCost,
        message: allSuccessful ? `Successfully generated ${successCount} image${successCount > 1 ? "s" : ""}` : `Generated ${successCount}/${images.length} images (${images.length - successCount} failed`
      };
      await trackToolSpan(
        "generateImage",
        userId,
        traceId || generateSpanId(),
        { imageCount: images.length },
        result,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: !allSuccessful
        }
      );
      await trackToolUsage(
        "generateImage",
        userId,
        projectId,
        { imageCount: images.length },
        result
      );
      return result;
    } catch (error) {
      logger2.error({
        msg: "Image generation failed",
        error: error instanceof Error ? error.message : String(error)
      });
      const errorResult = {
        success: false,
        images: [],
        totalRequested: images.length,
        totalGenerated: 0,
        error: error instanceof Error ? error.message : String(error),
        message: `Failed to generate images: ${error instanceof Error ? error.message : String(error)}`
      };
      await trackToolSpan(
        "generateImage",
        userId,
        traceId || generateSpanId(),
        { imageCount: images.length },
        errorResult,
        {
          spanId,
          latency: (Date.now() - startTime) / 1e3,
          isError: true,
          error: errorResult.error
        }
      );
      return errorResult;
    }
  }
});
var deployToShipperCloud = (context) => tool({
  description: `Enable Shipper Cloud (Convex backend) for this project.

\u26A0\uFE0F REQUIRES USER CONFIRMATION - This tool asks the user to confirm before deploying.

\u{1F6AB} NEVER CALL THIS TOOL ON THE FIRST USER MESSAGE! \u{1F6AB}
- Always build the frontend UI FIRST with mock/placeholder data
- Show the user something tangible before offering backend infrastructure
- Only call this tool AFTER you have created the initial app and the user can see it working

This provisions a production-ready backend with:
- Real-time database with automatic sync
- Type-safe queries and mutations
- Convex Auth integration (email/password authentication)
- File storage capabilities
- Scheduled functions (cron jobs)

WHEN TO CALL THIS TOOL:
- ONLY after you have already built the frontend UI with mock data
- User explicitly asks to "connect a database" or "make it real"
- User wants to persist data after seeing the UI working
- You have shown the app working and now need real data persistence

WHEN NOT TO CALL THIS TOOL:
- On the first message (NEVER - build UI first!)
- When user describes an app idea (build the UI first instead)
- Before you have created any React components
- Before the user has seen a working preview

WORKFLOW:
1. Build the frontend UI with mock/placeholder data FIRST
2. Let user see and interact with the app
3. THEN call this tool when ready for real data persistence
4. Call this tool without confirmed=true \u2192 Returns "pending_confirmation" status
5. Wait for user to confirm in the UI
6. If user confirms, they will tell you to proceed
7. Call this tool again with confirmed=true to execute deployment
8. After deployment succeeds, call deployConvex to generate types

Do NOT:
- Call this tool on the user's first message
- Create convex/ directory or files before deployment succeeds
- Set up ConvexAuthProvider before deployment succeeds
- Skip the confirmation step`,
  inputSchema: z.object({
    projectName: z.string().describe(
      "Name for the Shipper Cloud project (will be used as the Convex project name)"
    ),
    reason: z.string().describe(
      "Brief explanation of why deployment is needed (shown to user in confirmation dialog)"
    ),
    confirmed: z.boolean().optional().describe(
      "Set to true ONLY after user has confirmed deployment in the UI. Do NOT set this on first call."
    )
  }),
  execute: async ({ projectName, reason, confirmed }) => {
    const { projectId, userId, logger: logger2 } = context;
    if (!confirmed) {
      logger2?.info({
        msg: "Shipper Cloud deployment requested - awaiting user confirmation",
        projectId,
        projectName,
        reason
      });
      return {
        status: "pending_confirmation",
        message: "Awaiting user confirmation to deploy to Shipper Cloud",
        projectName,
        reason,
        instructions: "The user will see a confirmation dialog. If they approve, tell me to proceed and I will call this tool again with confirmed=true."
      };
    }
    logger2?.info({
      msg: "User confirmed Shipper Cloud deployment - executing",
      projectId,
      projectName,
      reason
    });
    try {
      const result = await executeShipperCloudDeploymentWithFiles(
        projectId,
        userId,
        projectName
      );
      if (!result.success) {
        return {
          status: "error",
          success: false,
          error: result.error || "Failed to provision Shipper Cloud backend"
        };
      }
      return {
        status: "success",
        success: true,
        message: result.isExisting ? "Shipper Cloud deployment already exists. Convex Auth files have been set up." : "Successfully provisioned Shipper Cloud backend with Convex Auth!",
        deploymentUrl: result.deploymentUrl,
        siteUrl: result.siteUrl,
        deploymentName: result.deploymentName,
        isExisting: result.isExisting,
        filesCreated: result.filesCreated,
        packagesInstalled: result.packagesInstalled,
        packagesInstalledList: result.packagesInstalledList,
        envVarsSet: result.envVarsSet,
        authClientPath: result.authClientPath,
        nextSteps: [
          "\u26A0\uFE0F STOP! Your VERY NEXT action MUST be: call deployConvex tool",
          "The convex/_generated/api types DO NOT EXIST yet - you will get import errors if you create components now!",
          "1. IMMEDIATELY call deployConvex tool NOW (before creating ANY files)",
          "2. WAIT for deployConvex to succeed",
          "3. ONLY THEN: Update src/main.tsx to use ConvexAuthProvider (import from @convex-dev/auth/react)",
          "4. ONLY THEN: Create /signin and /signup route files with REAL forms using useAuthActions hook from @convex-dev/auth/react",
          "5. \u26A0\uFE0F NEVER redirect unauth users from __root.tsx! Only redirect in PROTECTED routes",
          "6. Home page (/) should show landing page for unauth users, NOT redirect to signin!",
          "7. Use v.id('users') for userId fields that reference the auth users table"
        ],
        criticalWarning: "\u{1F6AB} DO NOT create ANY React components yet! Call deployConvex FIRST!"
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "Shipper Cloud deployment failed",
        projectId,
        error: errorMessage
      });
      return {
        status: "error",
        success: false,
        error: `Failed to deploy to Shipper Cloud: ${errorMessage}`
      };
    }
  }
});
var AI_PROVIDER_DEFAULTS = {
  openai: {
    defaultModel: "gpt-4.1-mini",
    availableModels: ["gpt-4.1-mini", "gpt-4.1", "gpt-4o", "gpt-4o-mini"]
  },
  anthropic: {
    defaultModel: "claude-3-5-haiku",
    availableModels: ["claude-3-5-haiku", "claude-3-5-sonnet", "claude-3-opus"]
  },
  google: {
    defaultModel: "gemini-2.0-flash-lite",
    availableModels: [
      "gemini-2.0-flash-lite",
      "gemini-2.0-flash",
      "gemini-1.5-pro"
    ]
  },
  xai: {
    defaultModel: "grok-2",
    availableModels: ["grok-2", "grok-beta"]
  },
  mistral: {
    defaultModel: "mistral-large",
    availableModels: ["mistral-large", "mistral-medium"]
  }
};
function generateAiProxyToken() {
  const crypto3 = __require("crypto");
  return `shipper_ai_${crypto3.randomBytes(32).toString("hex")}`;
}
var enableAI = (context) => tool({
  description: `Enable AI capabilities in this project using Shipper AI.

\u{1F680} NO API KEY NEEDED! AI usage is automatically charged to user's Shipper Cloud credits.

The Shipper AI proxy is OpenAI-compatible and supports ALL AI features:
- Chat completions (conversations, assistants)
- Vision (analyze images)
- Embeddings (semantic search, RAG)
- Function calling (AI agents with tools)
- Image generation
- 100+ models via OpenRouter (GPT-4, Claude, Gemini, Grok, Llama, Mistral, etc.)

PREREQUISITES:
- Shipper Cloud must be deployed first (call deployToShipperCloud)

WHAT THIS TOOL DOES:
1. Generates a secure project AI token
2. Sets SHIPPER_AI_TOKEN and SHIPPER_AI_URL in Convex environment

AFTER THIS TOOL SUCCEEDS:
- Create convex/ai.ts with "use node"; at the top
- Create Convex actions that call the Shipper AI proxy using fetch()
- Use SHIPPER_AI_URL env var as base URL
- Use X-Shipper-Token header with SHIPPER_AI_TOKEN
- Call deployConvex to activate the AI actions`,
  inputSchema: z.object({
    provider: z.enum(["openai", "anthropic", "google", "xai", "mistral"]).optional().default("openai").describe("AI provider to use. Defaults to OpenAI (gpt-4.1-mini)."),
    model: z.string().optional().describe(
      "Specific model to use. If not provided, uses the cheap default for the provider."
    )
  }),
  execute: async ({ provider = "openai", model }) => {
    const { projectId, userId, logger: logger2 } = context;
    const providerConfig = AI_PROVIDER_DEFAULTS[provider];
    const selectedModel = model || providerConfig?.defaultModel || "gpt-4.1-mini";
    logger2?.info({
      msg: "Enabling AI capabilities (Shipper AI Proxy)",
      projectId,
      provider,
      model: selectedModel
    });
    try {
      const project = await prisma.project.findUnique({
        where: { id: projectId },
        include: { convexDeployment: true }
      });
      if (!project?.convexDeployment) {
        return {
          success: false,
          action_required: "deploy_shipper_cloud",
          error: "Shipper Cloud is not deployed yet.",
          next_step: "Call deployToShipperCloud tool first, wait for user confirmation, then call enableAI again with the SAME API key.",
          hint: "You already have the user's API key - save it and reuse after deployment completes."
        };
      }
      const sandboxInfo = await getSandbox2(projectId);
      if (!sandboxInfo) {
        return {
          success: false,
          error: "No sandbox found for this project"
        };
      }
      let aiToken = project.aiProxyToken;
      if (!aiToken) {
        aiToken = generateAiProxyToken();
        await prisma.project.update({
          where: { id: projectId },
          data: {
            aiProxyToken: aiToken,
            aiProxyTokenCreatedAt: /* @__PURE__ */ new Date(),
            aiEnabled: true
          }
        });
        logger2?.info({ msg: "Generated new AI proxy token", projectId });
      } else {
        await prisma.project.update({
          where: { id: projectId },
          data: { aiEnabled: true }
        });
      }
      logger2?.info({ msg: "Setting SHIPPER_AI_TOKEN in Convex env" });
      const apiUrl = process.env.API_URL || "https://api.shipper.so";
      await executeCommand(
        sandboxInfo.sandboxId,
        `bunx convex env set SHIPPER_AI_TOKEN "${aiToken}"`,
        { timeoutMs: 3e4 }
      );
      await executeCommand(
        sandboxInfo.sandboxId,
        `bunx convex env set SHIPPER_AI_URL "${apiUrl}/api/v1/ai"`,
        { timeoutMs: 3e4 }
      );
      return {
        success: true,
        provider,
        model: selectedModel,
        aiEnabled: true,
        message: "AI is now enabled! Environment variables SHIPPER_AI_TOKEN and SHIPPER_AI_URL are set.",
        proxyInfo: {
          baseUrl: "SHIPPER_AI_URL environment variable",
          authHeader: "X-Shipper-Token: SHIPPER_AI_TOKEN",
          endpoints: [
            "POST /chat/completions - Chat, vision, function calling",
            "POST /embeddings - Create embeddings for RAG/search",
            "POST /images/generations - Generate images",
            "GET /models - List available models"
          ]
        },
        nextSteps: [
          "Create convex/ai.ts with 'use node'; at the top",
          "Create Convex actions that call the Shipper AI proxy",
          "Use fetch() with SHIPPER_AI_URL and X-Shipper-Token header",
          "Call deployConvex to activate the AI actions"
        ],
        exampleAction: `
"use node";
import { action } from "./_generated/server";
import { v } from "convex/values";

const SHIPPER_AI_URL = process.env.SHIPPER_AI_URL!;
const SHIPPER_TOKEN = process.env.SHIPPER_AI_TOKEN!;

export const chat = action({
  args: {
    messages: v.array(v.object({
      role: v.union(v.literal("system"), v.literal("user"), v.literal("assistant")),
      content: v.string(),
    })),
  },
  handler: async (ctx, { messages }) => {
    const response = await fetch(\`\${SHIPPER_AI_URL}/chat/completions\`, {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "X-Shipper-Token": SHIPPER_TOKEN,
      },
      body: JSON.stringify({
        model: "${selectedModel}",
        messages,
      }),
    });
    
    if (!response.ok) throw new Error(\`AI request failed: \${response.status}\`);
    const data = await response.json();
    return { content: data.choices?.[0]?.message?.content || "" };
  },
});`
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "Failed to enable AI",
        projectId,
        error: errorMessage
      });
      return {
        success: false,
        error: `Failed to enable AI: ${errorMessage}`
      };
    }
  }
});
var requestApiKeys = (context) => tool({
  description: `Request API keys from the user via a secure input card in the chat.

This tool triggers a UI card where users can securely enter their API keys.
The keys are AUTOMATICALLY SAVED to Convex environment variables when the user submits.

\u26A0\uFE0F PREREQUISITE: This tool will FAIL if Shipper Cloud is not deployed!
For stripe/openai/anthropic/google providers, you MUST call deployToShipperCloud first AND WAIT for user confirmation.
\u{1F6AB} NEVER call this tool at the same time as deployToShipperCloud! Wait for deployment to complete first.

SUPPORTED PROVIDERS:
- stripe: Requests Secret Key only (publishable key NOT needed for redirect flow)
- openai: Requests OpenAI API key
- anthropic: Requests Anthropic API key
- google: Requests Google AI API key
- custom: Use custom fields configuration

FLOW:
1. Call this tool with provider, fields, and envVarName
2. A secure input card appears in the chat
3. User enters their key and submits
4. Key is AUTOMATICALLY saved to Convex env var you specified
5. You receive confirmation: { confirmed: true, keys: {...}, keysSetInConvex: true, envVarsSet: ["RESEND_API_KEY"] }
6. Create your Convex action that uses process.env.RESEND_API_KEY (or whatever you specified)

EXAMPLES:
- Email (Resend): 
  requestApiKeys({ 
    provider: "resend", 
    envVarName: "RESEND_API_KEY",
    fields: [{ key: "apiKey", label: "Resend API Key" }],
    helpLink: { url: "https://resend.com/api-keys", text: "Get Resend API Key" }
  })

- Email (SendGrid): 
  requestApiKeys({ 
    provider: "sendgrid", 
    envVarName: "SENDGRID_API_KEY",
    fields: [{ key: "apiKey", label: "SendGrid API Key" }],
    helpLink: { url: "https://app.sendgrid.com/settings/api_keys", text: "Get SendGrid API Key" }
  })


- SMS (Twilio - multiple fields):
  requestApiKeys({ 
    provider: "twilio",
    fields: [
      { key: "accountSid", label: "Account SID", envVarName: "TWILIO_ACCOUNT_SID" },
      { key: "authToken", label: "Auth Token", envVarName: "TWILIO_AUTH_TOKEN" }
    ],
    helpLink: { url: "https://console.twilio.com", text: "Get Twilio Credentials" }
  })

FOR STRIPE - COMPLETE FLOW (FOLLOW THIS ORDER!):
1. deployToShipperCloud \u2192 WAIT for user confirmation
2. requestApiKeys({ provider: "stripe" }) \u2192 get secretKey
3. stripeCreateProductAndPrice({ stripeSecretKey, name, priceInCents, ... }) \u2192 user approves \u2192 get priceId
4. setupStripePayments({ stripeSecretKey, priceId, paymentType }) \u2192 saves key + creates files
5. deployConvex() \u2192 activates Stripe routes
6. Done! <CheckoutButton priceId="..." /> is ready to use.`,
  inputSchema: z.object({
    provider: z.string().describe(
      "The provider/service name (e.g., 'resend', 'stripe', 'openai', 'sendgrid', 'twilio')"
    ),
    envVarName: z.string().optional().describe(
      "The Convex environment variable name to save the key as (e.g., 'RESEND_API_KEY'). Required for single-field providers."
    ),
    title: z.string().optional().describe(
      "Custom title for the input card (defaults to 'Enter API Keys')"
    ),
    fields: z.array(
      z.object({
        key: z.string().describe(
          "Unique identifier for this field (e.g., 'apiKey', 'accountSid')"
        ),
        label: z.string().describe("Label shown in the input (e.g., 'Resend API Key')"),
        pattern: z.string().optional().describe("Regex pattern for validation"),
        errorMessage: z.string().optional().describe("Error message when validation fails"),
        envVarName: z.string().optional().describe(
          "Convex env var name for this specific field (for multi-field providers like Twilio)"
        )
      })
    ).describe(
      "REQUIRED: Array of input fields to display. Always specify at least one field with key and label."
    ),
    helpLink: z.object({
      url: z.string(),
      text: z.string()
    }).optional().describe("Link to help users get their API keys"),
    helpTooltip: z.string().optional().describe("Tooltip text explaining what keys are needed")
  }),
  execute: async ({
    provider,
    envVarName,
    title,
    fields,
    helpLink,
    helpTooltip
  }) => {
    const { projectId, logger: logger2 } = context;
    logger2?.info({
      msg: "Requesting API keys from user",
      provider
    });
    const providersRequiringBackend = [
      "stripe",
      "openai",
      "anthropic",
      "google"
    ];
    let project = null;
    if (providersRequiringBackend.includes(provider)) {
      project = await prisma.project.findUnique({
        where: { id: projectId },
        include: { convexDeployment: true }
      });
      if (!project?.convexDeployment) {
        return {
          success: false,
          action_required: "deploy_shipper_cloud",
          error: `${provider} integration requires Shipper Cloud backend.`,
          next_step: "Call deployToShipperCloud tool first and wait for user confirmation. THEN call requestApiKeys to get the keys."
        };
      }
    }
    let finalHelpLink = helpLink;
    if (provider === "stripe" && !helpLink) {
      if (!project) {
        project = await prisma.project.findUnique({
          where: { id: projectId }
        });
      }
      const appName = encodeURIComponent(project?.name || "MyApp");
      const stripePermissions = [
        "rak_product_write",
        "rak_product_read",
        "rak_price_write",
        "rak_price_read",
        "rak_plan_write",
        // Legacy subscription plans
        "rak_plan_read",
        "rak_payment_link_write",
        "rak_payment_link_read",
        "rak_payment_intent_write",
        "rak_payment_intent_read",
        "rak_customer_write",
        "rak_customer_read",
        "rak_subscription_write",
        "rak_subscription_read",
        "rak_invoice_read",
        "rak_invoice_item_write",
        "rak_invoice_item_read",
        "rak_balance_read",
        "rak_refund_write",
        "rak_refund_read",
        "rak_coupon_write",
        "rak_coupon_read",
        "rak_checkout_session_write",
        "rak_checkout_session_read"
      ];
      const permissionsQuery = stripePermissions.map((p) => `permissions%5B%5D=${p}`).join("&");
      finalHelpLink = {
        url: `https://dashboard.stripe.com/apikeys/create?name=${appName}&${permissionsQuery}`,
        text: "Create Stripe Key (1-click)"
      };
    }
    return {
      status: "pending_api_keys",
      provider,
      envVarName,
      title,
      fields,
      helpLink: finalHelpLink,
      helpTooltip,
      message: `Waiting for user to enter ${provider} API keys...`
    };
  }
});
var setupStripePayments = (context) => tool({
  description: `Setup Stripe payments with code generation. REQUIRES priceId from stripeCreateProductAndPrice HITL tool.

\u26A0\uFE0F PREREQUISITES (IN ORDER):
1. deployToShipperCloud \u2192 wait for confirmation
2. requestApiKeys({ provider: "stripe" }) \u2192 get secret key
3. stripeCreateProductAndPrice({ stripeSecretKey, name, priceInCents, ... }) \u2192 user approves \u2192 get priceId
4. THIS TOOL: setupStripePayments({ stripeSecretKey, priceId, ... }) \u2192 creates files
5. deployConvex() \u2192 REQUIRED to activate routes!

WHAT THIS TOOL DOES:
- Validates priceId format (must start with price_)
- Installs stripe package
- Sets STRIPE_SECRET_KEY in Convex env
- Generates convex/stripe.ts, convex/http.ts, convex/stripeWebhook.ts
- Generates CheckoutButton component and success page

\u26A0\uFE0F This tool does NOT create Stripe products - use stripeCreateProductAndPrice HITL tool first!`,
  inputSchema: z.object({
    stripeSecretKey: z.string().describe("User's Stripe Secret Key (sk_test_* or sk_live_*)"),
    priceId: z.string().describe(
      "The Stripe price ID (format: price_xxx). Get this from stripeCreateProductAndPrice HITL tool."
    ),
    paymentType: z.enum(["one_time", "subscription"]).describe("Type of payment: one_time or subscription"),
    successRoute: z.string().default("/checkout/success").describe("Route to redirect after successful payment"),
    cancelRoute: z.string().default("/").describe("Route to redirect if payment is cancelled")
  }),
  execute: async ({
    stripeSecretKey,
    priceId,
    paymentType,
    successRoute,
    cancelRoute
  }) => {
    const { projectId, logger: logger2 } = context;
    logger2?.info({
      msg: "Setting up Stripe payments",
      projectId,
      paymentType,
      priceId
    });
    try {
      if (!priceId || !priceId.startsWith("price_")) {
        return {
          success: false,
          error: "Invalid priceId. Must start with 'price_'",
          hint: "Call stripeCreateProductAndPrice HITL tool first to create a product and get the priceId"
        };
      }
      const keyValidation = await validateStripeKey(stripeSecretKey);
      if (!keyValidation.valid) {
        return {
          success: false,
          error: keyValidation.error || "Invalid Stripe secret key"
        };
      }
      const project = await prisma.project.findUnique({
        where: { id: projectId },
        include: { convexDeployment: true }
      });
      if (!project?.convexDeployment) {
        return {
          success: false,
          action_required: "deploy_shipper_cloud",
          error: "Shipper Cloud must be deployed first",
          next_step: "Call deployToShipperCloud, wait for confirmation, then call setupStripePayments again"
        };
      }
      const sandboxInfo = await getSandbox2(projectId);
      if (!sandboxInfo) {
        return {
          success: false,
          error: "No sandbox found for this project"
        };
      }
      logger2?.info({ msg: "Installing Stripe package" });
      const installResult = await executeCommand(
        sandboxInfo.sandboxId,
        "bun add stripe",
        { timeoutMs: 6e4 }
      );
      if (installResult.exitCode !== 0) {
        logger2?.warn({
          msg: "Package installation had issues",
          stderr: installResult.stderr
        });
      }
      logger2?.info({ msg: "Setting Stripe environment variables" });
      let secretKeySet = false;
      try {
        const deployKey = decryptDeployKey(
          project.convexDeployment.deployKeyEncrypted
        );
        const deploymentApi = new ConvexDeploymentAPI(
          project.convexDeployment.convexDeploymentUrl,
          deployKey
        );
        const envResult = await deploymentApi.setEnvironmentVariables({
          STRIPE_SECRET_KEY: stripeSecretKey
        });
        secretKeySet = envResult.success;
        if (envResult.success) {
          logger2?.info({ msg: "STRIPE_SECRET_KEY set via Convex API" });
        } else {
          logger2?.warn({
            msg: "Failed to set STRIPE_SECRET_KEY via Convex API",
            error: envResult.error
          });
        }
      } catch (envError) {
        logger2?.warn({
          msg: "Failed to set STRIPE_SECRET_KEY via Convex API",
          error: envError instanceof Error ? envError.message : String(envError)
        });
      }
      if (!secretKeySet) {
        logger2?.error({
          msg: "STRIPE_SECRET_KEY was NOT set - Stripe actions will fail!",
          projectId
        });
        return {
          success: false,
          error: "Failed to set STRIPE_SECRET_KEY environment variable. Please try again."
        };
      }
      await executeCommand(
        sandboxInfo.sandboxId,
        "mkdir -p convex src/components src/routes/checkout"
      );
      logger2?.info({ msg: "Generating Stripe action code" });
      const stripeMode = paymentType === "subscription" ? "subscription" : "payment";
      const stripeActionCode = generateStripeActionCode({
        featureType: "checkout_session",
        mode: stripeMode
      });
      await writeFile(
        sandboxInfo.sandboxId,
        "convex/stripe.ts",
        stripeActionCode
      );
      if (context.fragmentFiles) {
        context.fragmentFiles.set("convex/stripe.ts", stripeActionCode);
      }
      logger2?.info({ msg: "Generating Stripe HTTP routes" });
      const stripeHttpCode = generateStripeHttpCode({
        mode: stripeMode,
        successUrl: successRoute,
        // Will be relative path like /checkout/success
        cancelUrl: cancelRoute || "/"
      });
      await writeFile(
        sandboxInfo.sandboxId,
        "convex/http.ts",
        stripeHttpCode
      );
      if (context.fragmentFiles) {
        context.fragmentFiles.set("convex/http.ts", stripeHttpCode);
      }
      logger2?.info({ msg: "Generating webhook mutation handlers" });
      const webhookMutationsCode = generateStripeWebhookMutations();
      await writeFile(
        sandboxInfo.sandboxId,
        "convex/stripeWebhook.ts",
        webhookMutationsCode
      );
      if (context.fragmentFiles) {
        context.fragmentFiles.set(
          "convex/stripeWebhook.ts",
          webhookMutationsCode
        );
      }
      logger2?.info({ msg: "Generating checkout button component" });
      const checkoutButtonCode = generateCheckoutUICode();
      await writeFile(
        sandboxInfo.sandboxId,
        "src/components/CheckoutButton.tsx",
        checkoutButtonCode
      );
      if (context.fragmentFiles) {
        context.fragmentFiles.set(
          "src/components/CheckoutButton.tsx",
          checkoutButtonCode
        );
      }
      logger2?.info({ msg: "Generating success page" });
      const successCode = generateSuccessUICode({
        returnRoute: cancelRoute || "/"
      });
      await writeFile(
        sandboxInfo.sandboxId,
        "src/routes/checkout/success.tsx",
        successCode
      );
      await new Promise((resolve) => setTimeout(resolve, 300));
      try {
        const verifyResult = await executeCommand(
          sandboxInfo.sandboxId,
          "cat src/routes/checkout/success.tsx",
          { timeoutMs: 5e3 }
        );
        const verifyContent = verifyResult.stdout || "";
        const isCorrupted = verifyContent.includes('return <div>Hello "') || verifyContent.includes("return <div>Hello '/") || verifyContent.includes('Hello "/') && verifyContent.length < successCode.length * 0.5;
        if (isCorrupted) {
          logger2?.warn({
            msg: "\u{1F504} Route file corrupted by TanStack Router plugin, re-writing",
            path: "src/routes/checkout/success.tsx"
          });
          await writeFile(
            sandboxInfo.sandboxId,
            "src/routes/checkout/success.tsx",
            successCode
          );
          await new Promise((resolve) => setTimeout(resolve, 300));
        }
      } catch (verifyError) {
        logger2?.warn({
          msg: "Could not verify route file",
          error: verifyError instanceof Error ? verifyError.message : String(verifyError)
        });
      }
      if (context.fragmentFiles) {
        context.fragmentFiles.set(
          "src/routes/checkout/success.tsx",
          successCode
        );
      }
      const isTestMode = stripeSecretKey.startsWith("sk_test_");
      return {
        success: true,
        paymentType,
        priceId,
        mode: isTestMode ? "test" : "live",
        filesCreated: [
          "convex/stripe.ts",
          "convex/http.ts",
          "convex/stripeWebhook.ts",
          "src/components/CheckoutButton.tsx",
          "src/routes/checkout/success.tsx"
        ],
        envVarsSet: ["STRIPE_SECRET_KEY (Convex env)"],
        important: "\u26A0\uFE0F You MUST call deployConvex now to activate the Stripe routes!",
        checkoutButtonUsage: `import { CheckoutButton } from "./components/CheckoutButton";

<CheckoutButton priceId="${priceId}" label="${paymentType === "subscription" ? "Subscribe Now" : "Buy Now"}" />`,
        webhookInfo: {
          url: "Add to Stripe Dashboard -> Developers -> Webhooks",
          endpoint: "/stripe/webhook (on your Convex site URL)",
          events: [
            "checkout.session.completed",
            "customer.subscription.created",
            "customer.subscription.updated",
            "customer.subscription.deleted"
          ],
          note: "Webhooks are optional but recommended for tracking payments"
        },
        schemaNote: generatePaymentsTableSnippet(),
        nextSteps: [
          "\u26A0\uFE0F CALL deployConvex NOW to activate Stripe routes!",
          `Then use <CheckoutButton priceId="${priceId}" /> in your pricing page`,
          "Button opens Stripe Checkout in a new tab",
          "After payment, user is redirected to /checkout/success",
          isTestMode ? "Test with card: 4242 4242 4242 4242" : "\u26A0\uFE0F LIVE MODE - real charges!"
        ],
        testCard: isTestMode ? {
          number: "4242 4242 4242 4242",
          expiry: "Any future date",
          cvc: "Any 3 digits"
        } : null
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "Failed to setup Stripe payments",
        projectId,
        error: errorMessage
      });
      return {
        success: false,
        error: `Failed to setup Stripe: ${errorMessage}`
      };
    }
  }
});
var runConvexQuery = (context) => tool({
  description: `Execute a Convex query to READ data from the database.

Use this tool to fetch data from the Convex backend. Queries are read-only.

WHEN TO USE:
- Fetch all records from a table (e.g., api.queries.getAllTasks)
- Get a specific record by ID (e.g., api.queries.getTask with args: {id: "..."})
- Search or filter data (e.g., api.queries.searchTasks with args: {query: "..."})

ARGUMENTS FORMAT:
- functionPath: The path to the query function (e.g., "queries:getAllTasks" or "queries:getTask")
- args: Optional object with arguments to pass to the query

EXAMPLES:
- Get all tasks: functionPath="queries:getAllTasks", args={}
- Get task by ID: functionPath="queries:getTask", args={id: "abc123"}
- List by user: functionPath="queries:getByUser", args={userId: "user123"}

NOTE: The function path format is "filename:functionName" where filename is relative to convex/ folder.`,
  inputSchema: z.object({
    functionPath: z.string().describe(
      "Path to the Convex query function (e.g., 'queries:getAllTasks' or 'tasks:list')"
    ),
    args: z.record(z.string(), z.unknown()).optional().default({}).describe("Arguments to pass to the query function as a JSON object")
  }),
  execute: async ({ functionPath, args }) => {
    const { projectId, logger: logger2 } = context;
    logger2?.info({
      msg: "Executing Convex query",
      projectId,
      functionPath,
      args
    });
    try {
      const deployment = await prisma.convexDeployment.findUnique({
        where: { projectId },
        select: {
          convexDeploymentUrl: true,
          deployKeyEncrypted: true,
          status: true
        }
      });
      if (!deployment) {
        return {
          success: false,
          error: "No Convex deployment found for this project. Call deployToShipperCloud first to provision a backend."
        };
      }
      if (deployment.status !== "ACTIVE") {
        return {
          success: false,
          error: `Convex deployment is not active (status: ${deployment.status})`
        };
      }
      const deployKey = decryptDeployKey(deployment.deployKeyEncrypted);
      const response = await fetch(
        `${deployment.convexDeploymentUrl}/api/query`,
        {
          method: "POST",
          headers: {
            Authorization: `Convex ${deployKey}`,
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            path: functionPath,
            args: args || {},
            format: "json"
          })
        }
      );
      if (!response.ok) {
        const errorText = await response.text();
        logger2?.error({
          msg: "Convex query failed",
          projectId,
          functionPath,
          status: response.status,
          error: errorText
        });
        return {
          success: false,
          error: `Query failed (${response.status}): ${errorText}`
        };
      }
      const result = await response.json();
      logger2?.info({
        msg: "Convex query succeeded",
        projectId,
        functionPath,
        resultType: typeof result,
        isArray: Array.isArray(result.value),
        resultCount: Array.isArray(result.value) ? result.value.length : void 0
      });
      return {
        success: true,
        data: result.value ?? result,
        functionPath
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "Convex query error",
        projectId,
        functionPath,
        error: errorMessage
      });
      return {
        success: false,
        error: `Failed to execute query: ${errorMessage}`
      };
    }
  }
});
var runConvexMutation = (context) => tool({
  description: `Execute a Convex mutation to CREATE, UPDATE, or DELETE data.

Use this tool to modify data in the Convex backend. Mutations can insert, update, or delete records.

WHEN TO USE:
- Create a new record (e.g., api.mutations.createTask with args: {title: "..."})
- Update an existing record (e.g., api.mutations.updateTask with args: {id: "...", title: "..."})
- Delete a record (e.g., api.mutations.deleteTask with args: {id: "..."})
- Perform any write operation on the database

ARGUMENTS FORMAT:
- functionPath: The path to the mutation function (e.g., "mutations:createTask")
- args: Object with arguments to pass to the mutation

EXAMPLES:
- Create task: functionPath="mutations:createTask", args={title: "Buy groceries", completed: false}
- Update task: functionPath="mutations:updateTask", args={id: "abc123", completed: true}
- Delete task: functionPath="mutations:deleteTask", args={id: "abc123"}

NOTE: The function path format is "filename:functionName" where filename is relative to convex/ folder.

\u26A0\uFE0F WARNING: Mutations modify data permanently. Make sure you understand what the mutation does before executing.`,
  inputSchema: z.object({
    functionPath: z.string().describe(
      "Path to the Convex mutation function (e.g., 'mutations:createTask' or 'tasks:create')"
    ),
    args: z.record(z.string(), z.unknown()).describe(
      "Arguments to pass to the mutation function as a JSON object"
    )
  }),
  execute: async ({ functionPath, args }) => {
    const { projectId, logger: logger2 } = context;
    logger2?.info({
      msg: "Executing Convex mutation",
      projectId,
      functionPath,
      args
    });
    try {
      const deployment = await prisma.convexDeployment.findUnique({
        where: { projectId },
        select: {
          convexDeploymentUrl: true,
          deployKeyEncrypted: true,
          status: true
        }
      });
      if (!deployment) {
        return {
          success: false,
          error: "No Convex deployment found for this project. Call deployToShipperCloud first to provision a backend."
        };
      }
      if (deployment.status !== "ACTIVE") {
        return {
          success: false,
          error: `Convex deployment is not active (status: ${deployment.status})`
        };
      }
      const deployKey = decryptDeployKey(deployment.deployKeyEncrypted);
      const response = await fetch(
        `${deployment.convexDeploymentUrl}/api/mutation`,
        {
          method: "POST",
          headers: {
            Authorization: `Convex ${deployKey}`,
            "Content-Type": "application/json"
          },
          body: JSON.stringify({
            path: functionPath,
            args: args || {},
            format: "json"
          })
        }
      );
      if (!response.ok) {
        const errorText = await response.text();
        logger2?.error({
          msg: "Convex mutation failed",
          projectId,
          functionPath,
          status: response.status,
          error: errorText
        });
        return {
          success: false,
          error: `Mutation failed (${response.status}): ${errorText}`
        };
      }
      const result = await response.json();
      logger2?.info({
        msg: "Convex mutation succeeded",
        projectId,
        functionPath,
        result
      });
      return {
        success: true,
        data: result.value ?? result,
        functionPath,
        message: `Successfully executed mutation: ${functionPath}`
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "Convex mutation error",
        projectId,
        functionPath,
        error: errorMessage
      });
      return {
        success: false,
        error: `Failed to execute mutation: ${errorMessage}`
      };
    }
  }
});
var listConvexFunctions = (context) => tool({
  description: `List all available Convex functions (queries, mutations, actions) in the project.

Use this tool to discover what Convex functions are available before calling runConvexQuery or runConvexMutation.

This helps you understand:
- What queries are available to read data
- What mutations are available to modify data
- What arguments each function expects

WHEN TO USE:
- Before calling runConvexQuery or runConvexMutation for the first time
- When you need to find the correct function path
- To understand the schema and available operations`,
  inputSchema: z.object({}),
  execute: async () => {
    const { projectId, logger: logger2, sandboxId } = context;
    logger2?.info({
      msg: "Listing Convex functions",
      projectId
    });
    try {
      const deployment = await prisma.convexDeployment.findUnique({
        where: { projectId },
        select: {
          convexDeploymentUrl: true,
          status: true
        }
      });
      if (!deployment) {
        return {
          success: false,
          error: "No Convex deployment found for this project. Call deployToShipperCloud first to provision a backend."
        };
      }
      if (!sandboxId) {
        return {
          success: false,
          error: "Sandbox not available. Cannot read Convex function definitions."
        };
      }
      const convexFiles = [];
      const filesToCheck = [
        "convex/queries.ts",
        "convex/mutations.ts",
        "convex/actions.ts",
        "convex/tasks.ts",
        "convex/users.ts",
        "convex/schema.ts"
      ];
      for (const filePath of filesToCheck) {
        try {
          const content = await readFile(sandboxId, filePath);
          if (content) {
            const exportMatches = content.match(/export\s+const\s+(\w+)\s*=/g) || [];
            const functions = exportMatches.map((match) => {
              const nameMatch = match.match(/export\s+const\s+(\w+)/);
              return nameMatch ? nameMatch[1] : "";
            }).filter(Boolean);
            convexFiles.push({
              path: filePath,
              content: content.substring(0, 500) + (content.length > 500 ? "..." : ""),
              functions
            });
          }
        } catch {
        }
      }
      if (convexFiles.length === 0) {
        return {
          success: false,
          error: "No Convex function files found. Make sure convex/ directory exists with queries.ts, mutations.ts, etc."
        };
      }
      const functionList = convexFiles.map((file) => {
        const fileName = file.path.replace("convex/", "").replace(".ts", "");
        return {
          file: file.path,
          functions: file.functions.map((fn) => `${fileName}:${fn}`)
        };
      });
      logger2?.info({
        msg: "Listed Convex functions",
        projectId,
        fileCount: convexFiles.length,
        totalFunctions: functionList.reduce(
          (acc, f) => acc + f.functions.length,
          0
        )
      });
      return {
        success: true,
        deploymentUrl: deployment.convexDeploymentUrl,
        files: functionList,
        usage: {
          queryExample: "runConvexQuery with functionPath='queries:getAllTasks'",
          mutationExample: "runConvexMutation with functionPath='mutations:createTask', args={...}"
        }
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "Error listing Convex functions",
        projectId,
        error: errorMessage
      });
      return {
        success: false,
        error: `Failed to list Convex functions: ${errorMessage}`
      };
    }
  }
});
var deployConvex = (context) => tool({
  description: `Deploy Convex schema and functions to the Shipper Cloud PRODUCTION backend.

\u26A0\uFE0F\u26A0\uFE0F\u26A0\uFE0F CRITICAL ORDER: Call scaffoldConvexSchema BEFORE this tool! \u26A0\uFE0F\u26A0\uFE0F\u26A0\uFE0F

CORRECT ORDER:
1. deployToShipperCloud - provisions backend
2. scaffoldConvexSchema - generates schema.ts, queries.ts, mutations.ts
3. deployConvex (THIS TOOL) - deploys and generates types
4. Create React components

\u{1F6AB} DO NOT call this tool immediately after deployToShipperCloud!
\u{1F6AB} DO NOT call this tool before scaffoldConvexSchema!

This runs \`bunx convex deploy --yes\` which:
- Clears Convex cache to fix bundling issues
- Validates your schema and functions
- Deploys them to the PRODUCTION Convex backend
- Generates TypeScript types in convex/_generated/

\u26A0\uFE0F SCHEMA CONSTRAINTS - To avoid "NoImportModuleInSchema" errors:
- schema.ts can ONLY import from "convex/server" and "convex/values"
- schema.ts CANNOT import from auth.ts, queries.ts, or any other convex file
- If you get this error, check schema.ts imports

WHEN TO CALL:
- AFTER scaffoldConvexSchema has created the convex files
- After manually modifying schema.ts, queries.ts, or mutations.ts
- After adding new queries or mutations`,
  inputSchema: z.object({
    reason: z.string().optional().describe("Brief description of what changes are being deployed")
  }),
  execute: async ({ reason }) => {
    const { projectId, logger: logger2 } = context;
    logger2?.info({
      msg: "Deploying Convex schema",
      projectId,
      reason
    });
    try {
      const sandbox = await getSandbox(projectId);
      if (!sandbox) {
        return {
          success: false,
          error: "No active sandbox found. Please ensure the project has a running sandbox."
        };
      }
      logger2?.info({
        msg: "Clearing Convex cache before deploy",
        projectId
      });
      await executeCommand(
        sandbox.sandboxId,
        "rm -rf .convex node_modules/.convex convex/_generated"
      );
      const result = await executeCommand(
        sandbox.sandboxId,
        "bunx convex deploy --yes",
        { timeoutMs: 12e4 }
      );
      const output = [result.stdout, result.stderr].filter(Boolean).join("\n");
      if (result.exitCode !== 0) {
        logger2?.error({
          msg: "Convex deploy failed",
          projectId,
          exitCode: result.exitCode,
          stdout: result.stdout,
          stderr: result.stderr
        });
        return {
          success: false,
          error: result.stderr || result.stdout || `Convex deploy failed with exit code ${result.exitCode}`,
          exitCode: result.exitCode,
          output
        };
      }
      logger2?.info({
        msg: "Convex deploy succeeded",
        projectId
      });
      try {
        logger2?.info({
          msg: "Killing vite and clearing cache after convex deploy",
          projectId
        });
        await executeCommand(
          sandbox.sandboxId,
          "pkill -9 -f vite || true"
        );
        await executeCommand(
          sandbox.sandboxId,
          "rm -rf node_modules/.vite node_modules/.tmp"
        );
        await new Promise((resolve) => setTimeout(resolve, 1e3));
        logger2?.info({
          msg: "Restarting dev server after convex deploy",
          projectId
        });
        await startDevServer(sandbox.sandboxId, projectId, 5173);
      } catch (restartError) {
        logger2?.warn({
          msg: "Failed to restart dev server after convex deploy",
          projectId,
          error: restartError instanceof Error ? restartError.message : String(restartError)
        });
      }
      try {
        const envResult = await executeCommand(
          sandbox.sandboxId,
          "grep VITE_CONVEX_URL .env.local | head -1"
        );
        if (envResult.stdout) {
          const match = envResult.stdout.match(/VITE_CONVEX_URL=(.+)/);
          if (match && match[1]) {
            const cloudUrl = match[1].trim();
            const siteUrl = cloudUrl.replace(".convex.cloud", ".convex.site");
            const envVarsToAdd = [];
            const siteUrlCheck = await executeCommand(
              sandbox.sandboxId,
              "grep -q VITE_CONVEX_SITE_URL .env.local && echo 'exists' || echo 'missing'"
            );
            if (siteUrlCheck.stdout?.trim() === "missing") {
              envVarsToAdd.push(`VITE_CONVEX_SITE_URL=${siteUrl}`);
            }
            const localSiteUrlCheck = await executeCommand(
              sandbox.sandboxId,
              "grep -q '^SITE_URL=' .env.local && echo 'exists' || echo 'missing'"
            );
            if (localSiteUrlCheck.stdout?.trim() === "missing") {
              envVarsToAdd.push("SITE_URL=http://localhost:5173");
            }
            if (envVarsToAdd.length > 0) {
              await executeCommand(
                sandbox.sandboxId,
                `echo "${envVarsToAdd.join("\n")}" >> .env.local`
              );
              logger2?.info({
                msg: "Added env vars to .env.local",
                projectId,
                added: envVarsToAdd
              });
            }
          }
        }
      } catch (envError) {
        logger2?.warn({
          msg: "Failed to add env vars to .env.local",
          projectId,
          error: envError instanceof Error ? envError.message : String(envError)
        });
      }
      return {
        success: true,
        message: "Successfully synced Convex schema and functions!",
        output,
        nextSteps: [
          "TypeScript types have been generated in convex/_generated/",
          "Import { api } from 'convex/_generated/api' in your components",
          "Use useQuery(api.queries.yourQuery) and useMutation(api.mutations.yourMutation)"
        ]
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "Convex deploy error",
        projectId,
        error: errorMessage
      });
      return {
        success: false,
        error: `Failed to deploy Convex: ${errorMessage}`
      };
    }
  }
});
var stripeListProducts = (context) => tool({
  description: `Request to list existing products in the user's Stripe account (HITL approval required).

\u{1F6D1} STOP! After calling this tool, you MUST WAIT for the user to click "Allow" before doing anything else!
Do NOT call executeStripeListProducts until you receive { confirmed: true, ... } from the user.

FLOW:
1. Call this tool \u2192 user sees approval card \u2192 \u{1F6D1} STOP AND WAIT!
2. User clicks "Allow" \u2192 you receive { confirmed: true, stripeSecretKey, limit } in the NEXT message
3. ONLY THEN call executeStripeListProducts with stripeSecretKey from step 2`,
  inputSchema: z.object({
    stripeSecretKey: z.string().describe("The user's Stripe Secret Key (from requestApiKeys)"),
    limit: z.number().optional().default(10).describe("Maximum number of products to list (default 10)")
  }),
  execute: async ({ stripeSecretKey, limit }) => {
    const { projectId, logger: logger2 } = context;
    logger2?.info({
      msg: "Stripe HITL: List products requested",
      projectId
    });
    return {
      status: "pending_approval",
      toolName: "stripeListProducts",
      action: "List Stripe Products",
      description: `View up to ${limit} products in your Stripe account`,
      stripeSecretKey,
      // Pass through for execution after approval
      limit
    };
  }
});
var stripeListPrices = (context) => tool({
  description: `Request to list prices for a specific product in the user's Stripe account (HITL approval required).

This is a HITL tool - user must approve before the operation can proceed.

FLOW:
1. Call this tool \u2192 user sees approval card
2. User clicks "Allow" \u2192 you receive { confirmed: true, stripeSecretKey, productId, limit }
3. Call executeStripeListPrices with the same args \u2192 get actual price list

Use this to find existing prices before creating new ones.`,
  inputSchema: z.object({
    stripeSecretKey: z.string().describe("The user's Stripe Secret Key"),
    productId: z.string().describe("The Stripe product ID (prod_xxx)"),
    limit: z.number().optional().default(10).describe("Maximum number of prices to list")
  }),
  execute: async ({ stripeSecretKey, productId, limit }) => {
    const { projectId, logger: logger2 } = context;
    logger2?.info({
      msg: "Stripe HITL: List prices requested",
      projectId,
      productId
    });
    return {
      status: "pending_approval",
      toolName: "stripeListPrices",
      action: "List Stripe Prices",
      description: `View prices for product ${productId}`,
      stripeSecretKey,
      productId,
      limit
    };
  }
});
var stripeCreateProductAndPrice = (context) => tool({
  description: `Request to create a new product and price in the user's Stripe account (HITL approval required).

\u{1F6D1} STOP! After calling this tool, you MUST WAIT for the user to click "Allow" before doing anything else!
Do NOT call executeStripeCreateProductAndPrice until you receive { confirmed: true, ... } from the user.

\u26A0\uFE0F PREREQUISITES:
1. deployToShipperCloud must be confirmed
2. requestApiKeys({ provider: "stripe" }) must be called first to get stripeSecretKey

FLOW:
1. Call this tool \u2192 user sees approval card \u2192 \u{1F6D1} STOP AND WAIT!
2. User clicks "Allow" \u2192 you receive { confirmed: true, stripeSecretKey, ... } in the NEXT message
3. ONLY THEN call executeStripeCreateProductAndPrice with stripeSecretKey from step 2`,
  inputSchema: z.object({
    stripeSecretKey: z.string().describe("The user's Stripe Secret Key"),
    name: z.string().describe("Product name (e.g., 'Pro Plan', 'Premium Access')"),
    description: z.string().optional().describe("Product description"),
    priceInCents: z.number().describe("Price in cents (e.g., 2900 for $29.00)"),
    currency: z.string().optional().default("usd").describe("Currency code (default: usd)"),
    isSubscription: z.boolean().optional().default(false).describe("Whether this is a recurring subscription"),
    billingInterval: z.enum(["month", "year", "week", "day"]).optional().describe("Billing interval for subscriptions")
  }),
  execute: async ({
    stripeSecretKey,
    name,
    description,
    priceInCents,
    currency,
    isSubscription,
    billingInterval
  }) => {
    const { projectId, logger: logger2 } = context;
    const priceDisplay = `${(priceInCents / 100).toFixed(2)} ${currency.toUpperCase()}`;
    logger2?.info({
      msg: "Stripe HITL: Create product and price requested",
      projectId,
      name,
      priceDisplay,
      isSubscription
    });
    return {
      status: "pending_approval",
      toolName: "stripeCreateProductAndPrice",
      action: "Create Stripe Product And Price",
      details: {
        name,
        description: description || "No description",
        price: priceDisplay,
        type: isSubscription ? `Subscription (${billingInterval || "month"})` : "One-time payment"
      },
      // Pass through for execution after approval
      stripeSecretKey,
      name,
      description,
      priceInCents,
      currency,
      isSubscription,
      billingInterval
    };
  }
});
var executeStripeListProducts = (context) => tool({
  description: `Execute the Stripe list products operation after user approval.

\u26A0\uFE0F ONLY call this after stripeListProducts returns { confirmed: true, ... }
You must pass the stripeSecretKey from the requestApiKeys result.`,
  inputSchema: z.object({
    stripeSecretKey: z.string().describe("The Stripe Secret Key from requestApiKeys result"),
    limit: z.number().optional().default(10).describe("Maximum number of products to list")
  }),
  execute: async ({ stripeSecretKey, limit }) => {
    const { logger: logger2 } = context;
    try {
      if (!stripeSecretKey) {
        return {
          success: false,
          error: "stripeSecretKey is required. Use the key from the requestApiKeys result."
        };
      }
      const Stripe = (await import("stripe")).default;
      const stripe = new Stripe(stripeSecretKey);
      const result = await stripe.products.list({
        limit: limit || 10,
        active: true
      });
      logger2?.info({
        msg: "Stripe list products executed",
        count: result.data.length
      });
      return {
        success: true,
        action: "List Products",
        products: result.data.map((p) => ({
          id: p.id,
          name: p.name,
          description: p.description,
          active: p.active
        }))
      };
    } catch (error) {
      logger2?.error({
        msg: "Stripe list products failed",
        error: error instanceof Error ? error.message : String(error)
      });
      return {
        success: false,
        error: error instanceof Error ? error.message : String(error)
      };
    }
  }
});
var executeStripeListPrices = (context) => tool({
  description: `Execute the Stripe list prices operation after user approval.

\u26A0\uFE0F ONLY call this after stripeListPrices returns { confirmed: true, ... }
You must pass the stripeSecretKey from the requestApiKeys result.`,
  inputSchema: z.object({
    stripeSecretKey: z.string().describe("The Stripe Secret Key from requestApiKeys result"),
    productId: z.string().optional().describe("Optional product ID to filter prices"),
    limit: z.number().optional().default(10).describe("Maximum number of prices to list")
  }),
  execute: async ({ stripeSecretKey, productId, limit }) => {
    const { logger: logger2 } = context;
    try {
      if (!stripeSecretKey) {
        return {
          success: false,
          error: "stripeSecretKey is required. Use the key from the requestApiKeys result."
        };
      }
      const Stripe = (await import("stripe")).default;
      const stripe = new Stripe(stripeSecretKey);
      const listParams = {
        limit: limit || 10,
        active: true
      };
      if (productId) {
        listParams.product = productId;
      }
      const result = await stripe.prices.list(listParams);
      logger2?.info({
        msg: "Stripe list prices executed",
        count: result.data.length
      });
      return {
        success: true,
        action: "List Prices",
        prices: result.data.map((p) => ({
          id: p.id,
          product: p.product,
          unit_amount: p.unit_amount,
          currency: p.currency,
          recurring: p.recurring
        }))
      };
    } catch (error) {
      logger2?.error({
        msg: "Stripe list prices failed",
        error: error instanceof Error ? error.message : String(error)
      });
      return {
        success: false,
        error: error instanceof Error ? error.message : String(error)
      };
    }
  }
});
var executeStripeCreateProductAndPrice = (context) => tool({
  description: `Execute the Stripe create product and price operation after user approval.

\u{1F6D1} NEVER call this immediately after stripeCreateProductAndPrice!
You must WAIT for the user to click "Allow" first.

\u26A0\uFE0F ONLY call this when you receive { confirmed: true, stripeSecretKey, ... } from the user's approval.
The approval result contains the stripeSecretKey - extract it and pass it here.

After this succeeds, use the returned priceId in setupStripePayments.`,
  inputSchema: z.object({
    stripeSecretKey: z.string().describe("The Stripe Secret Key from requestApiKeys result"),
    name: z.string().describe("Product name"),
    description: z.string().optional().describe("Product description"),
    priceInCents: z.number().describe("Price in cents"),
    currency: z.string().optional().default("usd").describe("Currency code"),
    isSubscription: z.boolean().optional().default(false).describe("Whether this is a subscription"),
    billingInterval: z.enum(["month", "year", "week", "day"]).optional().describe("Billing interval for subscriptions")
  }),
  execute: async ({
    stripeSecretKey,
    name,
    description,
    priceInCents,
    currency,
    isSubscription,
    billingInterval
  }) => {
    const { logger: logger2 } = context;
    try {
      logger2?.info({
        msg: "executeStripeCreateProductAndPrice called",
        keyReceived: stripeSecretKey ? `${stripeSecretKey.substring(0, 12)}...${stripeSecretKey.substring(stripeSecretKey.length - 4)}` : "NO_KEY",
        keyLength: stripeSecretKey?.length || 0
      });
      if (!stripeSecretKey) {
        return {
          success: false,
          error: "stripeSecretKey is required. Use the key from the requestApiKeys result."
        };
      }
      const Stripe = (await import("stripe")).default;
      const stripe = new Stripe(stripeSecretKey);
      logger2?.info({ msg: "Creating Stripe product", name });
      const product = await stripe.products.create({
        name,
        description: description || void 0
      });
      logger2?.info({
        msg: "Creating Stripe price",
        productId: product.id,
        priceInCents
      });
      const priceParams = {
        product: product.id,
        unit_amount: priceInCents,
        currency: currency || "usd"
      };
      if (isSubscription && billingInterval) {
        priceParams.recurring = { interval: billingInterval };
      }
      const price = await stripe.prices.create(priceParams);
      logger2?.info({
        msg: "Stripe product and price created",
        productId: product.id,
        priceId: price.id
      });
      const priceDisplay = `${(priceInCents / 100).toFixed(2)} ${(currency || "usd").toUpperCase()}`;
      return {
        success: true,
        action: "Create Stripe Product And Price",
        productId: product.id,
        priceId: price.id,
        name,
        price: priceDisplay,
        message: `Created product "${name}" with price ${price.id}. Use this priceId when calling setupStripePayments.`
      };
    } catch (error) {
      logger2?.error({
        msg: "Stripe create product and price failed",
        error: error instanceof Error ? error.message : String(error)
      });
      return {
        success: false,
        error: error instanceof Error ? error.message : String(error)
      };
    }
  }
});
var scaffoldConvexSchema = (context) => tool({
  description: `Generate Convex schema, queries, and mutations from table definitions.

\u26A0\uFE0F\u26A0\uFE0F\u26A0\uFE0F CALL THIS IMMEDIATELY AFTER deployToShipperCloud! \u26A0\uFE0F\u26A0\uFE0F\u26A0\uFE0F

CORRECT ORDER:
1. deployToShipperCloud - provisions backend \u2713
2. scaffoldConvexSchema (THIS TOOL) - generates schema, queries, mutations
3. deployConvex - deploys and generates types
4. Create React components

This tool scaffolds complete Convex boilerplate code based on your table definitions.
It generates:
1. convex/schema.ts - Table definitions with proper types and indexes
2. convex/queries.ts - List and get queries for each table
3. convex/mutations.ts - Create, update, and delete mutations for each table

The generated code follows best practices:
- Uses Doc<"tableName"> types for type safety
- Includes proper indexes for common query patterns
- Implements user-scoped queries/mutations with getAuthUserId
- Handles authentication checks correctly (returns null in queries, throws in mutations)

\u{1F6AB} DO NOT call deployConvex before this tool!
\u2705 After this tool succeeds, call deployConvex to sync with backend.`,
  inputSchema: z.object({
    tables: z.array(
      z.object({
        name: z.string().describe(
          "Table name in camelCase (e.g., 'todos', 'products', 'messages')"
        ),
        fields: z.array(
          z.object({
            name: z.string().describe("Field name"),
            type: z.enum([
              "string",
              "number",
              "boolean",
              "id",
              "array",
              "optional_string",
              "optional_number",
              "optional_boolean"
            ]).describe("Field type"),
            refTable: z.string().optional().describe(
              "For 'id' type: the table being referenced (e.g., 'users', 'products')"
            ),
            arrayType: z.enum(["string", "number", "id"]).optional().describe("For 'array' type: the type of array elements"),
            arrayRefTable: z.string().optional().describe("For array of ids: the table being referenced")
          })
        ).describe(
          "Fields for the table (excluding _id and _creationTime)"
        ),
        userScoped: z.boolean().default(true).describe(
          "If true, adds userId field and scopes queries/mutations to authenticated user"
        ),
        indexes: z.array(z.string()).optional().describe(
          "Additional fields to create indexes on (e.g., ['category', 'status'])"
        )
      })
    ).describe("Array of table definitions to scaffold")
  }),
  execute: async ({ tables }) => {
    const { projectId, sandboxId, logger: logger2 } = context;
    logger2?.info({
      msg: "scaffoldConvexSchema called",
      projectId,
      tableCount: tables.length,
      tableNames: tables.map((t) => t.name)
    });
    try {
      if (!sandboxId) {
        throw new Error("Sandbox not found");
      }
      const sandboxInfo = await getSandbox2(projectId);
      if (!sandboxInfo) {
        throw new Error("Sandbox not available");
      }
      const schemaContent = generateSchemaFile(tables);
      const queriesContent = generateQueriesFile(tables);
      const mutationsContent = generateMutationsFile(tables);
      const filesToWrite = [
        { path: "convex/schema.ts", content: schemaContent },
        { path: "convex/queries.ts", content: queriesContent },
        { path: "convex/mutations.ts", content: mutationsContent }
      ];
      const results = [];
      for (const file of filesToWrite) {
        try {
          await writeFileToSandbox(sandboxInfo, file.path, file.content);
          results.push(`\u2713 Created ${file.path}`);
          if (context.fragmentFiles) {
            context.fragmentFiles.set(file.path, file.content);
          }
          if (context.files) {
            context.files.set(file.path, {
              size: file.content.length,
              modified: Date.now()
            });
          }
        } catch (err) {
          const errMsg = err instanceof Error ? err.message : String(err);
          results.push(`\u2717 Failed to create ${file.path}: ${errMsg}`);
        }
      }
      const generatedFunctions = tables.map((t) => {
        const singular = t.name.endsWith("s") ? t.name.slice(0, -1) : t.name;
        const capitalSingular = singular.charAt(0).toUpperCase() + singular.slice(1);
        const capitalPlural = t.name.charAt(0).toUpperCase() + t.name.slice(1);
        const queries = t.userScoped ? [
          `list${capitalPlural}`,
          `getMy${capitalPlural}`,
          `get${capitalSingular}`
        ] : [`list${capitalPlural}`, `get${capitalSingular}`];
        const mutations = [
          `create${capitalSingular}`,
          `update${capitalSingular}`,
          `delete${capitalSingular}`
        ];
        return {
          table: t.name,
          queries: queries.map((q) => `api.queries.${q}`),
          mutations: mutations.map((m) => `api.mutations.${m}`)
        };
      });
      return {
        success: true,
        message: `Scaffolded Convex schema with ${tables.length} table(s)`,
        filesCreated: results,
        tables: tables.map((t) => t.name),
        generatedFunctions,
        usage: generatedFunctions.map((f) => ({
          table: f.table,
          example: `const ${f.table} = useQuery(${f.queries[0]}); // List all ${f.table}`
        })),
        nextSteps: [
          "Call deployConvex NOW to sync schema with backend",
          "Then use the generated functions in your components:",
          ...generatedFunctions.flatMap((f) => [
            `  - ${f.queries.join(", ")}`,
            `  - ${f.mutations.join(", ")}`
          ])
        ]
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "scaffoldConvexSchema error",
        projectId,
        error: errorMessage
      });
      return {
        success: false,
        error: `Failed to scaffold Convex schema: ${errorMessage}`
      };
    }
  }
});
function generateSchemaFile(tables) {
  const imports = [
    'import { defineSchema, defineTable } from "convex/server";',
    'import { v } from "convex/values";'
  ];
  const tableDefinitions = tables.map((table) => {
    const fields = [];
    if (table.userScoped) {
      fields.push("    userId: v.string(),");
    }
    for (const field of table.fields) {
      if (table.userScoped && field.name === "userId") {
        continue;
      }
      const fieldDef = generateFieldDefinition(field);
      fields.push(`    ${field.name}: ${fieldDef},`);
    }
    const indexes = [];
    const usedIndexNames = /* @__PURE__ */ new Set();
    const usedIndexFields = /* @__PURE__ */ new Set();
    if (table.userScoped) {
      indexes.push(`    .index("by_user", ["userId"])`);
      usedIndexNames.add("by_user");
      usedIndexNames.add("by_userId");
      usedIndexFields.add("userId");
    }
    if (table.indexes) {
      for (const indexField of table.indexes) {
        if (usedIndexFields.has(indexField)) {
          continue;
        }
        const indexName = `by_${indexField}`;
        if (usedIndexNames.has(indexName)) {
          continue;
        }
        indexes.push(`    .index("${indexName}", ["${indexField}"])`);
        usedIndexNames.add(indexName);
        usedIndexFields.add(indexField);
      }
    }
    const indexString = indexes.length > 0 ? `
${indexes.join("\n")}` : "";
    return `  ${table.name}: defineTable({
${fields.join("\n")}
  })${indexString},`;
  });
  const schemaComment = "  // Better Auth tables (user, session, account, verification) are managed\n  // automatically by the @convex-dev/better-auth component.\n";
  return `${imports.join("\n")}

export default defineSchema({
${schemaComment}
  // Application tables
${tableDefinitions.join("\n\n")}
});
`;
}
function generateFieldDefinition(field) {
  switch (field.type) {
    case "string":
      return "v.string()";
    case "number":
      return "v.number()";
    case "boolean":
      return "v.boolean()";
    case "optional_string":
      return "v.optional(v.string())";
    case "optional_number":
      return "v.optional(v.number())";
    case "optional_boolean":
      return "v.optional(v.boolean())";
    case "id":
      return `v.id("${field.refTable || "unknown"}")`;
    case "array":
      if (field.arrayType === "id" && field.arrayRefTable) {
        return `v.array(v.id("${field.arrayRefTable}"))`;
      } else if (field.arrayType === "string") {
        return "v.array(v.string())";
      } else if (field.arrayType === "number") {
        return "v.array(v.number())";
      }
      return "v.array(v.string())";
    default:
      return "v.string()";
  }
}
function generateQueriesFile(tables) {
  const queries = [];
  for (const table of tables) {
    const singularName = table.name.endsWith("s") ? table.name.slice(0, -1) : table.name;
    const capitalName = singularName.charAt(0).toUpperCase() + singularName.slice(1);
    const capitalPlural = table.name.charAt(0).toUpperCase() + table.name.slice(1);
    if (table.userScoped) {
      queries.push(`// List all ${table.name} for the authenticated user
// Available as: api.queries.list${capitalPlural} OR api.queries.getMy${capitalPlural}
export const list${capitalPlural} = query({
  args: {},
  handler: async (ctx) => {
    const user = await authComponent.getAuthUser(ctx) as BetterAuthUser | null;
    if (!user) return [];

    return await ctx.db
      .query("${table.name}")
      .withIndex("by_user", (q: any) => q.eq("userId", user._id))
      .collect();
  },
});

// Alias for list${capitalPlural} - use whichever name you prefer
export const getMy${capitalPlural} = list${capitalPlural};`);
      queries.push(`// Get a single ${singularName} by ID (only if owned by user)
export const get${capitalName} = query({
  args: { id: v.id("${table.name}") },
  handler: async (ctx, args) => {
    const user = await authComponent.getAuthUser(ctx) as BetterAuthUser | null;
    if (!user) return null;

    const item = await ctx.db.get(args.id);
    if (!item || item.userId !== user._id) return null;
    return item;
  },
});`);
    } else {
      queries.push(`// List all ${table.name}
export const list${capitalPlural} = query({
  args: {},
  handler: async (ctx) => {
    return await ctx.db.query("${table.name}").collect();
  },
});`);
      queries.push(`// Get a single ${singularName} by ID
export const get${capitalName} = query({
  args: { id: v.id("${table.name}") },
  handler: async (ctx, args) => {
    return await ctx.db.get(args.id);
  },
});`);
    }
  }
  const hasUserScoped = tables.some((t) => t.userScoped);
  const userTypeDefinition = hasUserScoped ? `
// Type for Better Auth user (for TypeScript)
interface BetterAuthUser {
  _id: string;
  email: string;
  name?: string | null;
  image?: string | null;
  emailVerified?: boolean;
  createdAt: number;
  updatedAt: number;
}
` : "";
  return `import { query } from "./_generated/server";
import { v } from "convex/values";
${hasUserScoped ? 'import { authComponent } from "./auth";\n' : ""}${userTypeDefinition}
${queries.join("\n\n")}
`;
}
function generateMutationsFile(tables) {
  const mutations = [];
  for (const table of tables) {
    const singularName = table.name.endsWith("s") ? table.name.slice(0, -1) : table.name;
    const capitalName = singularName.charAt(0).toUpperCase() + singularName.slice(1);
    const fieldsForArgs = table.userScoped ? table.fields.filter((f) => f.name !== "userId") : table.fields;
    const createArgs = fieldsForArgs.map((f) => {
      const argType = generateArgType(f);
      return `    ${f.name}: ${argType},`;
    });
    const insertFields = table.userScoped ? ["      userId,"] : [];
    insertFields.push(
      ...fieldsForArgs.map((f) => `      ${f.name}: args.${f.name},`)
    );
    if (table.userScoped) {
      mutations.push(`// Create a new ${singularName}
export const create${capitalName} = mutation({
  args: {
${createArgs.join("\n")}
  },
  handler: async (ctx, args) => {
    const user = await authComponent.getAuthUser(ctx) as BetterAuthUser | null;
    if (!user) throw new Error("Not authenticated");

    return await ctx.db.insert("${table.name}", {
      userId: user._id,
${fieldsForArgs.map((f) => `      ${f.name}: args.${f.name},`).join("\n")}
    });
  },
});`);
      const updateArgs = fieldsForArgs.map((f) => {
        const argType = generateArgType(f);
        return `    ${f.name}: v.optional(${argType}),`;
      });
      mutations.push(`// Update a ${singularName} (only if owned by user)
export const update${capitalName} = mutation({
  args: {
    id: v.id("${table.name}"),
${updateArgs.join("\n")}
  },
  handler: async (ctx, args) => {
    const user = await authComponent.getAuthUser(ctx) as BetterAuthUser | null;
    if (!user) throw new Error("Not authenticated");

    const existing = await ctx.db.get(args.id);
    if (!existing || existing.userId !== user._id) {
      throw new Error("Not found or not authorized");
    }

    const { id, ...updates } = args;
    // Filter out undefined values
    const cleanUpdates = Object.fromEntries(
      Object.entries(updates).filter(([_, v]) => v !== undefined)
    );

    await ctx.db.patch(args.id, cleanUpdates);
    return args.id;
  },
});`);
      mutations.push(`// Delete a ${singularName} (only if owned by user)
export const delete${capitalName} = mutation({
  args: { id: v.id("${table.name}") },
  handler: async (ctx, args) => {
    const user = await authComponent.getAuthUser(ctx) as BetterAuthUser | null;
    if (!user) throw new Error("Not authenticated");

    const existing = await ctx.db.get(args.id);
    if (!existing || existing.userId !== user._id) {
      throw new Error("Not found or not authorized");
    }

    await ctx.db.delete(args.id);
    return args.id;
  },
});`);
    } else {
      mutations.push(`// Create a new ${singularName}
export const create${capitalName} = mutation({
  args: {
${createArgs.join("\n")}
  },
  handler: async (ctx, args) => {
    return await ctx.db.insert("${table.name}", {
${table.fields.map((f) => `      ${f.name}: args.${f.name},`).join("\n")}
    });
  },
});`);
      const updateArgs = table.fields.map((f) => {
        const argType = generateArgType(f);
        return `    ${f.name}: v.optional(${argType}),`;
      });
      mutations.push(`// Update a ${singularName}
export const update${capitalName} = mutation({
  args: {
    id: v.id("${table.name}"),
${updateArgs.join("\n")}
  },
  handler: async (ctx, args) => {
    const { id, ...updates } = args;
    const cleanUpdates = Object.fromEntries(
      Object.entries(updates).filter(([_, v]) => v !== undefined)
    );
    await ctx.db.patch(args.id, cleanUpdates);
    return args.id;
  },
});`);
      mutations.push(`// Delete a ${singularName}
export const delete${capitalName} = mutation({
  args: { id: v.id("${table.name}") },
  handler: async (ctx, args) => {
    await ctx.db.delete(args.id);
    return args.id;
  },
});`);
    }
  }
  const hasUserScoped = tables.some((t) => t.userScoped);
  const userTypeDefinition = hasUserScoped ? `
// Type for Better Auth user (for TypeScript)
interface BetterAuthUser {
  _id: string;
  email: string;
  name?: string | null;
  image?: string | null;
  emailVerified?: boolean;
  createdAt: number;
  updatedAt: number;
}
` : "";
  return `import { mutation } from "./_generated/server";
import { v } from "convex/values";
${hasUserScoped ? 'import { authComponent } from "./auth";\n' : ""}${userTypeDefinition}
${mutations.join("\n\n")}
`;
}
function generateArgType(field) {
  switch (field.type) {
    case "string":
      return "v.string()";
    case "number":
      return "v.number()";
    case "boolean":
      return "v.boolean()";
    case "optional_string":
      return "v.optional(v.string())";
    case "optional_number":
      return "v.optional(v.number())";
    case "optional_boolean":
      return "v.optional(v.boolean())";
    case "id":
      return `v.id("${field.refTable || "unknown"}")`;
    case "array":
      if (field.arrayType === "id" && field.arrayRefTable) {
        return `v.array(v.id("${field.arrayRefTable}"))`;
      } else if (field.arrayType === "string") {
        return "v.array(v.string())";
      } else if (field.arrayType === "number") {
        return "v.array(v.number())";
      }
      return "v.array(v.string())";
    default:
      return "v.string()";
  }
}
var fetchFromConnector = (context) => tool({
  description: `Fetch data from user's connected tools (Notion, Linear, Jira, Miro).

Use this when user references:
- "my Notion doc" / "from Notion" / "the Notion page"
- "my Linear issue" / "the ticket"
- "my Jira ticket" / "the story"
- "my Miro board" / "the wireframe"

This tool reads the user's actual data to understand requirements.
If the user hasn't connected the tool, it will return instructions to connect.`,
  inputSchema: z.object({
    provider: z.enum(["linear", "atlassian", "miro", "n8n"]).describe(
      "Which tool to fetch from (use notionWorkspace tool for Notion)"
    ),
    resourceType: z.enum(["search", "fetch", "pages", "databases"]).describe(
      "Type of operation: 'search' to find resources, 'fetch' to get specific content by URL, 'pages' to list pages, 'databases' to list databases"
    ),
    query: z.string().optional().describe(
      "Search query, page title, or URL to fetch. For 'fetch' type, provide the full URL."
    )
  }),
  execute: async ({ provider, resourceType, query }) => {
    const { userId, logger: logger2 } = context;
    logger2?.info({
      msg: "Fetching from connector",
      provider,
      resourceType,
      query
    });
    const connector = connectorRegistry.getPersonalConnector(
      provider.toUpperCase()
    );
    if (!connector) {
      return {
        success: false,
        error: `Unknown connector: ${provider}`,
        message: `The connector "${provider}" is not yet supported.`
      };
    }
    logger2?.info({
      msg: "Looking up connector access token",
      userId,
      provider: provider.toUpperCase()
    });
    const accessToken = await connectorRegistry.getPersonalAccessToken(
      userId,
      provider.toUpperCase()
    );
    logger2?.info({
      msg: "Access token lookup result",
      userId,
      provider: provider.toUpperCase(),
      hasToken: !!accessToken
    });
    if (!accessToken) {
      return {
        success: false,
        error: `${connector.name} is not connected`,
        action_required: "connect_connector",
        provider,
        message: `Please connect your ${connector.name} account in Settings \u2192 Connectors to use this feature.`,
        connectUrl: `/settings/connectors`
      };
    }
    try {
      const resources = await connector.fetchResources(accessToken, {
        resourceType,
        query: query || void 0
      });
      logger2?.info({
        msg: "Connector fetch successful",
        provider,
        resourceCount: resources.length
      });
      return {
        success: true,
        provider,
        resourceType,
        resources,
        count: resources.length,
        message: resources.length > 0 ? `Found ${resources.length} result(s) from ${connector.name}` : `No results found in ${connector.name} for "${query}"`
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "Connector fetch failed",
        provider,
        error: errorMessage
      });
      return {
        success: false,
        error: errorMessage,
        provider,
        message: `Failed to fetch from ${connector.name}: ${errorMessage}`
      };
    }
  }
});
var notionWorkspace = (context) => tool({
  description: `Interact with user's Notion workspace. USE THIS FOR ALL NOTION OPERATIONS.

ACTIONS:
- list_pages: Show all accessible pages (use when user says "check my pages", "what's in my Notion")
- search: Find pages by keyword (extract query from user's words, NOT project name)
- fetch: Get full content of a specific page
- create_page: Create a new page
- update_page: Update existing page
- create_database: Create a database
- query_database: Query database entries
- add_comment/get_comments: Manage comments
- duplicate_page/move_pages: Organize pages

IMPORTANT: The 'query' param must come from USER'S WORDS, not the project name!
Example: User says "find my PRD" \u2192 query: "PRD"
Example: User says "check my pages" \u2192 action: "list_pages" (no query)`,
  inputSchema: z.object({
    action: z.enum([
      "search",
      "list_pages",
      "fetch",
      "create_page",
      "update_page",
      "create_database",
      "query_database",
      "add_comment",
      "get_comments",
      "duplicate_page",
      "move_pages"
    ]).describe(
      "The action to perform: 'search' to find by keyword, 'list_pages' to list all accessible pages, 'fetch' to get full page content"
    ),
    // Search params
    query: z.string().optional().describe("Search query (for search action)"),
    // Fetch/Update params
    pageId: z.string().optional().describe(
      "Page or database ID (for fetch, update, comments, duplicate)"
    ),
    pageUrl: z.string().optional().describe("Notion page URL (alternative to pageId for fetch)"),
    // Create page params
    parentId: z.string().optional().describe(
      "Parent page or database ID (for create_page, create_database)"
    ),
    title: z.string().optional().describe("Title for new page or database"),
    content: z.string().optional().describe("Markdown content for page (create or update)"),
    // Database params
    databaseId: z.string().optional().describe("Database ID (for query_database)"),
    properties: z.record(z.string(), z.unknown()).optional().describe(
      "Properties schema (for create_database) or filter (for query)"
    ),
    filter: z.record(z.string(), z.unknown()).optional().describe("Filter criteria for database query"),
    sorts: z.array(
      z.object({
        property: z.string(),
        direction: z.enum(["ascending", "descending"])
      })
    ).optional().describe("Sort criteria for database query"),
    // Comment params
    comment: z.string().optional().describe("Comment text (for add_comment)"),
    // Move params
    pageIds: z.array(z.string()).optional().describe("Page IDs to move (for move_pages)"),
    newParentId: z.string().optional().describe("New parent ID (for move_pages, duplicate_page)")
  }),
  execute: async (params) => {
    const { userId, logger: logger2 } = context;
    const { action } = params;
    logger2?.info({ msg: "Notion workspace action", action, params });
    const accessToken = await connectorRegistry.getPersonalAccessToken(
      userId,
      "NOTION"
    );
    if (!accessToken) {
      return {
        success: false,
        error: "Notion is not connected",
        action_required: "connect_connector",
        provider: "notion",
        message: "Please connect your Notion account in Settings \u2192 Connectors to use this feature.",
        connectUrl: "/settings/connectors"
      };
    }
    try {
      const {
        notionMCPSearch: notionMCPSearch2,
        notionMCPFetch: notionMCPFetch2,
        notionMCPCreatePages,
        notionMCPUpdatePage,
        notionMCPCreateDatabase,
        notionMCPQueryDatabase,
        notionMCPCreateComment,
        notionMCPGetComments,
        notionMCPDuplicatePage,
        notionMCPMovePages
      } = await import("./mcp-client-JCOSPBZ6.js");
      let result;
      switch (action) {
        case "search": {
          const searchQuery = params.query || "*";
          result = await notionMCPSearch2(accessToken, searchQuery);
          break;
        }
        case "list_pages": {
          result = await notionMCPSearch2(accessToken, "page");
          break;
        }
        case "fetch": {
          const id = params.pageId || params.pageUrl;
          if (!id) {
            return {
              success: false,
              error: "pageId or pageUrl is required for fetch"
            };
          }
          result = await notionMCPFetch2(accessToken, id);
          break;
        }
        case "create_page": {
          if (!params.parentId || !params.title) {
            return {
              success: false,
              error: "parentId and title are required for create_page"
            };
          }
          result = await notionMCPCreatePages(
            accessToken,
            params.parentId,
            params.title,
            params.content
          );
          break;
        }
        case "update_page": {
          if (!params.pageId) {
            return {
              success: false,
              error: "pageId is required for update_page"
            };
          }
          result = await notionMCPUpdatePage(
            accessToken,
            params.pageId,
            params.properties,
            params.content
          );
          break;
        }
        case "create_database": {
          if (!params.parentId || !params.title || !params.properties) {
            return {
              success: false,
              error: "parentId, title, and properties are required for create_database"
            };
          }
          result = await notionMCPCreateDatabase(
            accessToken,
            params.parentId,
            params.title,
            params.properties
          );
          break;
        }
        case "query_database": {
          if (!params.databaseId) {
            return {
              success: false,
              error: "databaseId is required for query_database"
            };
          }
          result = await notionMCPQueryDatabase(
            accessToken,
            params.databaseId,
            params.filter,
            params.sorts
          );
          break;
        }
        case "add_comment": {
          if (!params.pageId || !params.comment) {
            return {
              success: false,
              error: "pageId and comment are required for add_comment"
            };
          }
          result = await notionMCPCreateComment(
            accessToken,
            params.pageId,
            params.comment
          );
          break;
        }
        case "get_comments": {
          if (!params.pageId) {
            return {
              success: false,
              error: "pageId is required for get_comments"
            };
          }
          result = await notionMCPGetComments(accessToken, params.pageId);
          break;
        }
        case "duplicate_page": {
          if (!params.pageId) {
            return {
              success: false,
              error: "pageId is required for duplicate_page"
            };
          }
          result = await notionMCPDuplicatePage(
            accessToken,
            params.pageId,
            params.newParentId
          );
          break;
        }
        case "move_pages": {
          if (!params.pageIds || !params.newParentId) {
            return {
              success: false,
              error: "pageIds and newParentId are required for move_pages"
            };
          }
          result = await notionMCPMovePages(
            accessToken,
            params.pageIds,
            params.newParentId
          );
          break;
        }
        default:
          return { success: false, error: `Unknown action: ${action}` };
      }
      if (!result.success) {
        return {
          success: false,
          error: result.error,
          message: `Notion ${action} failed: ${result.error}`
        };
      }
      return {
        success: true,
        action,
        content: result.content,
        message: `Notion ${action} completed successfully`
      };
    } catch (error) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      logger2?.error({
        msg: "Notion workspace error",
        action,
        error: errorMessage
      });
      return {
        success: false,
        error: errorMessage,
        message: `Notion ${action} failed: ${errorMessage}`
      };
    }
  }
});
var tools = (context) => ({
  getFiles: getFiles(context),
  readFile: readFile2(context),
  createOrEditFiles: createOrEditFiles(context),
  // Migration analysis for imported projects - scans codebase systematically
  analyzeMigration: analyzeMigration(context),
  getSandboxUrl: getSandboxUrl(context),
  finalizeWorkingFragment: finalizeWorkingFragment(context),
  createFragmentSnapshot: createFragmentSnapshot(context),
  installPackages: installPackages(context),
  quickEdit: quickEdit(context),
  // detectErrors and autoFixErrors removed - error detection now happens in finalizeWorkingFragment Gate 4
  // simpleMessage: simpleMessage(context),
  manageTodos: manageTodos(context),
  generateImage: generateImage(context),
  // Shipper Cloud (Convex) deployment with auth - executes immediately
  deployToShipperCloud: deployToShipperCloud(context),
  // Enable AI capabilities with Convex Agent component
  enableAI: enableAI(context),
  // Request API keys from user via UI card (HITL)
  requestApiKeys: requestApiKeys(context),
  // Setup Stripe payments with automatic code generation
  setupStripePayments: setupStripePayments(context),
  // Deploy Convex schema/functions to backend
  deployConvex: deployConvex(context),
  // Scaffold Convex schema, queries, and mutations from table definitions
  scaffoldConvexSchema: scaffoldConvexSchema(context),
  // Convex data operations - query and mutate data in the database
  runConvexQuery: runConvexQuery(context),
  runConvexMutation: runConvexMutation(context),
  listConvexFunctions: listConvexFunctions(context),
  // Stripe HITL tools - user sees and approves each operation
  stripeListProducts: stripeListProducts(context),
  stripeListPrices: stripeListPrices(context),
  stripeCreateProductAndPrice: stripeCreateProductAndPrice(context),
  // Stripe execution tools - called after user approval from HITL
  executeStripeListProducts: executeStripeListProducts(context),
  executeStripeListPrices: executeStripeListPrices(context),
  executeStripeCreateProductAndPrice: executeStripeCreateProductAndPrice(context),
  // Fetch from connected personal connectors (Notion, Linear, Jira, etc.)
  fetchFromConnector: fetchFromConnector(context),
  // Full Notion workspace capabilities (search, create, update, etc.)
  notionWorkspace: notionWorkspace(context)
});
var toolNames = Object.keys(tools({}));

export {
  getSandboxHealth,
  ensureSandboxRecovered,
  ErrorClassifier,
  VoltAgentService,
  getEnvironmentProperties,
  getPostHogCapture,
  generateSpanId,
  getFullStackPrompt,
  redisFileStreamPublisher,
  encrypt,
  encryptCredentials,
  connectorRegistry,
  getNotionAuthUrlAsync,
  getSandbox2 as getSandbox,
  createSandbox2 as createSandbox,
  getFilesFromSandbox,
  readFileFromSandbox,
  writeFileToSandbox,
  validateSyntaxOrThrow,
  analyzeProjectErrors,
  runBuildValidationGate,
  ensurePreviewHealthy,
  updateWorkingFragment,
  getFiles,
  analyzeMigration,
  readFile2 as readFile,
  createOrEditFiles,
  getSandboxUrl,
  finalizeWorkingFragment,
  createFragmentSnapshot,
  installPackages,
  quickEdit,
  detectErrors,
  autoFixErrors,
  simpleMessage,
  manageTodos,
  applyTheme,
  generateImage,
  deployToShipperCloud,
  enableAI,
  requestApiKeys,
  setupStripePayments,
  runConvexQuery,
  runConvexMutation,
  listConvexFunctions,
  deployConvex,
  stripeListProducts,
  stripeListPrices,
  stripeCreateProductAndPrice,
  executeStripeListProducts,
  executeStripeListPrices,
  executeStripeCreateProductAndPrice,
  scaffoldConvexSchema,
  fetchFromConnector,
  notionWorkspace,
  tools,
  toolNames
};
